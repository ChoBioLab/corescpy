{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Options & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import re\n",
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import corescpy as cr\n",
    "\n",
    "# Count Threshold for Cell Quantification\n",
    "count_threshold = 1\n",
    "\n",
    "# File Paths\n",
    "panel = \"TUQ97N\"\n",
    "direc = \"/mnt/cho_lab/bbdata2/\"\n",
    "dir_data = os.path.join(direc, f\"outputs/{panel}\")\n",
    "dir_writeable = \"/mnt/cho_lab/disk2/elizabeth/data/shared-xenium-library\"\n",
    "out_dir = os.path.join(dir_writeable, \"outputs/TUQ97N/nebraska\")\n",
    "mdf = os.path.join(dir_writeable, \"samples.csv\")  # metadata\n",
    "path_ann = \"~/corescpy/examples/markers_lineages.csv\"\n",
    "\n",
    "# Constants\n",
    "cso, csid, col_condition = (cr.pp.COL_SAMPLE_ID_O, cr.pp.COL_SAMPLE_ID,\n",
    "                            cr.pp.COL_CONDITION)\n",
    "col_inflamed, col_stricture = (cr.pp.COL_INFLAMED, cr.pp.COL_STRICTURE)\n",
    "\n",
    "# Clustering Version\n",
    "c_t = \"leiden_res1pt5_dist0_npc30\"  # high resolution\n",
    "# c_t = \"leiden_res0pt75_dist0pt3_npc30\"  # medium resolution\n",
    "# c_t = \"leiden_res0pt5_dist0pt5_npc30\"  # low resolution\n",
    "\n",
    "# ToppGene Sources & Quantification Count Threshold\n",
    "srcs = [\"Cells of the human intestinal tract mapped across space and time\",\n",
    "        \"Human Ileal Epithelial cells from Crohn’s Disease\",\n",
    "        \"Human Ileal Immune cells from Crohn’s Disease\"]\n",
    "count_threshold = 1\n",
    "\n",
    "# Display\n",
    "pd.options.display.max_colwidth = 1000\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 500\n",
    "\n",
    "# Annotation Guide File\n",
    "anf = pd.read_csv(path_ann)\n",
    "assign = anf.dropna(subset=col_assignment).set_index(\n",
    "    \"gene\").rename_axis(\"Gene\")  # markers\n",
    "\n",
    "# Metadata & List of Existing Xenium Data Directories\n",
    "metadata = (pd.read_excel if mdf[-4:] == \"xlsx\" else pd.read_csv)(mdf)\n",
    "metadata.loc[:, col_condition] = metadata.apply(lambda x: \"Stricture\" if x[\n",
    "    col_stricture].lower() in [\"stricture\", \"yes\"] else x[\n",
    "        col_inflamed].capitalize(), axis=1)  # inflamation/stricture condition\n",
    "metadata.loc[:, csid] = metadata[col_condition] + \"-\" + metadata[cso]\n",
    "samp_ids = dict(metadata.set_index(cso)[csid])  # map libid to condition-ID\n",
    "files = functools.reduce(lambda i, j: i + j, [[os.path.join(\n",
    "    run, i) for i in os.listdir(os.path.join(\n",
    "        dir_data, run))] for run in os.listdir(dir_data)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Spatial Data\n",
    "libid = \"Stricture-50403C1\"\n",
    "file_path = np.array(files)[np.where([\"-\".join(libid.split(\n",
    "    \"-\")[1:]) == os.path.basename(x).split(\"__\")[2].split(\n",
    "        \"-\")[0] for x in files])[0][0]]  # find file for sample\n",
    "self = cr.Spatial(os.path.join(dir_data, file_path), library_id=libid)\n",
    "self.update_from_h5ad(os.path.join(out_dir, libid + \".h5ad\"))\n",
    "self.get_layer(\"counts\", inplace=True)\n",
    "\n",
    "# Write Cluster Files\n",
    "# self.write_clusters(out_dir, col_cell_type=c, overwrite=True,\n",
    "#                     file_prefix=f\"{self._library_id}__\", n_top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToppGene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.get_layer(\"counts\", inplace=True)\n",
    "tgdf, mks = self.annotate_clusters(\n",
    "        None, sources=srcs, col_cell_type=c_t, max_results=10000,\n",
    "        name_pattern={srcs[0]: \"SmallIntestine\"}, p_threshold=1e-15,\n",
    "        lfc_threshold=1, n_top_genes=20, n_top_annotations=40)\n",
    "longs = [(\" / Per Region, Age_group, Lineage, cell class, cell type\", \"\"),\n",
    "         (\"SmallIntestine\", \"SmInt\")]\n",
    "for x in longs:\n",
    "    tgdf.loc[:, \"Name\"] = tgdf.Name.apply(lambda y: re.sub(x[0], x[1], y))\n",
    "tgdf.loc[:, \"Name\"] = tgdf.Name.apply(lambda y: \"|\".join(y.split(\"|\")[\n",
    "        :-1]) if y.split(\"|\")[-1].split(\"-\")[0] in y.split(\"-\")[0] and (any(\n",
    "            i in y for i in [\"Child\", \"Adult\", \"Pediatric\", \"Trim\"])) else y)\n",
    "tgdf = tgdf.rename_axis([c_t, \"Rank\"])\n",
    "tgdf = tgdf.join(tgdf.apply(\n",
    "    lambda x: f\"{x['GenesInTermInQuery']} / {x['GenesInQuery']}\",\n",
    "    axis=1).to_frame(\"Marker Matches\"))\n",
    "tgdf = tgdf[list(tgdf.columns[:1]) + [\"Marker Matches\"] + list(\n",
    "        tgdf.columns[1:-1])]\n",
    "tgdf = tgdf.rename_axis([c_t, \"Rank\"])\n",
    "tgdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "outs, failed = {}, []  # hold results\n",
    "for i, k in enumerate(self.rna.obs[c_t].unique()):\n",
    "    if tgdf is not None and k in tgdf.reset_index(1).index.values:\n",
    "        print(f\"{'=' * 80}\\n{k}\\n ({i + 1}/{len(self.rna.obs[c_t].unique())})\"\n",
    "              f\"\\n{'=' * 80}\\n\\n{tgdf.loc[k].iloc[:, :3]}\\n\\n\")\n",
    "    try:\n",
    "        outs[k] = self.print_markers(\n",
    "                k, assign, col_cell_type=c_t, lfc_threshold=2,\n",
    "                count_threshold=count_threshold, p_threshold=1e-15,\n",
    "                print_threshold=15, n_top_genes=20)\n",
    "    except Exception as err:\n",
    "        failed += [(k, err)]\n",
    "if len(failed) > 0:\n",
    "    print(f\"Failed: {pd.Series(dict(failed))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Specific Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ggg = pd.DataFrame([\"CDKN1A\", \"CDKN2A\", \"TP53\", \"PLAUR\", \"IL6ST\"])[\n",
    "    0].to_frame(\"Gene\").assign(Annotation=\"Senescence\").set_index(\"Gene\")\n",
    "outs_bg, failed = {}, []  # hold results\n",
    "for i, k in enumerate(self.rna.obs[c_t].unique()):\n",
    "    outs_bg[k] = self.print_markers(\n",
    "        k, ggg, col_cell_type=c_t, lfc_threshold=None, print_threshold=0,\n",
    "        count_threshold=count_threshold, p_threshold=None, n_top_genes=None)\n",
    "if len(failed) > 0:\n",
    "    print(f\"Failed: {pd.Series(dict(failed))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, x in [outs, outs_bg]:\n",
    "    quant = {}\n",
    "    for k in outs:\n",
    "        percs_exp, n_exp = x[k][1].copy(), x[k][2].copy()\n",
    "        quant[k] = pd.concat([\n",
    "            x.rename_axis(\"Measure\", axis=1).stack() for x in [\n",
    "                percs_exp.rename_axis(\"Cell Types\", axis=1).stack().replace(\n",
    "                    \"\", np.nan).dropna().to_frame(\"n_exp\"), n_exp.set_index(\n",
    "                        \"Cell Types\", append=True).rename({\n",
    "                            k: \"Cluster\"}, axis=1)]], keys=[\n",
    "                                \"quantification\", \"representation\"]).unstack(\n",
    "                                    0).unstack(-1).dropna(how=\"all\", axis=1)\n",
    "    quant = pd.concat(quant, names=[\"Cluster\"])\n",
    "    if out_dir:\n",
    "        suf = \"\" if i == 0 else \"_\" + \"_\".join(ggg.reset_index(\n",
    "            ).Gene.unique().to_list())  # file suffix if by gene\n",
    "        quant.to_excel(os.path.join(\n",
    "            out_dir, \"quantification\",\n",
    "            f\"{self._library_id}__{c_t}_quantification_annotation{suf}.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToppGene/Quantifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_cluster = \"32\"\n",
    "output = outs  # see \"by markers\" version\n",
    "# output = outs_bg  # see \"by specific genes\" version\n",
    "\n",
    "if tgdf is not None and key_cluster in tgdf.reset_index(1).index.values:\n",
    "    print(f\"{'=' * 80}\\n\\n{key_cluster}\\n\\n\"\n",
    "          f\"{tgdf.loc[key_cluster].iloc[:, :-3]}\")\n",
    "_, percs_exp, n_exp, genes, msg = outs[key_cluster]\n",
    "n_exp = n_exp.copy().set_index(\"Cell Types\", append=True)\n",
    "print(percs_exp.applymap(lambda x: x if x == \"\" else str(\n",
    "    int(x)) + \"%\").stack().replace(\"\", np.nan).dropna().sort_values(\n",
    "            ascending=False).head(20))\n",
    "print(f\"{genes}\\n\\n{n_exp.applymap(int)}\\n\\n{msg}\")\n",
    "print(f\"\\n\\nN = {sum(self.rna.obs[c_t] == k)}\\n\\n\")\n",
    "percs_exp.applymap(lambda x: x if x == \"\" else str(int(x)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(1, 2)\n",
    "self.plot_spatial(color=c_t, groups=[\"32\"], ax=axis[0])\n",
    "self.plot_spatial(\"Stricture-50336A___morphology_focus_scale4\", ax=axis[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specific to Subsets of Cell Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp = [\"0\", \"5\", \"8\", \"10\", \"18\", \"20\", \"34\"]\n",
    "comp = [\"2\", \"7\", \"11\", \"21\", \"28\"]\n",
    "count_threshold = 1\n",
    "key_cluster = \"2\"\n",
    "_, percs_exp, n_exp, genes, msg = self.print_markers(\n",
    "    key_cluster, assign, col_cell_type=c_t, lfc_threshold=None,\n",
    "    key_compare=comp, count_threshold=count_threshold, p_threshold=1,\n",
    "    n_top_genes=list(assign[assign.Lump == \"Epithelial\"].index.intersection(\n",
    "        self.rna.var_names)) + [\"TP53\", \"PLAUR\"])\n",
    "n_exp = n_exp.copy().set_index(\"Cell Types\", append=True)\n",
    "print(f\"{genes}\\n\\n{n_exp.applymap(int)}\\n\\n{msg}\")\n",
    "percs_exp.applymap(lambda x: x if x == \"\" else str(int(x)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write All Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'50336C': 'Uninflamed-50336C',\n",
       " '50336B': 'Inflamed-50336B',\n",
       " '50336A': 'Stricture-50336A',\n",
       " '50403C2': 'Stricture-50403C2',\n",
       " '50403C1': 'Stricture-50403C1',\n",
       " '50403B': 'Inflamed-50403B',\n",
       " '50403A1': 'Uninflamed-50403A1',\n",
       " '50403A2': 'Uninflamed-50403A2',\n",
       " '50217C': 'Stricture-50217C',\n",
       " '50217B': 'Uninflamed-50217B',\n",
       " '50217A': 'Inflamed-50217A',\n",
       " '50006C': 'Stricture-50006C',\n",
       " '50006B': 'Uninflamed-50006B',\n",
       " '50006A': 'Inflamed-50006A',\n",
       " '50445A3': 'Stricture-50445A3',\n",
       " '50007B2': 'Stricture-50007B2',\n",
       " '50115A2': 'Stricture-50115A2',\n",
       " '49696A4': 'Stricture-49696A4',\n",
       " '49559A5': 'Stricture-49559A5',\n",
       " '49464A4': 'Stricture-49464A4',\n",
       " '49471A4': 'Stricture-49471A4',\n",
       " '49377A2': 'Stricture-49377A2',\n",
       " '50618B5': 'Stricture-50618B5',\n",
       " '50564A4': 'Stricture-50564A4',\n",
       " '50452C': 'Stricture-50452C',\n",
       " '50452B': 'Inflamed-50452B',\n",
       " '50452A': 'Uninflamed-50452A'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TUQ97N'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.basename(\n",
    "    dir_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_fff = \"out_file\"\n",
    "fff = np.array(cr.pp.construct_file(directory=direc, panel_id=panel))\n",
    "bff = np.array([os.path.basename(i) for i in fff])  # base path names\n",
    "samps = np.array([i.split(\"__\")[2].split(\"-\")[0] for i in fff])\n",
    "for x in metadata[cso]:\n",
    "    m_f = metadata[metadata[cso] == x][\n",
    "        \"out_file\"].iloc[0]  # ...use to find unconventionally-named files\n",
    "    locx = np.where(samps == x)[0] if pd.isnull(\n",
    "        m_f) else np.where(bff == m_f)[0]\n",
    "    metadata.loc[metadata[cso] == x, col_fff] = fff[locx[0]] if (\n",
    "        len(locx) > 0) else np.nan  # assign output file to metadata row\n",
    "metadata = metadata.dropna(subset=[col_fff]).drop_duplicates().set_index(cso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/cho_lab/bbdata2/outputs/TUQ97N/CHO-001/output-XETG00189__0010700__50452A-TUQ97N-EA__20240126__205019'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Spatial Data\n",
    "for libid in samp_ids:\n",
    "    if not os.path.exists(os.path.join(out_dir, samp_ids[libid] + \".h5ad\")):\n",
    "        print(f\"\\n\\nWarning: Critical file(s) for {libid} not found.\\n\\n\")\n",
    "        continue\n",
    "    self = cr.Spatial(metadata.loc[libid][\"out_file\"],\n",
    "                      library_id=samp_ids[libid])\n",
    "    self.update_from_h5ad(os.path.join(out_dir, samp_ids[libid] + \".h5ad\"))\n",
    "    if c_t not in self.rna.obs.columns:\n",
    "        print(f\"\\n\\nWarning: {c_t} column for {libid} not found.\\n\\n\")\n",
    "        continue\n",
    "    self.write_clusters(out_dir, col_cell_type=c_t, overwrite=True,\n",
    "                        file_prefix=f\"{self._library_id}__\",\n",
    "                        n_top=\"find_markers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50336C annotated.\n",
      "50336B annotated.\n",
      "50336A annotated.\n",
      "50403C2 not in annotation dictionary.\n",
      "50403C1 annotated.\n",
      "50403B annotated.\n",
      "50403A1 annotated.\n",
      "50403A2 annotated.\n",
      "50217C annotated.\n",
      "50217B annotated.\n",
      "50217A annotated.\n",
      "50006C annotated.\n",
      "50006B annotated.\n",
      "50006A annotated.\n",
      "50445A3 not in annotation dictionary.\n",
      "50007B2 not in annotation dictionary.\n",
      "50115A2 not in annotation dictionary.\n",
      "\n",
      "\n",
      "Warning: leiden_res1pt5_dist0_npc30 column for 49696A4 not found.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Warning: Critical file(s) for 49559A5 not found.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Warning: Critical file(s) for 49464A4 not found.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Warning: leiden_res1pt5_dist0_npc30 column for 49471A4 not found.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Warning: Critical file(s) for 49377A2 not found.\n",
      "\n",
      "\n",
      "50618B5 not in annotation dictionary.\n",
      "50564A4 annotated.\n",
      "50452C annotated.\n",
      "50452B annotated.\n",
      "50452A annotated.\n"
     ]
    }
   ],
   "source": [
    "c_t = \"leiden_res1pt5_dist0_npc30\"\n",
    "# Faster way for spatial data\n",
    "\n",
    "# import scanpy as sc\n",
    "\n",
    "# c_t = \"leiden_res1pt5_dist0_npc30\"\n",
    "clusterings = [\"res1pt5_dist0_npc30\"]\n",
    "\n",
    "for libid in samp_ids:\n",
    "    if not os.path.exists(os.path.join(out_dir, samp_ids[libid] + \".h5ad\")):\n",
    "        print(f\"\\n\\nWarning: Critical file(s) for {libid} not found.\\n\\n\")\n",
    "        continue\n",
    "    adata = sc.read(os.path.join(out_dir, samp_ids[libid] + \".h5ad\"))\n",
    "    for r in clusterings:\n",
    "        c_t = f\"leiden_{r}\"\n",
    "        if c_t not in adata.obs.columns:\n",
    "            print(f\"\\n\\nWarning: {c_t} column for {libid} not found.\\n\\n\")\n",
    "            continue\n",
    "        fff = os.path.join(out_dir, f\"{samp_ids[libid]}__{c_t}.csv\")\n",
    "        adata.obs.set_index(\"cell_id\")[c_t].to_frame(\"group\").to_csv(fff)\n",
    "        fmr = pd.read_excel(os.path.join(\n",
    "            out_dir, \"annotation_dictionaries/annotations_all.xlsx\"),\n",
    "                            index_col=[0, 1]).iloc[:, :3].astype(str).dropna()\n",
    "        if f\"{samp_ids[libid]}___leiden_{r}_dictionary.xlsx\" not in [\n",
    "                v[0] for v in fmr.index]:\n",
    "            print(f\"{libid} not in annotation dictionary.\")\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"{libid} annotated.\")\n",
    "        fmr = fmr.loc[f\"{samp_ids[libid]}___leiden_{r}_dictionary.xlsx\"]\n",
    "        mans = dict(fmr[\"annotation\"])\n",
    "        adata.obs.loc[:, f\"manual_{r}\"] = adata.obs[f\"leiden_{r}\"].astype(\n",
    "            int).astype(str).replace(mans)  # Leiden -> manual annotation\n",
    "        adata.obs.loc[adata.obs[f\"manual_{r}\"].isnull(\n",
    "            ), f\"manual_{r}\"] = adata.obs.loc[adata.obs[\n",
    "                f\"manual_{r}\"].isnull(), f\"leiden_{r}\"].astype(str)\n",
    "        adata.obs.loc[:, f\"manual_{r}\"] = adata.obs[\n",
    "            f\"manual_{r}\"].astype(\"category\")  # as categorical\n",
    "        fff = os.path.join(out_dir, f\"{samp_ids[libid]}__manual_{r}.csv\")\n",
    "        adata.obs.set_index(\"cell_id\")[f\"manual_{r}\"].to_frame(\n",
    "            \"group\").to_csv(fff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
