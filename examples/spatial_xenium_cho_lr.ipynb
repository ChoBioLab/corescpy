{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Options\n",
    "\n",
    "Valid L-R pairs determined using the connectome database (literature-verified)\n",
    "Can also include putative pairs\n",
    "(22 in our data)\n",
    "\n",
    "From `stlearn`:\n",
    "\n",
    "> stLearn’s Spatially-Constrained and Two-level Permutation (SCTP) analysis solves this issue by first identifying spatial neighbourhoods of ligand-receptor co-expression, computing so-called LR scores (see “Methods” section). This is then followed by a unique constrained, two-level permutation test of both genes and spots/cells to robustly identify spatial locations where a given LR pair has significantly higher scores than random. This removes potential bias towards highly expressed genes and spatial location, thus reducing false discovery. Optionally, among the significant LRs and spatial locations, we continue to permute cell types by randomly shuffling cells/spots to different spatial locations to also test for cell type pairs that are significantly over-represented in those regions (Fig. 4a). In doing so, stLearn can make specific inferences about three important processes: cell type interactions (at the level of individual cells or spots), the LR pairs that are used for these interactions, and the spatial locations with the most active interactions in the tissue, as presented below.\n",
    "\n",
    "> (1) spatial neighbourhoods are scored for LR co-expression\n",
    "> \n",
    "> (2) background spatial co-expression is determined by randomly pairing genes (default 1000 pairs) with equivalent expression levels to LR pair\n",
    "> \n",
    "> (3) significant spots of spatial LR co-expression are determined by comparison to the random background\n",
    "> \n",
    "> (4) counting of cell type co-occurrence in neighbourhoods of significant LR co-expression, with and without permutation of cell type information\n",
    "> \n",
    "> (5) cell types with significant co-localisation in regions of LR co-expression are predicted as interacting\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import math\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import traceback\n",
    "import warnings\n",
    "import functools\n",
    "from dask_image.imread import imread\n",
    "import imagecodecs\n",
    "from PIL import Image\n",
    "import dask.array as da\n",
    "import scipy\n",
    "import scipy.spatial as spatial\n",
    "import stlearn as st\n",
    "import scanpy as sc\n",
    "import squidpy as sq\n",
    "from skbio.stats.composition import clr\n",
    "from pymer4.models import Lmer, Lm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import corescpy as cr\n",
    "# from corescpy.ax import create_spot_grid\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.options.display.max_colwidth = 1000\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 500\n",
    "\n",
    "SPATIAL_KEY = \"spatial\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# data_suffix = \"\"  # whole sample\n",
    "data_suffix = \"_mucosa\"\n",
    "out_dir_objects = str(\"/mnt/cho_lab/disk2/elizabeth/data/\"\n",
    "                      \"shared-xenium-library/outputs/TUQ97N/nebraska\")\n",
    "# for now, my home directory is where the original anndata objects are\n",
    "if data_suffix != \"\":  # in case cropped objects, subdirectory of nebraska\n",
    "    out_dir_objects = os.path.join(out_dir_objects, \"_\".join(\n",
    "        data_suffix.split(\"_\")[1:]))\n",
    "\n",
    "load_suffix = None  # don't load\n",
    "# load_suffix = f\"{data_suffix}_hires_hipair_hiperm\"\n",
    "load_suffix = f\"{data_suffix}\"\n",
    "# load_suffix = \"\"  # if didn't originally have a suffix\n",
    "\n",
    "# Directories\n",
    "ddm = \"/mnt/cho_lab\" if os.path.exists(\"/mnt/cho_lab\") else \"/mnt\"  # Spark?\n",
    "ddl = f\"{ddm}/disk2/{os.getlogin()}/data/shared-xenium-library\" if (\n",
    "    \"cho\" in ddm) else os.path.join(ddu, \"shared-xenium-library\")\n",
    "dir_data = os.path.join(ddm, \"bbdata2/outputs/TUQ97N\")\n",
    "out_dir = os.path.join(ddl, \"outputs/TUQ97N/nebraska\", data_suffix)\n",
    "file_a = os.path.join(os.path.join(ddl, \"outputs/TUQ97N/nebraska\"),\n",
    "                      \"annotation_dictionaries/annotations_all.xlsx\")\n",
    "file_mdf = os.path.join(ddl, \"samples.csv\")  # metadata\n",
    "c_m = \"annotation\"  # column in `file_a` to use for cell type labels\n",
    "\n",
    "\n",
    "# write_suffix = None  # don't write\n",
    "write_suffix = f\"{data_suffix}\"\n",
    "\n",
    "# libs = [\"50452A\", \"50452B\", \"50006A\", \"50006B\",\n",
    "#         \"50217A\", \"50217B\",\n",
    "#         \"50336B\", \"50336C\",\n",
    "#         # \"50403A1\",  # exclude because low quality\n",
    "#         \"50403A2\", \"50403B\"]  # paired (un)inflamed\n",
    "libs = [\"50006A\", \"50006B\", \"50217A\", \"50217B\",\n",
    "        \"50336B\", \"50336C\", \"50403B\", \"50403A2\"]\n",
    "\n",
    "# Analysis Options\n",
    "col_cell_type = \"leiden_res1pt5_dist0_npc30\"  # high resolution\n",
    "l_r = {\"CSF1\": \"CSF1R\", \"CSF2\": [\"CSF2RA\", \"CSF2RB\"]}\n",
    "plot_lr = [\"CSF1_CSF1R\", \"CSF2_CSF2RA\", \"CSF2_CSF2RB\"]\n",
    "# n_spots = 400\n",
    "# n_spots = \"80%\"\n",
    "n_spots = \"70%\"  # increase if label transfer looks bad\n",
    "organism = \"human\"\n",
    "resource = \"connectomeDB2020_lit\"\n",
    "# distance = 200\n",
    "distance = \"auto\"\n",
    "min_med_neighbors = 3\n",
    "min_spots = 2\n",
    "n_pairs = 20000  # CHANGE DEFAULT TO 10000\n",
    "n_top = 50\n",
    "n_jobs = 20\n",
    "layer = \"counts\"\n",
    "cell_prop_cutoff = 0.05\n",
    "n_perms = 20000\n",
    "# adj_method = \"fdr_bh\"\n",
    "# pval_adj_cutoff = 0.05\n",
    "adj_method = \"fdr_bh\"\n",
    "pval_adj_cutoff = 0.05\n",
    "adj_axis = \"spot\"\n",
    "\n",
    "# Column Names\n",
    "col_subject, col_condition = cr.pp.COL_SUBJECT, cr.pp.COL_CONDITION\n",
    "col_inflamed, col_stricture = cr.pp.COL_INFLAMED, cr.pp.COL_STRICTURE\n",
    "col_sample_id_o, col_sample_id = cr.pp.COL_SAMPLE_ID_O, cr.pp.COL_SAMPLE_ID\n",
    "key_uninfl, key_infl, key_stric = [cr.pp.KEY_UNINFLAMED, cr.pp.KEY_INFLAMED,\n",
    "                                   cr.pp.KEY_STRICTURE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pd.read_excel(file_a, index_col=[0, 1])  # Leiden-annotation map\n",
    "annotations = annotations.reset_index().astype({annotations.index.names[\n",
    "    1]: int}).astype({annotations.index.names[\n",
    "        1]: \"string\"}).set_index(annotations.index.names).rename_axis([\n",
    "            \"File\", col_cell_type])\n",
    "m_d = (pd.read_excel if file_mdf[-4:] == \"xlsx\" else pd.read_csv)(\n",
    "    file_mdf, dtype={\"Slide ID\": str}).rename({\n",
    "        \"Name\": col_subject, \"Inflammation\": col_inflamed}, axis=1)\n",
    "m_d.loc[:, col_condition] = m_d.apply(lambda x: \"Stricture\" if x[\n",
    "    col_stricture].lower() in [\"stricture\", \"yes\"] else x[\n",
    "        col_inflamed].capitalize(), axis=1)  # inflamation/stricture condition\n",
    "m_d.loc[:, col_sample_id] = m_d[[col_condition, col_sample_id_o]].apply(\n",
    "    \"-\".join, axis=1)\n",
    "m_d = m_d.set_index(col_sample_id)\n",
    "print(m_d[[col_subject, col_condition]].reset_index(0)[\n",
    "    col_condition].value_counts())\n",
    "# samps_paired = m_d.groupby(\"Patient\").apply(\n",
    "#     lambda x: list(x.reset_index()[col_sample_id].sort_values()) if all((\n",
    "#         i in list(x.reset_index()[col_condition]) for i in [\n",
    "#             key_uninfl, key_infl, key_stric])) else np.nan).dropna(\n",
    "#                 ).explode()\n",
    "# # m_d.reset_index().set_index([col_subject, col_condition]).sort_index()\n",
    "# samps_paired"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Paths & Options\n",
    "libids = [m_d.reset_index().set_index(\n",
    "    col_sample_id_o).loc[i][col_sample_id] for i in libs]\n",
    "col_cell_type = \"leiden_res1pt5_dist0_npc30\"  # high resolution\n",
    "\n",
    "# Spatial Data\n",
    "files = functools.reduce(lambda i, j: i + j, [[os.path.join(\n",
    "    run, i) for i in os.listdir(os.path.join(\n",
    "        dir_data, run))] for run in os.listdir(dir_data)])\n",
    "file_path = functools.reduce(\n",
    "    lambda x, y: list(x) + list(y), [np.array(files)[\n",
    "        np.where([\"-\".join(i.split(\"-\")[1:]) == os.path.basename(x).split(\n",
    "            \"__\")[2].split(\"-\")[0] for x in files])[0][0]] for i in libids])\n",
    "adatas = dict(zip(libids, [sc.read(os.path.join(\n",
    "    out_dir_objects, f\"{i}{data_suffix}.h5ad\")) for i in libids]))\n",
    "for x in adatas:\n",
    "    adatas[x].X = adatas[x].layers[layer].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Compatibility\n",
    "\n",
    "We have to re-configure a few object attributes to make it compatible with the expectations of `stlearn`, including legacy Squidpy styles of storing morphology image(s) and `stlearn`'s bespoke columns for coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Compatible with Expected Hard-Coded Columns/Attributes in stlearn Code\n",
    "# max_coor = np.max(adata.obsm[\"spatial\"])\n",
    "# scale = 2000 / max_coor\n",
    "for x in adatas:\n",
    "    adatas[x].uns[SPATIAL_KEY] = {x: {\"images\": {}}}\n",
    "scale = 1\n",
    "quality = \"hires\"\n",
    "spot_diameter_fullres = 15\n",
    "for x in adatas:\n",
    "    adatas[x].obs.loc[:, \"imagecol\"] = adatas[x].obsm[\"spatial\"][:, 0] * scale\n",
    "    adatas[x].obs.loc[:, \"imagerow\"] = adatas[x].obsm[\"spatial\"][:, 1] * scale\n",
    "    if \"scalefactors\" not in adatas[x].uns[\"spatial\"]:\n",
    "        adatas[x].uns[\"spatial\"][x][\"scalefactors\"] = {}\n",
    "        adatas[x].uns[\"spatial\"][x][\"scalefactors\"][\n",
    "            \"tissue_\" + quality + \"_scalef\"] = scale\n",
    "        adatas[x].uns[\"spatial\"][x][\"scalefactors\"][\n",
    "            \"spot_diameter_fullres\"] = spot_diameter_fullres\n",
    "        adatas[x].uns[\"spatial\"][x][\"use_quality\"] = \"hires\"\n",
    "\n",
    "# Full Resolution? (Not Compatible Yet with stlearn)\n",
    "# image_kws = {}\n",
    "# img_files = {f for f in os.listdir(img_dir) if f.endswith(\"_focus.ome.tif\")}\n",
    "# channel_names = {0: \"DAPI\"} if len(img_files) == 1 else {\n",
    "#     0: \"DAPI\", 1: \"ATP1A1/CD45/E-Cadherin\", 2: \"18S\",\n",
    "#     3: \"AlphaSMA/Vimentin\", 4: \"dummy\"}\n",
    "# image_kws[\"c_coords\"] = list(channel_names.values())\n",
    "# image_path = os.path.join(img_dir, \"morphology_focus_{:04}.ome.tif\".format(\n",
    "#     0) if len(img_files) > 1 else \"morphology_focus.ome.tif\")\n",
    "# img = imread(image_path)\n",
    "# if \"c_coords\" in image_kws and \"dummy\" in image_kws[\"c_coords\"]:\n",
    "#     img = da.concatenate([img, da.zeros_like(img[0:1])], axis=0)\n",
    "# adata.uns[\"spatial\"][library_id][\"images\"] = {\"hires\": sq.im.ImageContainer(\n",
    "#     img, library_id=library_id)}\n",
    "\n",
    "# Stlearn Way of Loading Images (Full Resolution)\n",
    "# st.add.image(adata, library_id=library_id, quality=quality,\n",
    "#              imgpath=image_path, scale=scale)\n",
    "\n",
    "# Stlearn Way of Loading Images (Not Full Resolution)\n",
    "for x in adatas:\n",
    "    max_size = np.max([adatas[x].obs[\"imagecol\"].max(),\n",
    "                       adatas[x].obs[\"imagerow\"].max()])\n",
    "    max_size = int(max_size + 0.1 * max_size)\n",
    "    img = Image.new(\"RGBA\", (max_size, max_size), (255, 255, 255, 255))\n",
    "    adatas[x].uns[\"spatial\"][x][\"images\"] = {\"hires\": np.array(img)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_lr_spatial(grid, col_cell_type, min_spots=3,\n",
    "                       do_lr=True, do_cci=True,\n",
    "                       distance=None, n_pairs=None,  # just for L-R\n",
    "                       n_perms=10000, cell_prop_cutoff=0.2,  # just for CCI\n",
    "                       resource=\"connectomeDB2020_lit\", organism=\"human\",\n",
    "                       pval_adj_cutoff=None, adj_method=None, adj_axis=\"spot\",\n",
    "                       n_jobs=1, kws_spot_grid=None, **kwargs):\n",
    "    \"\"\"Analyze ligand-receptor & cell-cell interaction with Xenium.\"\"\"\n",
    "    if kws_spot_grid not in [None, False]:  # convert Xenium->spots if need\n",
    "        grid = grid.copy()\n",
    "        kws_spot_grid = {} if kws_spot_grid is True else {**kws_spot_grid}\n",
    "        grid = create_spot_grid(grid, col_cell_type, **kws_spot_grid)  # grid\n",
    "    if do_lr is True:\n",
    "        lrs = st.tl.cci.load_lrs([resource], species=organism)  # L-R database\n",
    "        st.tl.cci.run(grid, lrs, min_spots=min_spots, distance=distance,\n",
    "                      n_pairs=n_pairs, n_cpus=n_jobs)  # analyze L-R\n",
    "        if pval_adj_cutoff is not None or adj_method is not None:  # adjust p?\n",
    "            grid.uns[\"lr_summary_preadjust\"] = grid.uns[\"lr_summary\"].copy()\n",
    "            st.tl.cci.adj_pvals(\n",
    "                grid, correct_axis=adj_axis, pval_adj_cutoff=pval_adj_cutoff,\n",
    "                adj_method=adj_method)  # optionally, adjust p-values\n",
    "        print(grid.uns[\"lr_summary\"])\n",
    "    if do_cci is True:\n",
    "        st.tl.cci.run_cci(grid, col_cell_type, min_spots=min_spots,\n",
    "                          cell_prop_cutoff=cell_prop_cutoff, n_cpus=n_jobs,\n",
    "                          n_perms=n_perms, **kwargs)  # cell-cell interaction\n",
    "    return grid\n",
    "\n",
    "\n",
    "def create_spot_grid(adata, col_cell_type, n_spots, layer=\"counts\", n_jobs=1,\n",
    "                     title=\"Grid Label Transfer\", cmap=None, kws_plot=True):\n",
    "    \"\"\"Create Visium-like data from Xenium data.\"\"\"\n",
    "    print(f\"\\n\\n{n_spots} by {n_spots} has {n_spots * n_spots} spots\\n\\n\")\n",
    "    if kws_plot is True:  # if no keywords to pass but still want plotting\n",
    "        kws_plot = {}\n",
    "    if layer is not None:\n",
    "        adata.X = adata.layers[layer].copy()\n",
    "    st.pp.normalize_total(adata)  # total count-normalize\n",
    "    grid = st.tl.cci.grid(adata, n_row=n_spots, n_col=n_spots,\n",
    "                          use_label=col_cell_type, n_cpus=n_jobs)\n",
    "    props = grid.obs[col_cell_type].rename_axis(\"Spot\").to_frame(\n",
    "        \"Label\").join(grid.uns[col_cell_type]).set_index(\n",
    "            \"Label\", append=True).rename_axis(col_cell_type, axis=1).stack()\n",
    "    grid.uns[f\"stlearn_label_transfer_{col_cell_type}\"] = props.to_frame(\n",
    "        \"Proportion\")  # store proportions of original labels in grid labels\n",
    "    if kws_plot not in [None, False]:  # plot label transfer; adata vs. grid\n",
    "        f_s, kws_transfer = kws_plot.pop(\"figsize\", None), {}\n",
    "        rename_dict = kws_plot.pop(\"rename_dict\", None)\n",
    "        for k in [\"original_order\", \"transfer_order\"]:\n",
    "            kws_transfer[x] = kws_plot.pop(x, None)\n",
    "        fig, axes = plt.subplots(ncols=2, figsize=f_s if f_s else (20, 8))\n",
    "        for i, a in enumerate([grid, adata]):\n",
    "            plot_space(a, col_cell_type, cmap=cmap, fig=fig, axes=axes[i],\n",
    "                       titles=[col_cell_type, \"Grid (Dominant Spots)\"][i],\n",
    "                       show=False, **kws_plot)  # plot adata or grid\n",
    "        fig.suptitle(title)\n",
    "        plt.show()\n",
    "        plot_label_transfer_stlearn(grid, col_cell_type, **kws_transfer)\n",
    "        if rename_dict is not None:  # optionally also plot ~ renamed clusters\n",
    "            plot_label_transfer_stlearn(\n",
    "                grid, col_cell_type, rename_dict=rename_dict, **kws_transfer)\n",
    "    else:\n",
    "        fig, axes = None, None\n",
    "    return grid, (fig, axes)\n",
    "\n",
    "\n",
    "def plot_space(grid, color, groups=None,\n",
    "               cmap=None, size=10, figsize=None, show=True,\n",
    "               fig=None, axes=None, titles=None, suptitle=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Plot data in spatial coordinates (alternative, stlearn way).\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    For additional options for plotting keyword arguments to pass,\n",
    "    https://stlearn.readthedocs.io/en/latest/\\\n",
    "        stlearn.pl.cluster\n",
    "    \"\"\"\n",
    "    color = [color] if isinstance(color, str) else list(color)  # color by\n",
    "    titles = [titles] * len(color) if isinstance(\n",
    "        titles, str) else color if titles is None else list(titles)  # title\n",
    "    if groups is not None:\n",
    "        kwargs.update({\"list_clusters\": groups})  # only plot certain groups\n",
    "    if axes is None:  # determine rows & columns\n",
    "        nrows = kwargs.pop(\"nrows\", 1 if len(color) == 1 else int(\n",
    "            np.sqrt(len(color))))\n",
    "        ncols = kwargs.pop(\"ncols\", 2 if len(color) == 2 else math.ceil(\n",
    "            len(color) / nrows) if nrows * 2 != len(color) else nrows)\n",
    "        fig, axes = plt.subplots(nrows, ncols, squeeze=False,\n",
    "                                 figsize=figsize if figsize else (20, 8))\n",
    "        axes = axes.flatten()\n",
    "    if not isinstance(axes, (list, np.ndarray)):\n",
    "        axes = [axes]\n",
    "    for i, c in enumerate(color):\n",
    "        c_m = cmap if cmap else \"default_102\" if len(\n",
    "            grid.obs[c].unique()) > 40 else \"jana_40\" if len(\n",
    "                grid.obs[c].unique()) > 28 else 28 if len(\n",
    "                    grid.obs[c].unique()) > 20 else \"default\"  # cmap\n",
    "        st.pl.cluster_plot(grid, use_label=c, cmap=c_m, size=size, fig=fig,\n",
    "                           ax=axes[i], show_plot=False, **kwargs)\n",
    "        axes[i].set_title(titles[i])\n",
    "    if suptitle is not None:\n",
    "        fig.suptitle(suptitle)\n",
    "    if show is True:\n",
    "        plt.show()\n",
    "    return fig, axes\n",
    "\n",
    "\n",
    "def plot_label_transfer_stlearn(grid, col_cell_type, title=\"Label Transfer\",\n",
    "                                original_order=None, transfer_order=None,\n",
    "                                rename_dict=None, **kwargs):\n",
    "    dots_df = grid.uns[f\"stlearn_label_transfer_{col_cell_type}\"][\n",
    "        \"Proportion\"].unstack(col_cell_type)\n",
    "    if rename_dict is not None:\n",
    "        dots_df.columns = [rename_dict[v] if v in rename_dict else v\n",
    "                           for v in dots_df.columns]\n",
    "        dots_df = dots_df.rename(rename_dict, axis=0, level=1)\n",
    "    dots_df.columns = dots_df.columns.astype(str)\n",
    "    dots_df = dots_df.reset_index().astype({\n",
    "        dots_df.index.names[1]: \"string\"}).set_index(dots_df.index.names)\n",
    "    if transfer_order is None:\n",
    "        transfer_order = list(pd.unique(dots_df.reset_index()[\n",
    "        dots_df.index.names[1]]))\n",
    "    dots_df = dots_df.loc[:, transfer_order]\n",
    "    if isinstance(original_order, str) and original_order == \"same\":\n",
    "        original_order = transfer_order\n",
    "    if original_order is not None:\n",
    "        dots_df = dots_df[original_order]\n",
    "    ann = sc.AnnData(\n",
    "        dots_df.reset_index(1, drop=True),\n",
    "        dots_df.reset_index(1, drop=True).index.to_frame(),\n",
    "        dots_df.columns.to_frame())\n",
    "    ann.obs.loc[:, \"Label\"] = list(dots_df.reset_index()[\n",
    "        dots_df.index.names[1]])\n",
    "    # if rename_dict is not None:\n",
    "    #     ann.obs.loc[:, \"Label\"] = ann.obs[\"Label\"].replace(rename_dict)\n",
    "    #     ann.var_names = [rename_dict[v] for v in ann.var_names]\n",
    "    ann.var_names_make_unique()\n",
    "    fig = sc.pl.dotplot(ann, list(dots_df.columns), \"Label\", title=title,\n",
    "                        categories_order=transfer_order, **kwargs)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def write_grid(grid, out_file):\n",
    "    \"\"\"Write grid object (removing un-writeable attributes).\"\"\"\n",
    "    grid = grid.copy()  # so not modified in-place\n",
    "    if \"lrfeatures\" in grid.uns:\n",
    "        grid.uns[\"lrfeatures\"] = grid.uns[\"lrfeatures\"].astype(float)\n",
    "    for e in [\"lrfeatures\", \"lr_summary\", \"lr_summary_preadjust\"]:\n",
    "        if e in grid.uns:  # avoid write errors\n",
    "            ix_o = grid.uns[e].index.names\n",
    "            ixs = [u if u else \"ix\" for u in ix_o]  # rename \"None\"\n",
    "            grid.uns[e] = grid.uns[e].rename_axis(ixs).reset_index()\n",
    "            for k in ixs:\n",
    "                grid.uns[e] = grid.uns[e].astype({k: str})\n",
    "            grid.uns[e] = grid.uns[e].set_index(ixs).rename_axis([\n",
    "                u if u else \"i\" for u in ix_o])\n",
    "    _ = grid.uns.pop(f\"stlearn_label_transfer_{col_cell_type}\", None)\n",
    "    grid.write_h5ad(out_file)  # write object\n",
    "\n",
    "\n",
    "def read_grid(file_path, col_cell_type):\n",
    "    \"\"\"Re-load gridded object & add back un-writeable attributes.\"\"\"\n",
    "    grid = sc.read(file_path)\n",
    "    for e in [\"lrfeatures\", \"lr_summary\", \"lr_summary_preadjust\"]:\n",
    "        if e in grid.uns:  # revert changes that avoided write errors\n",
    "            grid.uns[e] = grid.uns[e].rename_axis([None if (\n",
    "                u == \"i\") else u for u in grid.uns[e].index.names])\n",
    "    if f\"stlearn_label_transfer_{col_cell_type}\" not in grid.uns:\n",
    "        props = grid.obs[col_cell_type].rename_axis(\"Spot\").to_frame(\n",
    "            \"Label\").join(grid.uns[col_cell_type]).set_index(\n",
    "                \"Label\", append=True).rename_axis(\n",
    "                    col_cell_type, axis=1).stack().to_frame(\"Proportion\")\n",
    "        grid.uns[f\"stlearn_label_transfer_{col_cell_type}\"] = props\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create or Load Grids \n",
    "\n",
    "`stlearn` can create Visum-like data from Xenium data by aggregating the single cells into larger \"spots\" (reducing the resolution) and performing label transfer to annotate the cells according to the dominant cluster/cell type in that spot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Options\n",
    "grids = {}\n",
    "plot = False\n",
    "\n",
    "# Re-Load Instead of Running\n",
    "if load_suffix not in [None, False]:\n",
    "    for x in libids:\n",
    "        grids[x] = read_grid(os.path.join(\n",
    "            out_dir, f\"{x}_stlearn{load_suffix}.h5ad\"), col_cell_type)\n",
    "        # _ = grids[x].uns.pop(col_cell_type + \"_colors\", None)\n",
    "        # _ = adatas[x].uns.pop(col_cell_type + \"_colors\", None)\n",
    "        if plot is True:\n",
    "            fig, axes = plt.subplots(ncols=2, figsize=(20, 8))\n",
    "            for i, a in enumerate([grids[x], adatas[x]]):\n",
    "                plot_space(a, col_cell_type, fig=fig, axes=axes[i],\n",
    "                           show=False, cmap=\"jana_40\", titles=[\n",
    "                               \"Grid (Dominant Spots)\", col_cell_type][i])\n",
    "        plt.show()\n",
    "    if plot is True:\n",
    "        for x in grids:\n",
    "            cutoff = 0.15\n",
    "            plot_label_transfer_stlearn(\n",
    "                grids[x], col_cell_type, original_order=\"same\",\n",
    "                title=f\"{x}\\nLabel Transfer\\n(Cutoff = {cutoff * 100})\",\n",
    "                expression_cutoff=cutoff)\n",
    "\n",
    "# Run Gridding\n",
    "else:\n",
    "    for x in adatas:\n",
    "        n_s = n_spots if isinstance(n_spots, (int, float)) else np.sqrt(float(\n",
    "            n_spots.split(\"%\")[0]) / 100 * adatas[x].n_obs)  # constant or %\n",
    "        grids[x], _ = create_spot_grid(\n",
    "            adatas[x], col_cell_type, int(n_s), cmap=\"jana_40\", n_jobs=n_jobs,\n",
    "            title=x, kws_plot=None)  # grid the single-cell resolution data\n",
    "        grids[x].obs.loc[:, \"n_spots\"] = n_s if isinstance(n_spots, (\n",
    "            int, float)) else f\"{n_s} ({n_spots})\"  # store n_spots argument\n",
    "        if write_suffix not in [None, False]:\n",
    "            write_grid(grids[x], os.path.join(\n",
    "                out_dir, f\"{x}_stlearn{write_suffix}.h5ad\"))  # write object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See Label Transfer Proportions for Given Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in grids:\n",
    "#     grid = grids[x].copy()\n",
    "#     for g in grid.obs[col_cell_type].unique():  # iterate clusters\n",
    "#         grid.obs[f\"stlearn_{col_cell_type}_transfer\"] = grid.uns[\n",
    "#             col_cell_type][g].values\n",
    "#         st.pl.feat_plot(grid, feature=f\"stlearn_{col_cell_type}_transfer\",\n",
    "#                         show_plot=True, vmax=1, show_color_bar=False,\n",
    "#                         title=f\"{x}\\n\\nCluster {g} Grid Proportions (Max=1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot by Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in libids:\n",
    "#     f_n = f\"{x}___{col_cell_type}_dictionary.xlsx\"\n",
    "#     if f_n not in list(annotations[[c_m]].dropna().reset_index(0)[\n",
    "#             annotations.index.names[0]]):\n",
    "#         ccc = col_cell_type\n",
    "#         print(f\"\\n\\nNo annotations for {x}\\n\\n\")\n",
    "#     else:\n",
    "#         grids[x].obs.loc[:, c_m] = grids[x].obs[col_cell_type].astype(\n",
    "#             \"string\").replace(dict(annotations.loc[f_n][c_m])).astype(\n",
    "#                 \"category\")\n",
    "#         adatas[x].obs.loc[:, c_m] = adatas[x].obs[col_cell_type].astype(\n",
    "#             \"string\").replace(dict(\n",
    "#                 annotations.loc[f_n][c_m])).astype(\"category\")\n",
    "#         fig, axes = plt.subplots(ncols=2, figsize=(20, 8))\n",
    "#         ccc = c_m\n",
    "#     for i, a in enumerate([grids[x], adatas[x]]):\n",
    "#         plot_space(a, ccc, fig=fig, axes=axes[i],\n",
    "#                    show=False, cmap=\"jana_40\",\n",
    "#                    titles=[col_cell_type, \"Grid (Dominant Spots)\"][i])\n",
    "#     plt.show()\n",
    "#     plot_label_transfer_stlearn(grids[x], col_cell_type, rename_dict=dict(\n",
    "#         annotations.loc[f_n][ccc]), title=f\"{x}: Label Transfer\",\n",
    "#                                 expression_cutoff=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Cell Types Individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in grids[x]:\n",
    "#     groups = list(grids[x].obs[col_cell_type].cat.categories)\n",
    "#     for g in groups:\n",
    "#         fig, axes = plt.subplots(ncols=3, figsize=(20, 8))\n",
    "#         group_props = grids[x].uns[col_cell_type][g].values\n",
    "#         grids[x].obs.loc[:, \"Group\"] = group_props\n",
    "#         st.pl.feat_plot(grids[x], feature=\"Group\", ax=axes[0],\n",
    "#                         show_plot=False, vmax=1, show_color_bar=False)\n",
    "#         st.pl.cluster_plot(grids[x], use_label=col_cell_type,\n",
    "#                            list_clusters=[g], ax=axes[1], show_plot=False)\n",
    "#         st.pl.cluster_plot(grids[x], use_label=col_cell_type,\n",
    "#                            list_clusters=[g], ax=axes[2], show_plot=False)\n",
    "#         axes[0].set_title(f\"Grid {g} Proportions (Maximum = 1)\")\n",
    "#         axes[1].set_title(f\"Grid {g} Maximum Spots\")\n",
    "#         axes[2].set_title(f\"Individual Cell {g}\")\n",
    "#         fig.suptitle(x)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Number of Neighbors Given Different Distance Parameters\n",
    "\n",
    "Per https://github.com/BiomedicalMachineLearning/stLearn/issues/186#issuecomment-1238036775\n",
    "\n",
    "If distance is set to \"auto\" in the options cell earlier, then this dataframe will be used to set object/sample-specific distance parameters according to the `min_med_neighbors` parameter (i.e., will use the minimum distance that yields at least that specified number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = {}\n",
    "for d in np.arange(0, 301, 10):\n",
    "    nnb = {}\n",
    "    for x in grids:\n",
    "        point_tree = spatial.cKDTree(grids[x].obs[[\"imagerow\", \"imagecol\"]])\n",
    "        nnb[x] = point_tree.query_ball_point(point_tree.data[0], d)\n",
    "    neighbors[d] = pd.Series([len(nnb[i]) for i in nnb], index=pd.Index(\n",
    "        grids.keys(), name=col_sample_id))\n",
    "neighbors = pd.concat(neighbors, names=[\"Distances\"]).unstack(col_sample_id)\n",
    "sb.relplot(neighbors.stack().to_frame(\"Number of Neighbors\"), kind=\"line\",\n",
    "           hue=col_sample_id, x=\"Distances\", y=\"Number of Neighbors\")\n",
    "neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "**Important Input**\n",
    "\n",
    "`adj_axis`: Per `stlearn` documentation: \"adjusting by no. of LRs tested per spot (LR), no. of spots tested per LR (spot), or no adjustment (None)\".\n",
    "\n",
    "`distance`: Per author on `stlearn` GitHub: Distance is the \"pixel length as the radius from each spot center. We will query all the spots within that radius.\" Also see https://github.com/BiomedicalMachineLearning/stLearn/issues/199#issuecomment-1272672934.\n",
    "\n",
    "**Important Output**\n",
    "\n",
    "`grid.uns[\"lr_summary\"]`: Summarizes results for each ligand-receptor pair (number of spots with L-R, number of significant spots, and p-values).\n",
    "\n",
    "`grid.obsm[\"lr_scores\"]`: Ligand-receptor pair scores.\n",
    "\n",
    "`grid.obsm[\"lr_sig_scores\"]`: Rows = spots and columns = ligand-receptor pairs. Per `stLearn` GitHub issue, \"Positive values in this matrix indicate significance of the LR in the respective spot (non-significant spots are set to zero).\" It has the same index as in `grid.uns[\"lr_summary\"]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run L-R & CCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "load = load_suffix not in [None, False]\n",
    "distances = {}\n",
    "for p in [[True, False]]:  # just L-R analyses\n",
    "# for p in [[True, False], [False, True]]:  # iterate L-R, CCI analyses\n",
    "    print(f\"\\n\\n{'=' * 80}\\n{'L-R' if p[0] else 'CCI'}\\n{'=' * 80}\\n\\n\")\n",
    "    for x in grids:  # iterate samples\n",
    "        print(f\"\\n\\n{'*' * 40}\\n{x}\\n{'*' * 40}\\n\\n\")\n",
    "\n",
    "        # Re-Load Past Results if Already Done\n",
    "        if \"lrfeatures\" in grids[x].uns and p[0] is True and load is True:\n",
    "            distances[x] = grids[x].obs.loc[:, \"distance\"].iloc[0]\n",
    "            print(grids[x].uns[\"lr_summary\"])\n",
    "            continue\n",
    "        if f\"lr_cci_{col_cell_type}\" in grids[x].uns and (\n",
    "                p[1] is True and load is True):\n",
    "            print(f\"Results stored in `.uns['lr_cci_{col_cell_type}']`\")\n",
    "            continue\n",
    "\n",
    "        # Store Distance & Other Options\n",
    "        ddd = min(neighbors[x].index.values[np.where(np.array(\n",
    "            neighbors[x].apply(lambda y: y >= min_med_neighbors)))[0]]\n",
    "                  )  # least distance >= specified # of median neighbors\n",
    "        distances[x] = ddd if distance == \"auto\" else distance  # auto vs. #\n",
    "        grids[x].obs.loc[:, \"min_med_neighbors\"] = min_med_neighbors if (\n",
    "            distance == \"auto\") else np.nan  # store option to choose distance\n",
    "        kws = dict(distance=distances[x], min_spots=min_spots,\n",
    "                   n_pairs=n_pairs,\n",
    "                   adj_method=adj_method, adj_axis=adj_axis,\n",
    "                   pval_adj_cutoff=pval_adj_cutoff,\n",
    "                   cell_prop_cutoff=cell_prop_cutoff, n_perms=n_perms,\n",
    "                   organism=organism, resource=resource)\n",
    "        if p[0] is True:\n",
    "            print(f\"n_pairs = {n_pairs}; distance = {distances[x]}\")\n",
    "        for v in kws:  # store keyword arguments in .obs\n",
    "            grids[x].obs.loc[:, v] = str(kws[v])\n",
    "        grids[x] = analyze_lr_spatial(grids[x], col_cell_type, n_jobs=n_jobs,\n",
    "                                      do_lr=p[0], do_cci=p[1], **kws)\n",
    "        if write_suffix not in [None, False]:\n",
    "            grid = grids[x].copy()\n",
    "            for e in grid.uns[\"lrfeatures\"]:\n",
    "                grid.uns[\"lrfeatures\"][e] = grid.uns[\"lrfeatures\"][\n",
    "                    e].astype(np.float64)  # avoid write error\n",
    "            grid.uns[\"lrfeatures\"] = grids[x].uns[\n",
    "                \"lrfeatures\"].astype(np.float64)  # avoid write error\n",
    "            for e in [\"lrfeatures\", \"lr_summary\", \"lr_summary_preadjust\"]:\n",
    "                if e in grid.uns:  # avoid write errors\n",
    "                    ix_o = grid.uns[e].index.names\n",
    "                    ixs = [u if u else \"ix\" for u in ix_o]  # rename \"None\"\n",
    "                    grid.uns[e] = grid.uns[e].rename_axis(ixs).reset_index()\n",
    "                    for k in ixs:\n",
    "                        grid.uns[e] = grid.uns[e].astype({k: str})\n",
    "                    grid.uns[e] = grid.uns[e].set_index(ixs).rename_axis([\n",
    "                        u if u else \"i\" for u in ix_o])\n",
    "            _ = grid.uns.pop(f\"stlearn_label_transfer_{col_cell_type}\", None)\n",
    "            grid.write_h5ad(os.path.join(\n",
    "                out_dir, f\"{x}_stlearn{write_suffix}.h5ad\"))  # write object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = pd.concat([grids[x].uns[\"lr_summary\"] for x in grids],\n",
    "                      keys=grids.keys(), names=[col_sample_id, \"L-R\"])\n",
    "lr_sig_df = pd.concat([pd.DataFrame(\n",
    "    grids[x].obsm[\"lr_sig_scores\"], index=grids[x].obs_names.values,\n",
    "    columns=grids[x].uns[\"lr_summary\"].index.values) for x in grids],\n",
    "                      keys=grids.keys(), names=[col_sample_id, \"L-R\"])\n",
    "summaries = summaries.assign(Ratio=summaries.n_spots_sig / summaries.n_spots)\n",
    "summaries = summaries.join(m_d[[col_subject, col_condition]])  # join metadata\n",
    "summaries = summaries.join(pd.Series([\n",
    "    grids[x].n_obs for x in grids], index=pd.Index(\n",
    "        grids, name=col_sample_id)).to_frame(\"N Spots (Sample)\"))\n",
    "summaries.loc[:, \"Ratio (Significant Spots to N Spots Sample)\"] = (\n",
    "    summaries[\"n_spots_sig\"] /  summaries[\"N Spots (Sample)\"])\n",
    "summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summaries.to_excel(\"/home/{os.getlogin()}/projects/csf2rb/analysis/\"\n",
    "#                    f\"stlearn_summary_lr{write_suffix}.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Plots (DON'T RUN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot by Patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    x = \"_mucosa\"\n",
    "    ppp = [\"CSF1_CSF1R\", \"CSF2_CSF2RB\", \"CSF2_CSF2RA\", \"IL22_IL10RB\",\n",
    "           \"OSM_IL6ST\", \"IL1B_IL1R2\", \"IL34_CSF1R\", \"IL6_IL6ST\", \"PLAU_PLAUR\"]\n",
    "    sums = pd.read_excel(\"/home/elizabeth/elizabeth/projects/csf2rb/analysis/\"\n",
    "                         f\"stlearn_summary_lr{x}_hires_hipair_hiperm.xlsx\",\n",
    "                         index_col=[0, 1])\n",
    "    sums = sums.set_index([col_condition, col_subject], append=True)[[\n",
    "        \"Ratio (Significant Spots to N Spots Sample)\"]].rename({\n",
    "            \"Ratio (Significant Spots to N Spots Sample)\": \"Of Sample Total\"\n",
    "            }, axis=1).rename_axis(\n",
    "                \"Denominator\", axis=1).stack().to_frame(\"Ratio\")\n",
    "    fig = sb.catplot(sums.loc[:, ppp, :].reset_index(),\n",
    "                     margin_titles=True, kind=\"bar\",\n",
    "                     x=col_subject, y=\"Ratio\", palette=[\"r\", \"b\"],\n",
    "                     hue=col_condition, hue_order=[key_infl, key_uninfl],\n",
    "                     sharey=False, col=\"L-R\", col_wrap=3)\n",
    "    fig.figure.suptitle(\"_\".join(x.split(\"_\")[1:]))\n",
    "    fig.figure.tight_layout()\n",
    "    plt.subplots_adjust(right=0.95)\n",
    "    fig = sb.catplot(sums.loc[:, ppp, :].reset_index(),  # kind=\"bar\",\n",
    "                     margin_titles=True, kind=\"violin\", cut=0,\n",
    "                     x=col_condition, y=\"Ratio\", palette=[\"r\", \"b\"],\n",
    "                     hue=col_condition, hue_order=[key_infl, key_uninfl],\n",
    "                     sharey=False, col=\"L-R\", col_wrap=5)\n",
    "    fig.figure.suptitle(\"_\".join(x.split(\"_\")[1:]))\n",
    "    fig.figure.tight_layout()\n",
    "    plt.subplots_adjust(right=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    x = \"_mucosa\"\n",
    "    sums = pd.read_excel(\"/home/elizabeth/elizabeth/projects/csf2rb/analysis/\"\n",
    "                         f\"stlearn_summary_lr{x}_hires_hipair_hiperm.xlsx\",\n",
    "                         index_col=[0, 1])\n",
    "    sums = sums.set_index([col_condition, col_subject], append=True)[[\n",
    "        \"Ratio (Significant Spots to N Spots Sample)\", \"Ratio\"]].rename({\n",
    "            \"Ratio (Significant Spots to N Spots Sample)\": \"Of Sample Total\",\n",
    "            \"Ratio\": \"L-R Total\"}, axis=1).rename_axis(\n",
    "                \"Denominator\", axis=1).stack().to_frame(\"Ratio\")\n",
    "    fig = sb.catplot(sums.loc[:, plot_lr, :].reset_index(),\n",
    "                     margin_titles=True, kind=\"bar\",\n",
    "                     x=col_subject, y=\"Ratio\", palette=[\"r\", \"b\"],\n",
    "                     hue=col_condition, hue_order=[key_infl, key_uninfl],\n",
    "                     sharey=False, col=\"L-R\", row=\"Denominator\")\n",
    "    fig.figure.suptitle(\"_\".join(x.split(\"_\")[1:]))\n",
    "    fig.figure.tight_layout()\n",
    "    fig = sb.catplot(sums.loc[:, plot_lr, :].reset_index(),  # kind=\"bar\",\n",
    "                     margin_titles=True, kind=\"violin\", cut=0,\n",
    "                     x=col_condition, y=\"Ratio\", palette=[\"r\", \"b\"],\n",
    "                     hue=col_condition, hue_order=[key_infl, key_uninfl],\n",
    "                     sharey=False, col=\"L-R\", row=\"Denominator\")\n",
    "    fig.figure.suptitle(\"_\".join(x.split(\"_\")[1:]))\n",
    "    fig.figure.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in [\"\", \"_mucosa\", \"_mucosa_CSF2\"]:\n",
    "    sums = pd.read_excel(\"/home/elizabeth/elizabeth/projects/csf2rb/analysis/\"\n",
    "                         f\"stlearn_summary_lr{x}_hires_hipair_hiperm.xlsx\",\n",
    "                         index_col=[0, 1])\n",
    "    sums = sums.set_index([col_condition, col_subject], append=True)[[\n",
    "        \"Ratio (Significant Spots to N Spots Sample)\", \"Ratio\"]].rename({\n",
    "            \"Ratio (Significant Spots to N Spots Sample)\": \"Of Sample Total\",\n",
    "            \"Ratio\": \"L-R Total\"}, axis=1).rename_axis(\n",
    "                \"Denominator\", axis=1).stack().to_frame(\"Ratio\")\n",
    "    fig = sb.catplot(sums.loc[:, plot_lr, :].reset_index(),\n",
    "                     margin_titles=True, kind=\"bar\",\n",
    "                     x=col_subject, y=\"Ratio\", palette=[\"r\", \"b\"],\n",
    "                     hue=col_condition, hue_order=[key_infl, key_uninfl],\n",
    "                     sharey=False, col=\"L-R\", row=\"Denominator\")\n",
    "    fig.figure.suptitle(\"_\".join(x.split(\"_\")[1:]))\n",
    "    fig.figure.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in [\"\", \"_mucosa\", \"_mucosa_CSF2\"]:\n",
    "    sums = pd.read_excel(\"/home/elizabeth/elizabeth/projects/csf2rb/analysis/\"\n",
    "                         f\"stlearn_summary_lr{x}_hires_hipair_hiperm.xlsx\",\n",
    "                         index_col=[0, 1])\n",
    "    sums = sums.set_index(col_condition, append=True)[[\n",
    "        \"Ratio (Significant Spots to N Spots Sample)\", \"Ratio\"]].rename({\n",
    "            \"Ratio (Significant Spots to N Spots Sample)\": \"Of Sample Total\",\n",
    "            \"Ratio\": \"L-R Total\"}, axis=1).rename_axis(\n",
    "                \"Denominator\", axis=1).stack().to_frame(\"Ratio\")\n",
    "    fig = sb.catplot(sums.loc[:, plot_lr, :].reset_index(),  # kind=\"bar\",\n",
    "                     margin_titles=True, kind=\"violin\", cut=0,\n",
    "                     x=col_condition, y=\"Ratio\", palette=[\"r\", \"b\"],\n",
    "                     hue=col_condition, hue_order=[key_infl, key_uninfl],\n",
    "                     sharey=False, col=\"L-R\", row=\"Denominator\")\n",
    "    fig.figure.suptitle(\"_\".join(x.split(\"_\")[1:]))\n",
    "    fig.figure.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-Analysis (DON'T RUN)\n",
    "\n",
    "Per `stlearn` author [here](https://github.com/BiomedicalMachineLearning/stLearn/issues/185):\n",
    "> use compositional data analysis (CoDa, Tom Quinn @tpq has alot of good papers/reviews on this, e.g. review) on the ratios, (number of sig spots/ total spots), for each sample. \n",
    "> \n",
    "> transform the ratios from Atchison geomety to euclidean geometry using the centred-log-ratio (clr) transformation (available in scikit-bio)\n",
    "> \n",
    ">  perform independent Welch's t-test using scipy on the clrs between conditions, or other statistical tests (e.g. ANOVA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvls = [key_uninfl, key_infl, key_stric] if (key_stric in list(\n",
    "    summaries.reset_index()[col_condition])) else [key_uninfl, key_infl]\n",
    "fig, axes = plt.subplots(len(lvls), 1, squeeze=False)\n",
    "axes_dict = {key_infl: 0, key_uninfl: 1, key_stric: 2}\n",
    "for x in grids:  # plot L-R ranks for all\n",
    "    st.pl.lr_summary(grid, n_top=n_top, ax=axes.flatten()[\n",
    "        axes_dict[m_d.loc[x][col_condition]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvls = [key_uninfl, key_infl, key_stric] if (key_stric in list(\n",
    "    summaries.reset_index()[col_condition])) else [key_uninfl, key_infl]\n",
    "r_dict = {key_infl: 0, key_uninfl: 1, key_stric: 2}\n",
    "c_dict = dict(zip(summaries.reset_index()[col_subject].unique(), np.arange(\n",
    "    len(summaries.reset_index()[col_subject].unique()) + 1)))\n",
    "for p in plot_lr:\n",
    "    fig, axes = plt.subplots(len(lvls), len(summaries.reset_index()[\n",
    "        col_subject].unique()), squeeze=False)\n",
    "    for i, x in enumerate(grids):  # plot L-R ranks for all\n",
    "        st.pl.lr_plot(grid, p, \"lr_scores\", fig=fig, title=p,\n",
    "                      ax=axes[r_dict[m_d.loc[x][col_condition]],\n",
    "                              c_dict[m_d.loc[x][col_subject]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.catplot(summaries.loc[:, plot_lr, :].reset_index(), x=\"L-R\", y=\"Ratio\",\n",
    "           hue=col_condition, palette=[\"b\", \"r\", \"y\"],\n",
    "           hue_order=lvls, kind=\"violin\", cut=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_lrs = [x for x in summaries.reset_index()[\"L-R\"].unique() if any(\n",
    "    (any((j in x for j in i.split(\"_\"))) for i in plot_lr))]\n",
    "lmods = {}\n",
    "\n",
    "for g in plot_lr:\n",
    "    sums = summaries.loc[:, g, :].set_index([\n",
    "        col_subject, col_condition])[[\"Ratio\"]]\n",
    "    reps = {}\n",
    "    for x in summaries.loc[:, g, :].set_index([\n",
    "            col_subject, col_condition]).index:\n",
    "        if x in sums.index and sums.loc[x].shape[\n",
    "                0] > 1:  # distinguish subject-condition replicates index\n",
    "            rep_ids = [f\"{s}-{i}\"for i, s in enumerate(\n",
    "                sums.loc[x].reset_index()[col_subject])]\n",
    "            sums = pd.concat([sums.drop(x), sums.loc[x].assign(\n",
    "                subj=rep_ids).reset_index(0, drop=True).rename({\n",
    "                        \"subj\": col_subject}, axis=1).reset_index().set_index(\n",
    "                            sums.index.names)])\n",
    "            reps[x] = rep_ids\n",
    "    if len(reps) > 0 and sums[\"Ratio\"].unstack(col_condition).apply(\n",
    "        lambda x: x.isnull()).any().any():\n",
    "            for k in reps:\n",
    "                if k[0] in sums.reset_index()[col_subject].unique(\n",
    "                    ):  # if different subject-condition only had 1 replicate\n",
    "                    sums = sums.rename({k[0]: reps[k][0]}\n",
    "                                )  # unstack with 1st replicate\n",
    "    sums = sums[\"Ratio\"].unstack(col_condition)\n",
    "    # print(sums)\n",
    "    lmods[g] = scipy.stats.ttest_rel(np.array(sums)[0], np.array(sums)[1],\n",
    "                                     nan_policy=\"omit\")\n",
    "    # lmods[g] = scipy.stats.ttest_ind(np.array(sums)[0], np.array(sums)[1],\n",
    "    #                                  nan_policy=\"omit\", equal_var=False)\n",
    "res_t = pd.concat([pd.Series([lmods[g].statistic, lmods[g].pvalue, lmods[\n",
    "    g].confidence_interval(), lmods[g].df], index=[\"T\", \"P\", \"CI\", \"DF\"])\n",
    "                   for g in lmods], keys=lmods, names=[\"Gene\"]).unstack(1)\n",
    "# res_t = pd.concat([pd.Series([lmods[g].statistic, lmods[g].pvalue], index=[\n",
    "#     \"T\", \"P\"]) for g in lmods], keys=lmods, names=[\"Gene\"]).unstack(1)\n",
    "res_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (M)LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in summaries.reset_index()[col_sample_id].unique():\n",
    "    summaries.loc[x, \"Centered_Log_Ratio\"] = clr(\n",
    "        np.array(summaries.loc[x].Ratio.replace(\n",
    "            0, 1e-100)))  # replace 0 with small #; transform spot ratios\n",
    "lvls = [key_uninfl, key_infl, key_stric] if (key_stric in list(\n",
    "    summaries.reset_index()[col_condition])) else [key_uninfl, key_infl]\n",
    "mod_lrs = [x for x in summaries.reset_index()[\"L-R\"].unique() if any(\n",
    "    (any((j in x for j in i.split(\"_\"))) for i in plot_lr))]\n",
    "lmods = {}\n",
    "for g in mod_lrs:\n",
    "# or g in summaries.reset_index()[\"L-R\"].unique():\n",
    "    print(f\"\\n\\n{'=' * 80}\\n{g}\\n{'=' * 80}\\n\\n\")\n",
    "    lmods[g] = Lmer(\n",
    "        f\"Centered_Log_Ratio ~ C({col_condition}) + (1 | {col_subject})\",\n",
    "        data=summaries.loc[:, g, :].replace(\n",
    "            np.inf, np.nan).reset_index().dropna())\n",
    "    # lmods[g] = Lm(\n",
    "    #     f\"Centered_Log_Ratio ~ C({col_condition})\",\n",
    "    #     data=summaries.loc[:, g, :].replace(\n",
    "    #         np.inf, np.nan).reset_index().dropna())\n",
    "    print(lmods[g].fit(factors={col_condition: lvls}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spatial_lr(grid, col_cell_type, kind=\"results\", figsize=None,\n",
    "                    sig_spots=False, sig_cci=True, show_arrows=True,\n",
    "                    stats=None, plot_lr=3, n_top=50, min_total=100,\n",
    "                    plot_cci=True, **kwargs):\n",
    "    \"\"\"Plot QC & results from spatial LR & CCI analysis.\"\"\"\n",
    "    figs = {}\n",
    "    f_s = (12, 6) if figsize is None else figsize\n",
    "    if stats is None:\n",
    "        # stats = [\"lr_scores\", \"p_vals\", \"p_adjs\", \"-log10(p_adjs)\"]\n",
    "        stats = [\"lr_scores\", \"p_vals\", \"p_adjs\"]\n",
    "    kind_all = [\"qc\", \"results\", \"arrow\", \"map\", \"net\", \"chord\"]\n",
    "    kind = [kind_all if kind.lower() == \"all\" else kind.lower()] if (\n",
    "        isinstance(kind, str)) else [k.lower() for k in kind]\n",
    "    if plot_lr not in [False, None]:\n",
    "        plot_lr = [plot_lr] if isinstance(plot_lr, str) else grid.uns[\n",
    "            \"lr_summary\"].index.values[:int(plot_lr)] if isinstance(plot_lr, (\n",
    "                int, float)) else list(plot_lr)  # use top N (plot_lr)\n",
    "        ncols = 3 if len(plot_lr) > 3 else len(plot_lr)  # L-R facets (row)\n",
    "        nrows = int(len(plot_lr) / ncols) if ncols > 1 else 1  # L-R columns\n",
    "    if \"lr_colors\" in kwargs:\n",
    "        kwargs[\"lr_colors\"] = dict(zip(kwargs[\"lr_colors\"], [\n",
    "            mpl.colors.to_hex(kwargs[\"lr_colors\"][u])\n",
    "            for u in kwargs[\"lr_colors\"]]))  # convert colors to hex\n",
    "\n",
    "    # QC/Diagnostics (Metrics Shouldn't Correlate Much with L-R Expression)\n",
    "    if \"qc\" in kind:\n",
    "        print(f\"\\n\\n{'*' * 40}\\nQC Plots\\n{'*' * 40}\\n\\n\"\n",
    "              \"Expression frequency and L-R/CCI metrics shouldn't correlate much\"\n",
    "              \"; otherwise, increase `n_perms` and/or `n_pairs`.\")\n",
    "        try:\n",
    "            st.pl.lr_diagnostics(grid, figsize=(10, 2.5))  # QC\n",
    "            figs[\"qc_lr_diagnostics\"] = plt.gcf()\n",
    "            st.pl.lr_n_spots(grid, n_top=n_top, figsize=(11, 3), max_text=100)\n",
    "            figs[\"qc_lr_spots\"] = plt.gcf()\n",
    "        except Exception:\n",
    "            traceback.print_exc()\n",
    "        if f\"per_lr_cci_{col_cell_type}\" in grid.uns and (\n",
    "                plot_cci is True):  # if CCI has been run\n",
    "            try:\n",
    "                st.pl.cci_check(grid, col_cell_type, figsize=(16, 5))\n",
    "                figs[\"qc_cci\"] = plt.gcf()\n",
    "                figs[\"qc_cci\"].suptitle(\"CCI Check: Interactions & cell type \"\n",
    "                                        \"frequency shouldn't correlate much\")\n",
    "            except Exception:\n",
    "                traceback.print_exc()\n",
    "                print(\"\\n\\nCCI QC plot failed\")\n",
    "\n",
    "    # Results Summary (Rankings of L-R Pairs by Number of Significant Spots)\n",
    "    if \"results\" in kind:\n",
    "        print(f\"\\n\\n{'*' * 40}\\nResults Plots\\n{'*' * 40}\\n\\n\")\n",
    "        st.pl.lr_summary(grid, n_top=n_top, figsize=f_s,\n",
    "                         highlight_lrs=plot_lr)  # plot L-R ranks\n",
    "        figs[\"lr_ranks\"] = plt.gcf()\n",
    "        if plot_lr is not False:\n",
    "            fig, axes = kwargs.pop(\"fig\", None), kwargs.pop(\"axes\", None)\n",
    "            if fig is None or axes is None:\n",
    "                fig, axes = plt.subplots(ncols=len(stats), nrows=len(plot_lr),\n",
    "                                         figsize=f_s)  # subplots: L-R pairs\n",
    "            for r, lr in enumerate(plot_lr):  # iterate ligand-receptors\n",
    "                # kws = {\"show_color_bar\": False, **kwargs}\n",
    "                kws = {\"show_color_bar\": False}\n",
    "                try:\n",
    "                    for c, stat in enumerate(stats):  # iterate statistics\n",
    "                        st.pl.lr_result_plot(\n",
    "                            grid, use_result=stat, use_lr=lr,\n",
    "                            fig=fig, ax=axes[r, c], **kws)  # plot L-R\n",
    "                        axes[r, c].set_title(f\"{lr} {stat}\")\n",
    "                except Exception:\n",
    "                    traceback.print_exc()\n",
    "                    print(f\"Results summary plot error for {lr}\")\n",
    "            if fig is not None:\n",
    "                fig.show()\n",
    "            figs[\"results\"] = fig, axes\n",
    "\n",
    "    # Color Spot by Mean L-R Expression in Spots Connected by Arrow\n",
    "    if \"arrow\" in kind:\n",
    "        fig, axes = kwargs.pop(\"fig\", None), kwargs.pop(\"axes\", None)\n",
    "        if fig is None or axes is None:\n",
    "            fig, axes = plt.subplots(ncols=ncols, nrows=nrows,\n",
    "                                     figsize=f_s, squeeze=False)\n",
    "        for i, lr in enumerate(plot_lr):  # iterate L-R pairs\n",
    "            axes.flatten()[i].set_title(lr)\n",
    "            kws = dict(arrow_width=2, pt_scale=10, arrow_head_width=4,\n",
    "                       arrow_cmap=\"YlOrRd\", arrow_vmax=1.5, outer_mode=None,\n",
    "                       outer_size_prop=1, fig=fig, ax=axes.flatten()[i],\n",
    "                       sig_spots=sig_spots, sig_cci=sig_cci)\n",
    "            kws.update({**kwargs, \"show_arrows\": False} if (\n",
    "                col_cell_type is None) else {**kwargs})\n",
    "            if \"lr_colors\" in kws:\n",
    "                kws[\"lr_colors\"] = {**kws[\"lr_colors\"]}\n",
    "                for v, k in enumerate([\"l\", \"r\", \"lr\"]):  # key palette by L-R\n",
    "                    lab = lr.split(\"_\")[v] if v < 2 else lr\n",
    "                    kws[\"lr_colors\"][lab] = kws[\"lr_colors\"][k]\n",
    "                    _ = kws[\"lr_colors\"].pop(k)\n",
    "            try:\n",
    "                st.pl.lr_plot(grid, lr, use_label=col_cell_type, **kws)\n",
    "            except Exception:\n",
    "                traceback.print_exc()\n",
    "                print(f\"L-R arrow plot error for {lr}\")\n",
    "        fig.tight_layout()\n",
    "        figs[\"arrow\"] = fig, axes\n",
    "        plt.show()\n",
    "\n",
    "    # Net Plot: # of Interactions between Cell Types across All L-R Pairs\n",
    "    if \"net\" in kind:\n",
    "        pos_1 = st.pl.ccinet_plot(grid, col_cell_type, return_pos=True)  # all\n",
    "        if plot_lr is not False:\n",
    "            for lr in plot_lr:  # iterate L-R pairs\n",
    "                try:\n",
    "                    st.pl.ccinet_plot(grid, col_cell_type, lr, min_counts=2,\n",
    "                                      figsize=f_s, pos=pos_1, **kwargs)\n",
    "                except Exception as err:\n",
    "                    print(f\"Net plot error for {lr}\")\n",
    "\n",
    "    # Chord Plot\n",
    "    if \"chord\" in kind:\n",
    "        # st.pl.lr_chord_plot(grid, col_cell_type)  # all\n",
    "        if plot_lr is not False:\n",
    "            for lr in plot_lr:  # just between selected pairs\n",
    "                try:\n",
    "                    st.pl.lr_chord_plot(grid, col_cell_type, lr)\n",
    "                except Exception:\n",
    "                    traceback.print_exc()\n",
    "                    print(f\"Chord plot error for {lr}\")\n",
    "\n",
    "    # Heatmap Equivalent of Net & Chord\n",
    "    if \"map\" in kind:\n",
    "        st.pl.cci_map(grid, col_cell_type, **kwargs)\n",
    "        if plot_lr is not False:\n",
    "            fig, axes = kwargs.pop(\"fig\", None), kwargs.pop(\"axes\", None)\n",
    "            if fig is None or axes is None:\n",
    "                fig, axes = plt.subplots(ncols=ncols, nrows=nrows,\n",
    "                                         figsize=f_s)  # subplots: L-R pairs\n",
    "            for i, lr in enumerate(plot_lr):  # iterate L-R pairs\n",
    "                try:\n",
    "                    figs[\"map\"] = st.pl.cci_map(\n",
    "                        grid, col_cell_type, lr, show=False,\n",
    "                        ax=axes.flatten()[i], **kwargs)  # heatmap plot\n",
    "                except Exception:\n",
    "                    traceback.print_exc()\n",
    "                    print(f\"CCI map plot error for {lr}\")\n",
    "            plt.show()\n",
    "            try:\n",
    "                st.pl.lr_cci_map(grid, col_cell_type, lrs=plot_lr,\n",
    "                                 min_total=min_total, figsize=(20, 4))\n",
    "            except Exception:\n",
    "                traceback.print_exc()\n",
    "    return figs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QC/Diagnostics\n",
    "\n",
    "**First Set of Plots (For L-R Analysis; Scatter)**\n",
    "\n",
    "`st.pl.lr_diagnostics`: Per `stlearn` documentation...\n",
    "\n",
    "> A key aspect of the LR analysis is to control for LR expression level and frequency when calling significant hotspots.\n",
    ">\n",
    "> Hence, our diagnostic plots should show next to no correlation between the hotspots of the LR pairs and the expression level and frequency of expression.\n",
    ">\n",
    "> The following diagnostics allow us to check and make sure this is the case; if not, could indicate a larger number of permutations is required.\n",
    ">\n",
    ">\n",
    "> * Left plot: Relationship between LR expression level (non-zero spots average median expression of genes in the LR pair) and the ranking of the LR.\n",
    "> \n",
    "> * Right plot: Relationship between LR expression frequency (average proportion of zero spots for each gene in the LR pair) and the ranking of the LR.\n",
    "> \n",
    "> [If] there is a...correlation between the LR expression frequency and number of significant spots, [this indicates] the n_pairs parameter should be set higher to create more accurate background distributions (10,000 pairs was used in the case of the paper version of the above).\n",
    "\n",
    "**Second Set of Plots (For L-R Analysis; Bars)**\n",
    "\n",
    "`st.pl.lr_n_spots`: Per `stlearn` documentation...\n",
    "> The above boxplots show the number of spots with ligand-receptor scores for each LR on the y-axis, with the LR ranking on the x-axis. The bar area is stratified by spots which were significant (green) and non-significant (blue).\n",
    "> \n",
    "> [If] there does appear to be some correlation with more highly frequent LR pairs and LR ranking...the n_pairs parameter above should be set higher.\n",
    "\n",
    "**Third Set of Plots (for CCI Analysis)**\n",
    "\n",
    "Interactions & cell type frequency shouldn't correlate much if well-controlled for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in grids:\n",
    "    print(f\"\\n\\n{'=' * 80}\\n{x}\\n{'=' * 80}\")\n",
    "    plot_spatial_lr(grids[x], col_cell_type, kind=\"qc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L-R Results Summary\n",
    "\n",
    "Rankings, p-values, and scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_spots = True\n",
    "# sig_spots = False\n",
    "for x in grids:\n",
    "    print(f\"\\n\\n{'=' * 80}\\n{x}\\n{'=' * 80}\")\n",
    "    _ = plot_spatial_lr(grids[x], col_cell_type, kind=\"results\",\n",
    "                        plot_lr=plot_lr, sig_spots=sig_spots, title=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L-R Co-Expression\n",
    "\n",
    "`outer_mode` & corresponding color map arguments: Per `stlearn` documentation...\n",
    "> The mode for the larger points when displaying LR expression; can either be ‘binary’ or ‘continuous’ or None. \n",
    "* > ‘Binary’ discretizes each spot as expressing L, R, both, or neither. \n",
    "   - `inner_cmap`: \"Cmap for the inner point\"\n",
    "   - `lr_colors`: \"Specifies the colors of the LRs...{‘l’: color, ‘r’: color, ‘lr’: color, ‘’: color}; the last key-value indicates colour for spots not expressing the ligand or receptor\"\n",
    "* > ‘Continuous’ shows color gradient for levels of LR expression by plotting two points for each spot, the ‘inner’ point is the receptor expression levels, and the ‘outer’ point is the ligand expression level. None plots no ligand/receptor expression.\n",
    "   - `l_cmap`:  \"Cmap for coloring the ligand expression\"\n",
    "   - `r_cmap`: \"Cmap for coloring the receptor expression\"\n",
    "   - `lr_cmap`: \"Cmap for coloring coexpression\"\n",
    "\n",
    "`min_expr`: Per `stlearn`...\"The minimum expr above which LR considered expressed when plotting binary LR expression.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to None for Just L-R; `col_cell_type` to Show Labels Too\n",
    "cct = None\n",
    "# cct = col_cell_type\n",
    "\n",
    "# Plot\n",
    "for m in [\"binary\", \"continuous\"]:\n",
    "    for s in [True, False]:\n",
    "        for x in grids:\n",
    "            palette = {\"lr_colors\": {\"l\": \"g\", \"r\": \"b\", \"lr\":\n",
    "                \"y\", \"\": \"w\"}} if m == \"binary\" else {}\n",
    "            title = str(f\"{x}: {m.capitalize()} Coexpression\"\n",
    "                        f\" ({'Significant Only' if s else 'All'})\")\n",
    "            plot_spatial_lr(grids[x], cct, kind=\"arrow\", plot_lr=plot_lr,\n",
    "                            outer_mode=m, title=title, sig_spots=s,\n",
    "                            figsize=(35, 15), **palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell-Cell Interactions\n",
    "\n",
    "Per `stlearn`...\n",
    "> The number of interactions refers to the number of times a spot with the reciever cell type expressed the ligand and the source cell type expressed the receptor in the same neighbourhood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CCI Map\n",
    "\n",
    "**First Plot (CCI)**\n",
    "Per `stlearn` documentation:\n",
    "> This is a heatmap equivalent to the network diagrams and chordplots, it has more quantitative benefits.\n",
    "> The # of interactions refers to the number of times a spot with the reciever cell type expressed the ligand and the source cell type expressed the receptor in the same neighbourhood.\n",
    "\n",
    "**Second Plot (LR-CCI)**\n",
    "\n",
    "CCI plots by individual L-R pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sig = False\n",
    "sig = True  # only show significant\n",
    "for x in grids:\n",
    "    print(f\"\\n\\n{'=' * 80}\\n{x}\\n{'=' * 80}\")\n",
    "    plot_spatial_lr(grids[x], col_cell_type, kind=\"map\",\n",
    "                    figsize=(12 * len(plot_lr), 10), sig_interactions=sig,\n",
    "                    title=str(f\"{x}: Cell-Cell Interactions \"\n",
    "                              f\"(Significant{'' if sig else ' and N.S.'})\"),\n",
    "                    plot_lr=plot_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CCI Chord\n",
    "\n",
    "Most useful for small numbers of cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in grids:\n",
    "    print(f\"\\n\\n{'=' * 80}\\n{x}\\n{'=' * 80}\")\n",
    "    plot_spatial_lr(grids[x], col_cell_type, kind=\"chord\", plot_lr=plot_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CCI Arrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in grids:\n",
    "    print(f\"\\n\\n{'=' * 80}\\n{x}\\n{'=' * 80}\")\n",
    "    plot_spatial_lr(grids[x], col_cell_type, kind=\"arrow\",\n",
    "                    figsize=(60, 60), plot_lr=plot_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CCI Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in grids:\n",
    "    print(f\"\\n\\n{'=' * 80}\\n{x}\\n{'=' * 80}\")\n",
    "    plot_spatial_lr(grids[x], col_cell_type, title=f\"{x}: L-R Interactions\",\n",
    "                    kind=\"net\", plot_lr=plot_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gene Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_lr is not None:\n",
    "    genes = functools.reduce(lambda i, j: list(i) + list(j),\n",
    "                             [i.split(\"_\") for i in plot_lr])\n",
    "    for g in genes:\n",
    "        fig, axes = plt.subplots(ncols=2, figsize=(20, 5))\n",
    "        st.pl.gene_plot(grid, gene_symbols=g, ax=axes[0],\n",
    "                        show_color_bar=False, show_plot=False)\n",
    "        st.pl.gene_plot(adata, gene_symbols=g, ax=axes[1],\n",
    "                        show_color_bar=False, show_plot=False, vmax=80)\n",
    "        axes[0].set_title(f\"Grid {g} Expression\")\n",
    "        axes[1].set_title(f\"Cell {g} Expression\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_int_dfs = grid.uns[f\"per_lr_cci_{col_cell_type}\"]\n",
    "lr_dfs = [lr_int_dfs[lr] if lr in lr_int_dfs else np.nan for lr in plot_lr]\n",
    "[x.replace(0, np.nan).stack().dropna().to_frame(plot_lr[i]) if isinstance(\n",
    "    x, pd.DataFrame) else None for i, x in enumerate(lr_dfs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "load = load_suffix not in [None, False]\n",
    "distances = {}\n",
    "for p in [[True, False], [False, True]]:  # iterate L-R, CCI analysis\n",
    "    print(f\"\\n\\n{'=' * 80}\\n{'L-R' if p[0] else 'CCI'}\\n{'=' * 80}\\n\\n\")\n",
    "    for x in grids:  # iterate samples\n",
    "        print(f\"\\n\\n{'*' * 40}\\n{x}\\n{'*' * 40}\\n\\n\")\n",
    "\n",
    "        if \"50217A\" in x:\n",
    "            continue\n",
    "\n",
    "        # Re-Load Past Results if Already Done\n",
    "        if \"lrfeatures\" in grids[x].uns and p[0] is True and load is True:\n",
    "            distances[x] = grids[x].obs.loc[:, \"distance\"].iloc[0]\n",
    "            print(grids[x].uns[\"lr_summary\"])\n",
    "            continue\n",
    "        if f\"lr_cci_{col_cell_type}\" in grids[x].uns and (\n",
    "                p[1] is True and load is True):\n",
    "            print(f\"Results stored in `.uns['lr_cci_{col_cell_type}']`\")\n",
    "            continue\n",
    "\n",
    "        # Store Distance & Other Options\n",
    "        ddd = min(neighbors[x].index.values[np.where(np.array(\n",
    "            neighbors[x].apply(lambda y: y >= min_med_neighbors)))[0]]\n",
    "                  )  # least distance >= specified # of median neighbors\n",
    "        distances[x] = ddd if distance == \"auto\" else distance  # auto vs. #\n",
    "        grids[x].obs.loc[:, \"min_med_neighbors\"] = min_med_neighbors if (\n",
    "            distance == \"auto\") else np.nan  # store option to choose distance\n",
    "        kws = dict(distance=distances[x], min_spots=min_spots,\n",
    "                   n_pairs=n_pairs,\n",
    "                   adj_method=adj_method, adj_axis=adj_axis,\n",
    "                   pval_adj_cutoff=pval_adj_cutoff,\n",
    "                   cell_prop_cutoff=cell_prop_cutoff, n_perms=n_perms,\n",
    "                   organism=organism, resource=resource)\n",
    "        if p[0] is True:\n",
    "            print(f\"n_pairs = {n_pairs}; distance = {distances[x]}\")\n",
    "        for v in kws:  # store keyword arguments in .obs\n",
    "            grids[x].obs.loc[:, v] = str(kws[v])\n",
    "        grids[x] = analyze_lr_spatial(grids[x], col_cell_type, n_jobs=n_jobs,\n",
    "                                      do_lr=p[0], do_cci=p[1], **kws)\n",
    "        if write_suffix not in [None, False]:\n",
    "            grid = grids[x].copy()\n",
    "            for e in grid.uns[\"lrfeatures\"]:\n",
    "                grid.uns[\"lrfeatures\"][e] = grid.uns[\"lrfeatures\"][\n",
    "                    e].astype(np.float64)  # avoid write error\n",
    "            grid.uns[\"lrfeatures\"] = grids[x].uns[\n",
    "                \"lrfeatures\"].astype(np.float64)  # avoid write error\n",
    "            for e in [\"lrfeatures\", \"lr_summary\", \"lr_summary_preadjust\"]:\n",
    "                if e in grid.uns:  # avoid write errors\n",
    "                    ix_o = grid.uns[e].index.names\n",
    "                    ixs = [u if u else \"ix\" for u in ix_o]  # rename \"None\"\n",
    "                    grid.uns[e] = grid.uns[e].rename_axis(ixs).reset_index()\n",
    "                    for k in ixs:\n",
    "                        grid.uns[e] = grid.uns[e].astype({k: str})\n",
    "                    grid.uns[e] = grid.uns[e].set_index(ixs).rename_axis([\n",
    "                        u if u else \"i\" for u in ix_o])\n",
    "            _ = grid.uns.pop(f\"stlearn_label_transfer_{col_cell_type}\", None)\n",
    "            grid.write_h5ad(os.path.join(\n",
    "                out_dir, f\"{x}_stlearn{write_suffix}.h5ad\"))  # write object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "load = load_suffix not in [None, False]\n",
    "distances = {}\n",
    "for p in [[True, False], [False, True]]:  # iterate L-R, CCI analysis\n",
    "    print(f\"\\n\\n{'=' * 80}\\n{'L-R' if p[0] else 'CCI'}\\n{'=' * 80}\\n\\n\")\n",
    "    for x in grids:  # iterate samples\n",
    "        print(f\"\\n\\n{'*' * 40}\\n{x}\\n{'*' * 40}\\n\\n\")\n",
    "\n",
    "        if \"50217A\" not in x:\n",
    "            continue\n",
    "\n",
    "        # Re-Load Past Results if Already Done\n",
    "        if \"lrfeatures\" in grids[x].uns and p[0] is True and load is True:\n",
    "            distances[x] = grids[x].obs.loc[:, \"distance\"].iloc[0]\n",
    "            print(grids[x].uns[\"lr_summary\"])\n",
    "            continue\n",
    "        if f\"lr_cci_{col_cell_type}\" in grids[x].uns and (\n",
    "                p[1] is True and load is True):\n",
    "            print(f\"Results stored in `.uns['lr_cci_{col_cell_type}']`\")\n",
    "            continue\n",
    "\n",
    "        # Store Distance & Other Options\n",
    "        ddd = min(neighbors[x].index.values[np.where(np.array(\n",
    "            neighbors[x].apply(lambda y: y >= min_med_neighbors)))[0]]\n",
    "                  )  # least distance >= specified # of median neighbors\n",
    "        distances[x] = ddd if distance == \"auto\" else distance  # auto vs. #\n",
    "        grids[x].obs.loc[:, \"min_med_neighbors\"] = min_med_neighbors if (\n",
    "            distance == \"auto\") else np.nan  # store option to choose distance\n",
    "        kws = dict(distance=distances[x], min_spots=min_spots,\n",
    "                   n_pairs=n_pairs,\n",
    "                   adj_method=adj_method, adj_axis=adj_axis,\n",
    "                   pval_adj_cutoff=pval_adj_cutoff,\n",
    "                   cell_prop_cutoff=cell_prop_cutoff, n_perms=n_perms,\n",
    "                   organism=organism, resource=resource)\n",
    "        if p[0] is True:\n",
    "            print(f\"n_pairs = {n_pairs}; distance = {distances[x]}\")\n",
    "        for v in kws:  # store keyword arguments in .obs\n",
    "            grids[x].obs.loc[:, v] = str(kws[v])\n",
    "        grids[x] = analyze_lr_spatial(grids[x], col_cell_type, n_jobs=n_jobs,\n",
    "                                      do_lr=p[0], do_cci=p[1], **kws)\n",
    "        if write_suffix not in [None, False]:\n",
    "            grid = grids[x].copy()\n",
    "            for e in grid.uns[\"lrfeatures\"]:\n",
    "                grid.uns[\"lrfeatures\"][e] = grid.uns[\"lrfeatures\"][\n",
    "                    e].astype(np.float64)  # avoid write error\n",
    "            grid.uns[\"lrfeatures\"] = grids[x].uns[\n",
    "                \"lrfeatures\"].astype(np.float64)  # avoid write error\n",
    "            for e in [\"lrfeatures\", \"lr_summary\", \"lr_summary_preadjust\"]:\n",
    "                if e in grid.uns:  # avoid write errors\n",
    "                    ix_o = grid.uns[e].index.names\n",
    "                    ixs = [u if u else \"ix\" for u in ix_o]  # rename \"None\"\n",
    "                    grid.uns[e] = grid.uns[e].rename_axis(ixs).reset_index()\n",
    "                    for k in ixs:\n",
    "                        grid.uns[e] = grid.uns[e].astype({k: str})\n",
    "                    grid.uns[e] = grid.uns[e].set_index(ixs).rename_axis([\n",
    "                        u if u else \"i\" for u in ix_o])\n",
    "            _ = grid.uns.pop(f\"stlearn_label_transfer_{col_cell_type}\", None)\n",
    "            grid.write_h5ad(os.path.join(\n",
    "                out_dir, f\"{x}_stlearn{write_suffix}.h5ad\"))  # write object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "col_cell_type = c_m\n",
    "write_suffix += \"_annotated\"\n",
    "\n",
    "load = load_suffix not in [None, False]\n",
    "distances = {}\n",
    "for p in [[True, False], [False, True]]:  # iterate L-R, CCI analysis\n",
    "    print(f\"\\n\\n{'=' * 80}\\n{'L-R' if p[0] else 'CCI'}\\n{'=' * 80}\\n\\n\")\n",
    "    for x in grids:  # iterate samples\n",
    "        print(f\"\\n\\n{'*' * 40}\\n{x}\\n{'*' * 40}\\n\\n\")\n",
    "\n",
    "        if col_cell_type not in grids[x].obs:\n",
    "            print(f\"{col_cell_type} not in {x}\")\n",
    "            continue\n",
    "\n",
    "        # Re-Load Past Results if Already Done\n",
    "        if f\"lr_cci_{col_cell_type}\" in grids[x].uns:\n",
    "            print(f\"Results stored in `.uns['lr_cci_{col_cell_type}']`\")\n",
    "            continue\n",
    "\n",
    "        # Store Distance & Other Options\n",
    "        ddd = min(neighbors[x].index.values[np.where(np.array(\n",
    "            neighbors[x].apply(lambda y: y >= min_med_neighbors)))[0]]\n",
    "                  )  # least distance >= specified # of median neighbors\n",
    "        distances[x] = ddd if distance == \"auto\" else distance  # auto vs. #\n",
    "        grids[x].obs.loc[:, \"min_med_neighbors\"] = min_med_neighbors if (\n",
    "            distance == \"auto\") else np.nan  # store option to choose distance\n",
    "        kws = dict(distance=distances[x], min_spots=min_spots,\n",
    "                   n_pairs=n_pairs,\n",
    "                   adj_method=adj_method, adj_axis=adj_axis,\n",
    "                   pval_adj_cutoff=pval_adj_cutoff,\n",
    "                   cell_prop_cutoff=cell_prop_cutoff, n_perms=n_perms,\n",
    "                   organism=organism, resource=resource)\n",
    "        if p[0] is True:\n",
    "            print(f\"n_pairs = {n_pairs}; distance = {distances[x]}\")\n",
    "        for v in kws:  # store keyword arguments in .obs\n",
    "            grids[x].obs.loc[:, v] = str(kws[v])\n",
    "        grids[x] = analyze_lr_spatial(grids[x], col_cell_type, n_jobs=n_jobs,\n",
    "                                      do_lr=p[0], do_cci=p[1], **kws)\n",
    "        if write_suffix not in [None, False]:\n",
    "            grid = grids[x].copy()\n",
    "            for e in grid.uns[\"lrfeatures\"]:\n",
    "                grid.uns[\"lrfeatures\"][e] = grid.uns[\"lrfeatures\"][\n",
    "                    e].astype(np.float64)  # avoid write error\n",
    "            grid.uns[\"lrfeatures\"] = grids[x].uns[\n",
    "                \"lrfeatures\"].astype(np.float64)  # avoid write error\n",
    "            for e in [\"lrfeatures\", \"lr_summary\", \"lr_summary_preadjust\"]:\n",
    "                if e in grid.uns:  # avoid write errors\n",
    "                    ix_o = grid.uns[e].index.names\n",
    "                    ixs = [u if u else \"ix\" for u in ix_o]  # rename \"None\"\n",
    "                    grid.uns[e] = grid.uns[e].rename_axis(ixs).reset_index()\n",
    "                    for k in ixs:\n",
    "                        grid.uns[e] = grid.uns[e].astype({k: str})\n",
    "                    grid.uns[e] = grid.uns[e].set_index(ixs).rename_axis([\n",
    "                        u if u else \"i\" for u in ix_o])\n",
    "            _ = grid.uns.pop(f\"stlearn_label_transfer_{col_cell_type}\", None)\n",
    "            # grid.write_h5ad(os.path.join(\n",
    "            #     out_dir, f\"{x}_stlearn{write_suffix}.h5ad\"))  # write object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sig = False\n",
    "sig = True  # only show significant\n",
    "for x in grids:\n",
    "    print(f\"\\n\\n{'=' * 80}\\n{x}\\n{'=' * 80}\")\n",
    "    plot_spatial_lr(grids[x], col_cell_type, kind=\"map\",\n",
    "                    figsize=(12 * len(plot_lr), 10), sig_interactions=sig,\n",
    "                    title=str(f\"{x}: Cell-Cell Interactions \"\n",
    "                              f\"(Significant{'' if sig else ' and N.S.'})\"),\n",
    "                    plot_lr=plot_lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial-alt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
