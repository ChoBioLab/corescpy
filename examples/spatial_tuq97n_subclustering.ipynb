{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ryp2 is not installed. Install with </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">pip install rpy2 </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">to run tools with R support.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33mryp2 is not installed. Install with \u001b[0m\u001b[1;32mpip install rpy2 \u001b[0m\u001b[1;33mto run tools with R support.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tangram'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcorescpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcr\u001b[39;00m\n\u001b[1;32m     17\u001b[0m pd\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mmax_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     18\u001b[0m pd\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mmax_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m\n",
      "File \u001b[0;32m~/corescpy/corescpy/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# __init__.py\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils \u001b[38;5;28;01mas\u001b[39;00m tl\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m processing \u001b[38;5;28;01mas\u001b[39;00m pp\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m analysis \u001b[38;5;28;01mas\u001b[39;00m ax\n",
      "File \u001b[0;32m~/corescpy/corescpy/utils/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (print_dictionary, make_printable_object,\n\u001b[1;32m      2\u001b[0m                       print_pretty_dictionary, explore_h5_file, print_counts)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_outlier\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_manipulation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (create_pseudobulk, create_condition_combo,\n\u001b[1;32m      5\u001b[0m                                 merge_pca_subset, write_ome_tif)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01margument_manipulation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_list, merge\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresources\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_markers_database, get_topp_gene\n",
      "File \u001b[0;32m~/corescpy/corescpy/utils/data_manipulation.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcorescpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_layer_dict\n\u001b[1;32m     19\u001b[0m layers \u001b[38;5;241m=\u001b[39m get_layer_dict()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_pseudobulk\u001b[39m(adata, col_cell_type, col_sample_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     23\u001b[0m                       layer\u001b[38;5;241m=\u001b[39mlayers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcounts\u001b[39m\u001b[38;5;124m\"\u001b[39m], mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     24\u001b[0m                       kws_process\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "File \u001b[0;32m~/corescpy/corescpy/processing/__init__.py:15\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mguide_rna\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m process_guide_rna\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimporting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (combine_matrix_protospacer,\n\u001b[1;32m     13\u001b[0m                         process_multimodal_crispr)\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial_pp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (describe_tiff, extract_tiff, command_cellpose,\n\u001b[1;32m     16\u001b[0m                          read_spatial, update_spatial_uns,\n\u001b[1;32m     17\u001b[0m                          _get_control_probe_names, integrate_spatial,\n\u001b[1;32m     18\u001b[0m                          SPATIAL_KEY, SPATIAL_IMAGE_KEY_SEP)\n\u001b[1;32m     20\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_object\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_object_multi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_layer_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess_data\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck_normalization\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz_normalize_by_reference\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperform_qc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSPATIAL_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSPATIAL_IMAGE_KEY_SEP\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     28\u001b[0m ]\n",
      "File \u001b[0;32m~/corescpy/corescpy/processing/spatial_pp.py:28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msio\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msubprocess\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtangram\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtg\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tangram'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from anndata import AnnData\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import corescpy as cr\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 200\n",
    "sc.settings.set_figure_params(dpi=100, frameon=False, figsize=(20, 20))\n",
    "\n",
    "palette = \"tab20\"\n",
    "\n",
    "\n",
    "def construct_file(sample, slide, date=None, timestamp=None,\n",
    "                   panel_id=\"TUQ97N\", prefix=\"output-XETG00189\",\n",
    "                   project_owner=\"EA\", run=\"CHO-001\", directory=None):\n",
    "    \"\"\"Construct file path from information.\"\"\"\n",
    "    if isinstance(sample, str):\n",
    "        sample = [sample]\n",
    "    if \"outputs\" not in directory and os.path.exists(\n",
    "            os.path.join(directory, \"outputs\")):\n",
    "        directory = os.path.join(directory, \"outputs\")\n",
    "    print(directory)\n",
    "    panel_id, prefix, project_owner, slide, date, timestamp = [\n",
    "        [x] * len(sample) if isinstance(x, str) else list(x) if x else x\n",
    "        for x in [panel_id, prefix, project_owner, slide, date, timestamp]]\n",
    "    run = [run] * len(sample) if isinstance(run, (str, int, float)) else run\n",
    "    block = [\"-\".join(i) for i in zip(sample, panel_id, project_owner)]\n",
    "    fff = [f\"{prefix[i]}__{slide[i]}__{block[i]}\" for i in range(len(sample))]\n",
    "    if date is None or timestamp is None:\n",
    "        for i, x in enumerate(fff):  # iterate current file stems\n",
    "            ddd = os.path.join(directory, panel_id[i], run[i])\n",
    "            print(ddd)\n",
    "            matches = sum([x in d for d in os.listdir(ddd)])\n",
    "            if  matches != 1:\n",
    "                raise ValueError(f\"{x} found in 0 or multiple file paths\",\n",
    "                                 f\"\\n\\n{os.listdir(ddd)}\")\n",
    "            fff[i] = os.path.join(ddd, np.array(os.listdir(ddd))[np.where([\n",
    "                x in d for d in os.listdir(ddd)])[0][0]])  # find match\n",
    "    else:\n",
    "        fff = [os.path.join(directory, panel_id[i], run[i],\n",
    "                            f\"{x}__{date[i]}__{timestamp[i]}\")\n",
    "               for i, x in enumerate(fff)]\n",
    "    return fff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Names\n",
    "col_sample_id_original = \"Sample ID\"\n",
    "col_sample_id = \"Sample\"\n",
    "col_subject = \"Patient\"\n",
    "col_batch = \"Slide\"\n",
    "col_path = \"file_path\"\n",
    "# col_date_time, col_date = \"Date Sectioned\", \"Date\"\n",
    "col_date_time, col_date = None, None\n",
    "col_inflamed, col_stricture = \"Inflamed\", \"Stricture\"\n",
    "col_condition = \"Condition\"\n",
    "meta_rn = {\"Name\": col_subject, \"Slide ID\": col_batch,\n",
    "           \"Inflammation Status\": col_inflamed}\n",
    "\n",
    "# Directories & Metadata\n",
    "# Replace manually or mirror my file/directory tree in your home\n",
    "include_stricture = True\n",
    "run = \"CHO-001\"\n",
    "samples = [\"50452A\", \"50452B\", \"50452C\"]\n",
    "# samples = [\"50452A\", \"50452B\"]\n",
    "# samples = [\"50452A\", \"50452B\", \"50452C\", \"50564A4\", \"50618B5\"]\n",
    "# run = [\"CHO-001\"] * 3 + [\"CHO-002\"] * 3\n",
    "panel_id = \"TUQ97N\"\n",
    "prefix = \"output-XETG00189\"\n",
    "project_owner = \"EA\"\n",
    "ddu = os.path.expanduser(\"~\")\n",
    "ddl = \"/mnt/cho_lab/disk2/elizabeth/data/shared-xenium-library\"\n",
    "ddd = os.path.join(ddl, \"outputs\", panel_id)\n",
    "panel = os.path.join(ddu, \"projects/senescence/ProposedGenePanel.xlsx\")\n",
    "file_ann = os.path.join(ddu, \"corescpy/examples/annotation_guide.xlsx\")\n",
    "\n",
    "# Input/Output Options\n",
    "reload = True\n",
    "out_dir = os.path.join(ddd, \"nebraska\")  # set to None to avoid saving\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "# Computing Resources\n",
    "gpu = False\n",
    "sc.settings.n_jobs = 4\n",
    "sc.settings.max_memory = 150\n",
    "\n",
    "# Read Metadata & Other Information\n",
    "annot_df = pd.read_excel(file_ann)\n",
    "metadata = pd.read_excel(os.path.join(ddl, \"Xenium_Samples_02092024.xlsx\"),\n",
    "                         dtype={\"Slide ID\": str})\n",
    "metadata = metadata.rename(meta_rn, axis=1)\n",
    "if samples not in [\"all\", None]:  # subset by sample ID?\n",
    "    metadata = metadata.set_index(col_sample_id_original).loc[\n",
    "        samples].reset_index()\n",
    "\n",
    "# Processing & Clustering Options\n",
    "resolution = 0.5\n",
    "min_dist = 1\n",
    "n_comps = 20\n",
    "# col_qscore = ?\n",
    "# custom_thresholds = {col_qscore: [, None]}\n",
    "custom_thresholds = None\n",
    "genes_subset = list(annot_df.iloc[:, 0])\n",
    "kws_pp = dict(cell_filter_pmt=None, cell_filter_ncounts=[50, None],\n",
    "              cell_filter_ngene=[30, None], gene_filter_ncell=[3, None],\n",
    "              gene_filter_ncounts=[3, None],\n",
    "              custom_thresholds=custom_thresholds,\n",
    "              kws_scale=dict(max_value=10, zero_center=True))\n",
    "kws_umap = dict(min_dist=min_dist, method=\"rapids\") if gpu is True else dict(\n",
    "    min_dist=min_dist)\n",
    "kws_cluster = dict(use_gpu=gpu, kws_umap=kws_umap, kws_neighbors=None,\n",
    "                   use_highly_variable=False, n_comps=n_comps,\n",
    "                   genes_subset=genes_subset, resolution=resolution)\n",
    "# kws_subcluster = dict(use_gpu=gpu, kws_umap=dict(min_dist=0.3),\n",
    "#                       kws_neighbors=None, use_highly_variable=False,\n",
    "#                       n_comps=n_comps, genes_subset=genes_subset,\n",
    "#                       method_cluster=\"leiden\", resolution=0.5)\n",
    "kws_subcluster = dict(method_cluster=\"leiden\", resolution=0.5)\n",
    "\n",
    "# Revise Metadata & Construct Variables from Options\n",
    "if col_stricture not in metadata.columns:\n",
    "    metadata.loc[:, col_stricture] = metadata[\"Sample Location\"].apply(\n",
    "        lambda x: \"Stricture\" if \"stricture\" in x.lower() else \"None\")\n",
    "metadata.loc[:, col_condition] = metadata.apply(\n",
    "    lambda x: \"Stricture\" if \"stricture\" in x[col_stricture].lower() else x[\n",
    "        col_inflamed].capitalize() , axis=1)\n",
    "if col_date_time:\n",
    "    metadata.loc[:, col_date] = metadata[col_date_time].apply(\n",
    "        lambda x: datetime.strftime(x, \"%Y%m%d\"))\n",
    "    dates = list(metadata[col_date])\n",
    "else:\n",
    "    dates = None\n",
    "metadata.loc[:, col_sample_id] = metadata.apply(\n",
    "    lambda x: f\"{x[col_condition]}-{x[col_sample_id_original]}\" , axis=1)\n",
    "metadata = metadata.set_index(col_sample_id)\n",
    "metadata.loc[:, col_path] = construct_file(\n",
    "    list(metadata[col_sample_id_original]), list(metadata[col_batch]),\n",
    "    dates, panel_id=panel_id, prefix=prefix,\n",
    "    project_owner=project_owner, run=run, directory=ddl)\n",
    "col_cell_type = \"Annotation\"\n",
    "file_path_dict = dict(zip(metadata.index.values, metadata[\"file_path\"]))\n",
    "kws_init = dict(col_batch=col_batch, col_subject=col_subject,\n",
    "                col_sample_id=col_sample_id, col_cell_type=col_cell_type)\n",
    "\n",
    "# Annotation File\n",
    "col_assignment = \"Bin\"\n",
    "assign = pd.read_excel(file_ann, index_col=0).dropna(subset=col_assignment)\n",
    "sources = assign[col_assignment].unique()\n",
    "rename = dict(zip(sources, [\" \".join([i.capitalize() if i and i[\n",
    "    0] != \"(\" and not i.isupper() and i not in [\n",
    "        \"IgG\", \"IgA\"] else i for i in x.split(\" \")]) if len(x.split(\n",
    "            \" \")) > 1 else x for x in [re.sub(\"glia\", \"Glia\", re.sub(\n",
    "                \"_\", \" \", j)) for j in sources]]))\n",
    "assign.loc[:, col_assignment] = assign[col_assignment].replace(rename)\n",
    "assign = assign.rename_axis(\"Gene\")\n",
    "marker_genes_dict = dict(assign.reset_index().groupby(col_assignment).apply(\n",
    "    lambda x: list(pd.unique(x.Gene))))  # to marker dictionary\n",
    "\n",
    "# Subset if Desired\n",
    "if include_stricture is False:\n",
    "    metadata = metadata[metadata.Stricture != \"Stricture\"]\n",
    "metadata\n",
    "\n",
    "# Genes\n",
    "# genes = [\"CDKN1A\", \"CDKN2A\", \"TP53\", \"PLAUR\", \"PTGER4\", \"FTL\", \"IL6ST\"]\n",
    "# cell_types = [\"ILC3\", \"LTi-like NCR+ ILC3\", \"LTi-like NCR- ILC3\",\n",
    "#               \"ILCP\", \"Macrophages\", \"Stem cells\"]\n",
    "# palette = [\"r\", \"tab:pink\", \"m\", \"b\", \"tab:brown\", \"cyan\"]\n",
    "# High in inf. vs. un\n",
    "# OSM\n",
    "# IL13\n",
    "# IL1B\n",
    "# IL6\n",
    "# TNF\n",
    "# S100A8\n",
    "# S100A9\n",
    "# ------------------------------\n",
    "# High in stricture vs inf/un\n",
    "# PDGFRA\n",
    "# IL6ST\n",
    "# PTPN1\n",
    "# IFNG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-Name Files in Standard Form Using Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fff = list(pd.Series([x if \"h5ad\" in x else np.nan for x in os.listdir(\n",
    "#     out_dir)]).dropna())\n",
    "# frn = []\n",
    "# for x in fff:\n",
    "#     ann = sc.read(os.path.join(out_dir, x))\n",
    "#     kwu = re.sub(\"{\", \"\", re.sub(\"}\", \"\", str(ann.obs.iloc[0].kws_umap))\n",
    "#                  ).split(\", \")\n",
    "#     kwu = np.array(kwu)[np.where([\"min_dist\" in x for x in kwu])[\n",
    "#         0]][0].split(\": \")[1]\n",
    "#     frn += [str(f\"{str(ann.obs.iloc[0][col_sample_id])}__\"\n",
    "#                 f\"res{str(ann.obs.iloc[0].resolution)}\"\n",
    "#                 f\"_dist{kwu}_npc{ann.varm['PCs'].shape[1]}\")]\n",
    "# frd = dict(zip([os.path.join(out_dir, i) for i in fff], [os.path.join(\n",
    "#     out_dir, re.sub(\"[.]\", \"pt\", re.sub(\"[.]h5ad\", \"\", i)) + \".h5ad\")\n",
    "#                                                          for i in frn]))\n",
    "# frd\n",
    "# # for x in frd:\n",
    "# #     os.system(f\"mv {x} {frd[x]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Load Spatial Data\n",
    "suff = str(f\"res{re.sub('[.]', 'pt', str(resolution))}_dist\"\n",
    "           f\"{re.sub('[.]', 'pt', str(min_dist))}_npc{n_comps}\")  # file end\n",
    "selves, paths_he, file_mks, out_files = [], [], [], []\n",
    "for x in metadata.index.values:\n",
    "    self = cr.Spatial(metadata.loc[x][col_path], library_id=x, **kws_init)\n",
    "    for i in metadata:  # add metadata for subject\n",
    "        self.rna.obs.loc[:, i] = str(metadata.loc[x][i])  # add metadata\n",
    "    selves += [self]\n",
    "    paths_he += [os.path.join(metadata.loc[x][\n",
    "        col_path], \"aux_outputs/image_he.ome.tif\")]  # H&E paths\n",
    "        # out_files += [os.path.join(out_dir, f\"{x}.zarr\")]\n",
    "    if out_dir is not None:\n",
    "        out_files += [os.path.join(out_dir, f\"{x}__{suff}.zarr\")]\n",
    "    file_mks += [os.path.join(out_dir, f\"{x}__{suff}_markers.csv\")]\n",
    "\n",
    "# Reload Processed & Clustered Data (Optionally)\n",
    "if reload is True:\n",
    "    for i, s in enumerate(selves):\n",
    "        mks = file_mks[i] if os.path.exists(file_mks[i]) else None\n",
    "        s.update_from_h5ad(file=out_files[i], file_path_markers=mks)\n",
    "        print(s.adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reload is True:\n",
    "    for i, s in enumerate(selves):\n",
    "        s.plot_spatial(color=\"leiden\")\n",
    "        # s.plot_spatial(color=col_cell_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selves[0].cluster(**kws_subcluster, restrict_to=(col_cell_type, [1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selves[0].rna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation & Sub-Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "self = selves[i]\n",
    "self.add_image(paths_he[i], name=\"H_E\", file_align=paths_he_align[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in selves:\n",
    "    _ = s.cluster(**kws_cluster)\n",
    "    _ = s.annotate_clusters(file_ann, col_cell_type=\"leiden\",\n",
    "                            col_annotation=col_cell_type,\n",
    "                            col_assignment=col_assignment)  # annotate & write\n",
    "    s.plot_spatial(color=col_cell_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.plot_spatial(color=\"Annotation\", palette=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf = pd.read_excel(file_ann)\n",
    "adf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_epi = [\"BEST2+ Goblet Cell\", \"BEST4+ Epithelial\", \"EC Cells (NPW+)\",\n",
    "#            \"EC Cells (TAC1+)\", \"Enterocyte\", \"Epithelial\", \"Goblet Cell\",\n",
    "#            \"I Cells (CCK+)\", \"Paneth\", \"D Cells (SST+)\",\n",
    "#            \"Stem Cells\", \"N Cells (NTS+)\", \"K Cells (GIP+)\",\n",
    "#            # \"Colonocyte\",\n",
    "#            \"L Cells (PYY+)\", \"Tuft\", \"Microfold Cell\"]\n",
    "# cat_epi = list(np.array()[np.where([\"epithelial\" in x.lower()\n",
    "#                                     for x in marker_genes_dict])[0]])\n",
    "# file_ann_epi = pd.concat([pd.Series(marker_genes_dict[x]) for x in cat_epi],\n",
    "#                          keys=cat_epi, names=[\"Type\"]).to_frame(\n",
    "#                              \"Gene\").reset_index(0).set_index(\"Gene\")\n",
    "file_ann_epi = file_ann\n",
    "# key_cell_type, col_ann = [\"7\"], \"Subclustering_Epi\"\n",
    "key_cell_type, col_ann = None, \"leiden_sub\"\n",
    "for s in selves:\n",
    "    ann = s.subcluster(restrict_to=(col_cell_type, key_cell_type), copy=False,\n",
    "                       key_added=\"leiden_sub\", **kws_subcluster)\n",
    "    s.annotate_clusters(kws_annotation={\"model\": file_ann_epi,\n",
    "                                        \"col_assignment\": \"Bin\"},\n",
    "                        col_annotation=[col_ann, col_cell_type])\n",
    "    s.plot_spatial(color=col_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in selves:\n",
    "    s.write(out_files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_cell_type, col_ann = None, \"leiden_sub\"\n",
    "for s in selves:\n",
    "    s.plot_spatial(color=col_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_genes_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.annotate_clusters(file_ann, col_cell_type=\"leiden\", col_annotation=\"Annotation\")\n",
    "s.annotate_clusters(file_ann, col_cell_type=\"leiden_subcluster\", col_annotation=\"Annotation_Subcluster\")\n",
    "s.plot_spatial(color=\"Annotation_Subcluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 500\n",
    "\n",
    "dff = pd.concat([pd.Series(marker_genes_dict[x]).to_frame(\"Marker\")\n",
    "                 for x in marker_genes_dict], keys=marker_genes_dict)\n",
    "dff[dff.Marker.isin(self.rna.var_names)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-bio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
