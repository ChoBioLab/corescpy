{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ryp2 is not installed. Install with </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">pip install rpy2 </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">to run tools with R support.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33mryp2 is not installed. Install with \u001b[0m\u001b[1;32mpip install rpy2 \u001b[0m\u001b[1;33mto run tools with R support.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data from `https://omnipathdb.org/queries/enzsub?format=json`\n",
      "Downloading data from `https://omnipathdb.org/queries/interactions?format=json`\n",
      "Downloading data from `https://omnipathdb.org/queries/complexes?format=json`\n",
      "Downloading data from `https://omnipathdb.org/queries/annotations?format=json`\n",
      "Downloading data from `https://omnipathdb.org/queries/intercell?format=json`\n",
      "Downloading data from `https://omnipathdb.org/about?format=text`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Directories\n",
      "================================================================================\n",
      "\n",
      "HPC Entry Point (Cho): /mnt/cho_lab\n",
      "Data: /mnt/cho_lab/bbdata2\n",
      "Metadata: /mnt/cho_lab/disk2/elizabeth/data/shared-xenium-library/samples_XR4UZH.csv\n",
      "Images: /mnt/cho_lab/bbdata1/xenium/XR4UZH\n",
      "Object/Outputs:\n",
      "\t/mnt/cho_lab/disk2/elizabeth/data/shared-xenium-library/outputs/XR4UZH/nebraska (objects)\n",
      "\t/mnt/cho_lab/disk2/elizabeth/data/shared-xenium-library/outputs/XR4UZH/nebraska/plots (plots)\n",
      "\t/mnt/cho_lab/disk2/elizabeth/data/shared-xenium-library/outputs/XR4UZH/nebraska/find_markers (markers)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import re\n",
    "import itertools\n",
    "import scipy\n",
    "import scanpy as sc\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import corescpy as cr\n",
    "\n",
    "# Computing Resources\n",
    "gpu = False\n",
    "sc.settings.n_jobs = 8\n",
    "# sc.settings.max_memory = 150\n",
    "\n",
    "# Display\n",
    "pd.options.display.max_colwidth = 1000\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 500\n",
    "sc.settings.set_figure_params(dpi=100, frameon=False, figsize=(20, 20))\n",
    "\n",
    "# Panel & Column Names (from Metadata & To Be Created)\n",
    "panel = \"XR4UZH\"\n",
    "# panel = \"TUQ97N\"\n",
    "suffix = \"\"  # no file suffix for object h5ad file (main object)\n",
    "capitalize_sample = True if panel == \"TUQ97N\" else False\n",
    "# suffix = \"_new\"  # suffix for object h5ad file (to avoid overwrite)\n",
    "\n",
    "# Samples/Runs\n",
    "use_prior_clustering = False\n",
    "run = None  # just look for samples in all Xenium runs for the panel\n",
    "# run = \"CHO-001\"  # run all from this run; so don't have to specify samples\n",
    "# samples = \"all\"  # use samples = \"all\" with run = something for all from run\n",
    "# or run = None for all available samples\n",
    "samples = [\"1014A2\"]\n",
    "\n",
    "# Main Directories\n",
    "usr_write_rel_path = f\"{os.getlogin()}/data/shared-xenium-library\"\n",
    "d_hpc = \"/mnt/cho_lab\" if os.path.exists(\n",
    "    \"/mnt/cho_lab\") else \"/sc/arion/projects/untreatedIBD\"  # HPC path\n",
    "d_nfs = os.path.join(d_hpc, \"bb-xenium-registry\") if os.path.exists(\n",
    "    os.path.join(d_hpc, \"bb-xenium-registry\")) else os.path.join(\n",
    "        d_hpc, \"chobiolab-core/shared-xenium-library\")\n",
    "d_usr = os.path.join(d_hpc, \"disk2\", usr_write_rel_path) if os.path.exists(\n",
    "    os.path.join(d_hpc, \"disk2\")) else os.path.join(d_hpc, usr_write_rel_path)\n",
    "d_img = os.path.join(d_hpc, f\"cache/tissue-registry/xenium/{panel}\") if (\n",
    "    \"arion\" in d_hpc) else os.path.join(\n",
    "        d_hpc, f\"bb-nfs-data-registries/tissue-registry/xenium/{panel}\")\n",
    "\n",
    "# Construct Directories (Less Likely to Need Changes)\n",
    "# Mirror my file/directory tree in the `d_usr` directory\n",
    "# out_dir = None  # don't write any outputs\n",
    "out_subdir_markers = \"find_markers\"  # sub-directory under out_dir for markers\n",
    "out_subdir_cluster = \"explorer_files\"  # sub-directory for cluster-cell ID csv\n",
    "out_dir = os.path.join(d_usr, f\"outputs/{panel}/nebraska\")  # to save objects\n",
    "out_dir_plot = None if out_dir is None else os.path.join(\n",
    "    out_dir, \"plots\")  # plot output directory\n",
    "file_mdf = os.path.join(d_usr, f\"samples_{panel}.csv\")  # metadata file path\n",
    "print(f\"\\n\\n\\n{'=' * 80}\\nDirectories\\n{'=' * 80}\\n\\nHPC Entry Point (Cho): \"\n",
    "      f\"{d_hpc}\\nData: {d_nfs}\\nMetadata: {file_mdf}\\nImages: {d_img}\\n\"\n",
    "      f\"Object/Outputs:\\n\\t{out_dir} (objects)\\n\\t{out_dir_plot} (plots)\\n\\t\"\n",
    "      f\"{os.path.join(out_dir, out_subdir_markers)} (markers)\\n\\n\\n\")\n",
    "\n",
    "# Automated Annotation Options\n",
    "file_ann = None  # to skip marker-based annotation\n",
    "# file_ann = os.path.join(\"~/corescpy/examples/markers_lineages.csv\")\n",
    "col_assignment = None  # column in annotation file whose labels to use\n",
    "# col_assignment = \"Bin\"  # all clustering versions use same annotation column\n",
    "# col_assignment = [\"group\", \"Bin\", \"Bin\"]  # (order corresponds to res_list)\n",
    "\n",
    "# Preprocessing Options\n",
    "outlier_mads = {\"n_counts\": [1.25, None]}\n",
    "kws_pp = dict(cell_filter_ngene=[3, None], gene_filter_ncell=[3, None],\n",
    "              gene_filter_ncounts=[3, None], custom_thresholds=None,\n",
    "              kws_scale=dict(max_value=10, zero_center=True),\n",
    "              outlier_mads=outlier_mads, method_norm=\"log\")  # preprocessing\n",
    "# kws_pp = dict(cell_filter_pmt=None, cell_filter_ncounts=[15, None],\n",
    "#               cell_filter_ngene=[3, None], gene_filter_ncell=[3, None],\n",
    "#               gene_filter_ncounts=[3, None], custom_thresholds=None,\n",
    "#               kws_scale=dict(max_value=10, zero_center=True),\n",
    "#               method_norm=\"log\")  # preprocessing keyword arguments\n",
    "# kws_pp = None   # if loading object already preprocessed\n",
    "\n",
    "# Clustering Options\n",
    "genes_subset = None  # use all genes in clustering\n",
    "# genes_subset = list(pd.read_csv(file_ann).iloc[:, 0])  # only cell markers\n",
    "kws_cluster = dict(kws_umap=dict(method=\"rapids\" if gpu else \"umap\"),\n",
    "                   genes_subset=genes_subset,  # use only markers\n",
    "                   use_gpu=gpu, use_highly_variable=False)\n",
    "# res_list = [1.5, 0.75, 0.5]  # resolutions (iterate clustering runs)\n",
    "# min_dist_list = [0, 0.3, 0.5]  # distances (order corresponds to res_list)\n",
    "# n_comps_list = [30, 30, 30]  # PCA components (order same as res_list)\n",
    "res_list = [1.5, 0.5]  # resolutions (iterate different clustering runs)\n",
    "min_dist_list = [0, 0.5]  # distances (order corresponds to res_list)\n",
    "n_comps_list = [30, 30]  # PCA components (order corresponds to res_list)\n",
    "kws_clustering_spatial = None  # specify to perform spatial clustering\n",
    "suffix_clustering_spatial = None  # column key for spatial clustering results\n",
    "# ^ should parallel the parameters, like normal clustering does\n",
    "# e.g., res0pt75_dist0pt3_npc30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Get constants (e.g., column names in metadata), read metadata, create dictionary of clustering parameters (so can iterate across different clustering specifications to make multiple versions, e.g., at multiple resolutions) using `res_list`, `min_dist_list`, and `n_comps_list`, make any output directories (e.g., for processed objects, plots, find markers results, Xenium Explorer cluster files) if any don't exist yet, load data into objects, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                sourceID disease_status    inflamed sampleID\n",
      "Sample                                                     \n",
      "metCRC-1014A2      1014         metCRC  uninflamed   1014A2\n"
     ]
    }
   ],
   "source": [
    "# Get/Set Constants\n",
    "constants_dict = cr.get_panel_constants(panel_id=panel)\n",
    "col_sample_id_o, col_sample_id, col_condition, col_inflamed, col_subject = [\n",
    "    constants_dict[x] if x in constants_dict else None for x in [\n",
    "        \"col_sample_id_o\", \"col_sample_id\", \"col_condition\",\n",
    "        \"col_inflamed\", \"col_subject\"]]\n",
    "col_stricture, key_stricture, col_f, col_tangram, col_segment, col_object = [\n",
    "    constants_dict[x] if (x in constants_dict) else None for x in [\n",
    "        \"col_stricture\", \"key_stricture\", \"col_data_dir\",\n",
    "        \"col_tangram\", \"col_segment\", \"col_object\"]]\n",
    "\n",
    "# Construct Clustering Keyword Dictionary\n",
    "kws_clustering = {}\n",
    "for i in zip(res_list, min_dist_list, n_comps_list):\n",
    "    kws = {**kws_cluster}\n",
    "    kws.update({\"resolution\": i[0], \"n_comps\": i[2],\n",
    "                \"kws_umap\": {**kws_cluster[\"kws_umap\"], \"min_dist\": i[1]}})\n",
    "    suff = str(f\"res{re.sub('[.]', 'pt', str(kws['resolution']))}_dist\"\n",
    "               f\"{re.sub('[.]', 'pt', str(kws['kws_umap']['min_dist']))}\"\n",
    "               f\"_npc{kws['n_comps']}\")  # file path suffix\n",
    "    kws_clustering.update({suff: kws})\n",
    "\n",
    "# Read Metadata\n",
    "metadata = cr.pp.get_metadata_cho(\n",
    "    d_nfs, file_mdf, panel_id=panel, samples=samples, run=run,\n",
    "    capitalize_sample=capitalize_sample)  # get metadata\n",
    "print(\"\\n\\n\", metadata[list(set([\n",
    "    col_sample_id_o, col_subject, col_condition, col_inflamed, col_stricture,\n",
    "    col_segment]).intersection(metadata))])\n",
    "\n",
    "# Annotation File\n",
    "assign = pd.read_csv(file_ann).dropna(subset=col_assignment).set_index(\n",
    "    \"gene\").rename_axis(\"Gene\") if file_ann is not None else None\n",
    "# assign = assign[~assign.Quality.isin([-1])]  # drop low-quality markers\n",
    "if col_assignment is not None and isinstance(col_assignment, str):\n",
    "    col_assignment = [col_assignment] * len(res_list)  # same for each version\n",
    "\n",
    "# Create Objects\n",
    "[os.makedirs(x, exist_ok=True) for x in [\n",
    "    out_dir, out_dir_plot, os.path.join(out_dir, out_subdir_markers),\n",
    "    os.path.join(out_dir, out_subdir_cluster)] if x]  # make out directories\n",
    "kws_init = dict(col_sample_id=col_sample_id, col_subject=col_subject,\n",
    "                col_cell_type=f\"leiden_{list(kws_clustering.keys())[0]}\")\n",
    "selves = [None] * metadata.shape[0]  # to hold different samples\n",
    "for i, x in enumerate(metadata.index.values):\n",
    "    out = os.path.join(out_dir, x + suffix)  # object output path\n",
    "\n",
    "    # Ensure No Overwrite of Prior Preprocessing or Skipping Preprocessing\n",
    "    # without Loading Prior Preprocessed Object\n",
    "    if os.path.exists(out + \".h5ad\"):  # if processed object file exists...\n",
    "        if kws_pp is not None:  # don't overwrite with new preprocessing\n",
    "            raise ValueError(f\"\\n\\nProcessed object already exists!\\n{out}\"\n",
    "                             \".h5ad.\\nSpecify different file suffix, or set \"\n",
    "                             \"`kws_pp` to None to reload processed object.\")\n",
    "    elif kws_pp is None:  # if doesn't exist but pp parameters specified...\n",
    "        raise ValueError(f\"\\n\\nProcessed object doesn't exist!\\n{out}.\\n\"\n",
    "                         \"Specify `kws_pp` to perform new proprocessing \"\n",
    "                         \"or ensure processed object paths are correct.\")\n",
    "\n",
    "    # Load Data into Object (Update with Prior Preprocessed Object if Exists)\n",
    "    selves[i] = cr.Spatial(metadata.loc[x][col_f], library_id=x, **kws_init)\n",
    "    if os.path.exists(out + \".h5ad\") and kws_pp is None:\n",
    "        selves[i].update_from_h5ad(out)  # update with prior preprocessing\n",
    "\n",
    "    # Add metadata to object\n",
    "    for j in metadata.dropna(how=\"all\", axis=1):  # add metadata to .obs\n",
    "        selves[i].rna.obs.loc[:, j] = str(metadata.loc[x][j])\n",
    "    selves[i].rna.obs.loc[:, col_object] = out  # path for processed object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing, Leiden, Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for i, s in enumerate(selves):  # iterate objects (samples)\n",
    "    f_o = None if out_dir is None else str(s.rna.obs[col_object].iloc[0])\n",
    "\n",
    "    # Preprocessing\n",
    "    if kws_pp is not None:\n",
    "        print(\"\\n\\n\", kws_pp, \"\\n\\n\")\n",
    "        _ = s.preprocess(**kws_pp, figsize=(15, 15))  # preprocess\n",
    "    else:\n",
    "        print(f\"\\n\\n***** Using Prior Preprocessing\\n\\n{s.rna.obs.iloc[[0]]}\")\n",
    "\n",
    "    # Clustering at Different Resolutions & Minimum Distances & # of PCs\n",
    "    for j, x in enumerate(kws_clustering):  # iterate clustering versions\n",
    "\n",
    "        # Variables & Output Files\n",
    "        print(f\"\\n\\n{'=' * 80}\\n{x}\\n{'=' * 80}\\n\\n\")\n",
    "        cct, cca = f\"leiden_{x}\", f\"label_{x}\"  # Leiden & annotation columns\n",
    "\n",
    "        # Clustering & Find Markers\n",
    "        if use_prior_clustering is True and cct in s.rna.obs:\n",
    "            print(\"Using prior clustering results...\")\n",
    "        else:\n",
    "            _ = s.cluster(**kws_clustering[x], key_added=cct, out_file=f_o)\n",
    "        _ = s.find_markers(col_cell_type=cct, kws_plot=False)  # DEGs\n",
    "\n",
    "        # Annotation\n",
    "        if assign is not None:  # annotate by marker list\n",
    "            _ = s.annotate_clusters(assign[[col_assignment[j]]],\n",
    "                                    col_cell_type=cct, col_annotation=cca)\n",
    "\n",
    "        # Create Xenium Explorer Cluster Files\n",
    "        if out_dir is not None:\n",
    "            for c in [k for k in [cct, cca] if k in s.rna.obs]:  # Explorer\n",
    "                s.write_clusters(out_dir, col_cell_type=c, overwrite=True,\n",
    "                                 file_prefix=f\"{s._library_id}__\",\n",
    "                                 n_top=out_subdir_markers)\n",
    "\n",
    "        # Write Final Object\n",
    "        if out_dir is not None:\n",
    "            s.write(f_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Clusters Individually (Save in Same PDF if `out_dir` is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, s in enumerate(selves):\n",
    "    for x in kws_clustering:\n",
    "        print(f\"\\n\\n{'=' * 80}\\n{x}\\n{'=' * 80}\\n\\n\")\n",
    "        for c in [f\"leiden_{x}\", f\"label_{x}\", f\"manual_{x}\"]:\n",
    "            if c not in s.rna.obs:\n",
    "                print(f\"\\n\\n{c} not in {s.rna.obs.columns}.\\n\\n\")\n",
    "            if out_dir_plot is not None:\n",
    "                pfp = os.path.join(out_dir_plot, s._library_id, f\"{c}.pdf\")\n",
    "                s.plot_clusters(col_cell_type=c, out_dir=pfp, multi_pdf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Clusters (Overall; No Save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for s in selves:\n",
    "#     for j, x in enumerate(kws_clustering):\n",
    "#         _ = s.plot_spatial(color=list(set([\n",
    "#             f\"leiden_{x}\", f\"label_{x}\"]).intersection(s.rna.obs.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatially-Informed Clustering (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kws_clustering_spatial is not None:\n",
    "    for s in selves:\n",
    "        f_o = None if out_dir is None else str(s.rna.obs[col_object].iloc[0])\n",
    "        cct = f\"leiden_spatial_{suffix_clustering_spatial}\"\n",
    "        _ = s.cluster_spatial(key_added=cct, **kws_clustering_spatial)\n",
    "        _ = s.find_markers(col_cell_type=cct, kws_plot=False)\n",
    "        _ = s.annotate_clusters(assign[[col_assignment[-1]]], col_cell_type=cct,\n",
    "                                col_annotation=f\"annotation_{cct}\")\n",
    "        for c in [cct, f\"annotation_{cct}\"]:\n",
    "            s.plot_spatial(c)\n",
    "            if out_dir is not None:\n",
    "                s.write_clusters(os.path.join(out_dir, out_subdir_cluster),\n",
    "                                 col_cell_type=c, overwrite=True,\n",
    "                                 file_prefix=f\"{s._library_id}__\",\n",
    "                                 n_top=out_subdir_markers)\n",
    "        if out_dir is not None:\n",
    "            s.write(f_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze\n",
    "\n",
    "The first clustering version (first specified in `res_list`) is the cell type column used by default in downstream analyses (because it was specified in `kws_init[\"col_cell_type\"]` when creating the object and thus is stored in `self._columns[\"col_cell_type\"]`). Specify `col_cell_type` as an argument in the following functions to use a different column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centrality Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for s in selves:\n",
    "    s.calculate_centrality(n_jobs=sc.settings.n_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighborhood Enrichment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for s in selves:\n",
    "    _ = s.calculate_neighborhood(figsize=(60, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell Type Co-Occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for s in selves:\n",
    "    _ = s.find_cooccurrence(figsize=(60, 20), kws_plot=dict(wspace=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatially-Variable Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "kws = dict(kws_plot=dict(legend_fontsize=\"large\"), figsize=(15, 15))\n",
    "for s in selves:\n",
    "    _ = s.find_svgs(genes=15, method=\"moran\", n_perms=10, **kws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for s in selves:\n",
    "#     s.plot_spatial(color=[\"TNF\", \"IL23\", col_cell_type])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-bio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
