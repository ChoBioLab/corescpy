{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "```\n",
    "pip install git+https://github.com/scverse/spatialdata.git@main\n",
    "pip install git+https://github.com/scverse/spatialdata-io.git@main\n",
    "```\n",
    "\n",
    "This is the stuff you have to edit; the rest of the sections can run as-is after you've set the needed parameters.\n",
    "\n",
    "---\n",
    "\n",
    "`coord_suffix` must align with \n",
    "* the sub-directory (corresponds to region, e.g., \"mucosa\") under the `dir_coord` directory where the Xenium Explorer-exported selection files are stored, and\n",
    "* the suffixes of the coordinate selection files (see file naming conventions below).\n",
    "  \n",
    "The `AnnData` objects created will have this suffix as well (e.g., `Uninflamed-50452A_mucosa.h5ad`).\n",
    "\n",
    "---\n",
    "\n",
    "Selection files should be named by this convention:\n",
    "`<library_id>_<coord_suffix>.csv`.\n",
    "\n",
    "For example, if `dir_coord` is `.../coordinates/mucosa`, the mucosa selection file for sample 50452A should be under `.../coordinates/mucosa/50452A_mucosa.csv`. \n",
    "\n",
    "More specifically, if the coordinates directory is under `/mnt/cho_lab/disk2/elizabeth/data/shared-xenium-library/outputs/TUQ97N/nebraska/coordinates`, and the selection region is \"mucosa,\"`dir_coord` should be `/mnt/cho_lab/disk2/elizabeth/data/shared-xenium-library/outputs/TUQ97N/nebraska/coordinates/mucosa`, and the full file path for this sample would be `/mnt/cho_lab/disk2/elizabeth/data/shared-xenium-library/outputs/TUQ97N/nebraska/coordinates/mucosa/50452A_mucosa.csv`.\n",
    "\n",
    "---\n",
    "\n",
    "**As with any other file naming schema, suffixes/directory names should not any special characters other than underscores (`_`) (no periods, dashes, spaces, etc.).**\n",
    "\n",
    "N.B. In the above explanation, `library_id` refers to library/original sample ID without condition (e.g., \"50452A\", not \"Uninflamed-50452A\" like in other places). Remember that `coord_suffix` should also be the name of the parent directory of the coordinate file. I include this information in both the directory and file name to prevent mix-ups should files be moved or placed in the wrong folder.\n",
    "\n",
    "Loading the metadata allows us to find the object IDs (e.g., for TUQ97N, object IDs are in the format <condition (Inflamed/Uninflamed/Stricture)><block_id>) corresponding to the sample IDs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data from `https://omnipathdb.org/queries/enzsub?format=json`\n",
      "Downloading data from `https://omnipathdb.org/queries/interactions?format=json`\n",
      "Downloading data from `https://omnipathdb.org/queries/complexes?format=json`\n",
      "Downloading data from `https://omnipathdb.org/queries/annotations?format=json`\n",
      "Downloading data from `https://omnipathdb.org/queries/intercell?format=json`\n",
      "Downloading data from `https://omnipathdb.org/about?format=text`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sample\n",
       "uninflamed-50006B    50006\n",
       "uninflamed-50217B    50217\n",
       "Name: subject_id, dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import functools\n",
    "import traceback\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "import shapely.validation\n",
    "from shapely.geometry import box\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "# import spatialdata_plot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import corescpy as cr\n",
    "\n",
    "# Files & Directories\n",
    "panel = \"TUQ97N\"  # Xenium panel ID\n",
    "direc = \"/mnt/cho_lab/bbdata2/\"  # mounted NFS with Xenium raw data\n",
    "obj_dir = os.path.join(  # this path will point to where original .h5ads are\n",
    "    \"/mnt/cho_lab/disk2\",  # Spark entry directory\n",
    "    \"elizabeth\",  # change if objects in different person's/your folder\n",
    "    f\"data/shared-xenium-library/outputs/{panel}/nebraska\")  # subdirectory\n",
    "out_new = os.path.join(\"/mnt/cho_lab/disk2\", os.getlogin(),  # for new objects\n",
    "                       f\"data/shared-xenium-library/outputs/{panel}/nebraska\")\n",
    "mdf = str(\"/mnt/cho_lab/disk2/elizabeth/data/shared-xenium-library/samples_\"\n",
    "          f\"{panel}.csv\")  # metadata file path (for now; will soon be on NFS)\n",
    "\n",
    "# Main\n",
    "write_object = True  # change to True when you're ready to save objects\n",
    "overwrite = False  # overwrite if already exists?\n",
    "regions = [\"mucosa\", \"serosa\", \"myenteric_plexus\", \"submucosa\",\n",
    "           \"smc_circular\", \"smc_longitudinal\"]\n",
    "col_leiden = \"leiden_res1pt5_dist0_npc30\"\n",
    "col_ann = \"Bucket\"\n",
    "cells_as_circles = True\n",
    "allow_make_valid = True  # allow shapely package to correct invalid geometries\n",
    "libs = [  # sample IDs from patients for whom we have all conditions\n",
    "    \"50452A\", \"50452B\", \"50452C\",  # old segmentation\n",
    "    \"50006A\", \"50006B\", \"50006C\",  # rest are new segmentation\n",
    "    \"50217A\", \"50217B\", \"50217C\",\n",
    "    \"50336B\", \"50336C\", \"50336A\",\n",
    "    \"50403A2\", \"50403B\", \"50403C1\"\n",
    "]  # excludes low-quality sample/condition replicates 50403A1 & 50403C2\n",
    "# libs = [\"50006A\", \"50006B\", \"50217A\", \"50217B\", \"50336B\", \"50336C\",\n",
    "#         \"50403B\", \"50403A2\"]  # just inflamed/uninflamed (no strictures)\n",
    "# libs = None  # to run all available samples\n",
    "libs = [\"50006B\", \"50217B\"]\n",
    "input_suffix = \"\"  # in case want to crop objects with some suffix\n",
    "# due to creation of a subsidiary object, e.g., for\n",
    "# \"Stricture-50452C_downsampled.h5ad\"\n",
    "# input_suffix would be \"_downsampled\". For \"main\" objects, input_suffix=\"\"\n",
    "plot = True  # could slow process down if large samples/cropped area\n",
    "\n",
    "#  Your Folders\n",
    "constants_dict = cr.get_panel_constants(panel_id=panel)\n",
    "\n",
    "# Constants (Shouldn't Need Edits Unless Extreme Process Changes)\n",
    "cso, col_sample, col_condition, col_inflamed, col_subject = [\n",
    "    constants_dict[x] if x in constants_dict else None for x in [\n",
    "        \"col_sample_id_o\", \"col_sample_id\", \"col_condition\",\n",
    "        \"col_inflamed\", \"col_subject\"]]\n",
    "dir_data = os.path.join(direc, f\"outputs/{panel}\")\n",
    "files = functools.reduce(lambda i, j: i + j, [[os.path.join(\n",
    "    run, i) for i in os.listdir(os.path.join(\n",
    "        dir_data, run))] for run in os.listdir(dir_data)])  # all data paths\n",
    "os.makedirs(obj_dir, exist_ok=True)  # make output directory if needed\n",
    "metadata = cr.pp.get_metadata_cho(direc, mdf, panel_id=panel, samples=libs)\n",
    "metadata[col_subject]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset Data by Coordinate Files & Write Cropped Objects\n",
    "\n",
    "Subset the data by coordinates (`corescpy` can use Xenium Explorer-exported manual selection files to get those coordinates) and then write the cropped objects to `obj_dir/<coord_suffix>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in libs:  # iterate samples\n",
    "    print(f\"\\n\\n{'=' * 80}\\n{s}\\n{'=' * 80}\\n\\n\")\n",
    "    fff = os.path.join(dir_data, np.array(files)[np.where([\n",
    "        s == os.path.basename(x).split(\"__\")[2].split(\"-\")[0]\n",
    "        for x in files])[0][0]])  # sample's Xenium data directory path\n",
    "    lib = metadata.reset_index().set_index(cso).loc[s][col_sample]\n",
    "    file_obj_proc = os.path.join(obj_dir, f\"{lib}{input_suffix}.h5ad\")\n",
    "    if overwrite is False:  # skip entirely if all crops exist & no overwrite\n",
    "        all_files = [os.path.join(out_new, \"objects_cropped\",\n",
    "                                  r, f'{lib}_{r}.h5ad') for r in regions]\n",
    "        if overwrite is False and all([os.path.exists(r) for r in all_files]):\n",
    "            print(f\"*** All subsets {', '.join(all_files)} already exist\")\n",
    "            continue\n",
    "    self = cr.Spatial(fff, library_id=lib,\n",
    "                      cells_as_circles=cells_as_circles)  # load original data\n",
    "    adata = sc.read_h5ad(file_obj_proc)  # processed adata\n",
    "    # self.update_from_h5ad(file_obj_proc)  # update with processed object\n",
    "    for coord_suffix in regions:\n",
    "        sdata = None\n",
    "        print(f\"\\n\\n\\t\\t{'*' * 40}\\n\\t\\t{coord_suffix}\\n\\t\\t{'*' * 40}\\n\\n\")\n",
    "        dir_coord = os.path.join(\n",
    "            out_new, \"coordinates\", coord_suffix)  # coordinates (NFS soon?)\n",
    "        out = os.path.join(out_new, \"objects_cropped\", coord_suffix)  # path\n",
    "        os.makedirs(out, exist_ok=True)  # make sub-directory for new objects?\n",
    "        file_coord = os.path.join(dir_coord, s + f\"_{coord_suffix}.csv\")\n",
    "        file_obj_crop = os.path.join(out, f\"{lib}_{coord_suffix}.h5ad\")\n",
    "        if overwrite is False and os.path.exists(file_obj_crop):\n",
    "            print(f\"*** Subset {file_obj_crop} already exists\")\n",
    "            continue\n",
    "        if not os.path.exists(file_coord):\n",
    "            print(f\"*** Coordinate file {file_coord} doesn't exist\")\n",
    "            continue\n",
    "        print(f\"\\n\\nData: {fff}\\nObject: {file_obj_proc}\"\n",
    "              f\"\\nCoordinates: {file_coord}\\nOuput: {file_obj_crop}\")\n",
    "        # try:\n",
    "        sdata = self.crop(\n",
    "            file_coord, allow_make_valid=allow_make_valid)  # crop\n",
    "        i_x = sdata.table.obs[\"cell_id\"].copy()\n",
    "        # orig = sdata.table.copy()\n",
    "        del sdata.table\n",
    "        sdata.table = adata[adata.obs[\"cell_id\"].isin(i_x[\n",
    "            i_x.isin(adata.obs[\"cell_id\"])])]  # coordinate- & pp-filtered\n",
    "        if plot:\n",
    "            try:\n",
    "                sdata.pl.render_labels(\"cell_labels\").pl.show()  # plot\n",
    "            except Exception:\n",
    "                pass\n",
    "        if write_object is True:\n",
    "            sdata.table.write_h5ad(file_obj_crop)  # write cropped\n",
    "        # except Exception:\n",
    "        #     print(traceback.format_exc(),\n",
    "        #           f\"Cropping \\n\\n{s}, {coord_suffix} failed!\")\n",
    "print(\"\\n\\nCompleted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = gpd.GeoDataFrame(geometry=coords)\n",
    "dff[\"geometries\"] = dff.apply(lambda x: [g for g in x.geometry.geoms], axis=1)\n",
    "dff = dff.explode(column=\"geometries\").drop(columns=\"geometry\").set_geometry(\"geometries\").rename_geometry(\"geometry\")\n",
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kws = {\"target_coordinate_system\": \"global\", \"filter_table\": True}\n",
    "coords = cr.pp.xenium_explorer_selection(file_coord)\n",
    "print(type(coords))\n",
    "p_coords = gpd.GeoSeries(coords).plot()\n",
    "p_coords.set_title(\"Input\")\n",
    "plt.show()\n",
    "coords = shapely.validation.make_valid(coords)\n",
    "print(type(coords))\n",
    "p_coords_new = gpd.GeoSeries(coords).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for i, p in enumerate(coords.geoms):  # Handle each Polygon in MultiPolygon\n",
    "    data[f\"Selection { + 1i}\"] = []\n",
    "    for xi, yi in zip(*p.exterior.xy):\n",
    "        data[f\"Selection { + 1i}\"] += [{\"X\": xi * p_size, \"Y\": yi * p_size}]\n",
    "    data[f\"Selection {i + 1}\"] = pd.DataFrame(data[f\"Selection { + 1i}\"])\n",
    "data = pd.concat(data, names=[\"Selection\"]).reset_index(1, drop=True)\n",
    "cols = [f\"\", \", \".join(data.reset_index().Selection.unique())]\n",
    "data = pd.concat([pd.DataFrame([[\"\", \"\"]], index=[\n",
    "    \"Areas (µm^2): x\"], columns=cols), pd.DataFrame(data.columns, columns=[\n",
    "        \"Selection\"], index=cols).T, pd.DataFrame(np.array(\n",
    "            data), index=data.index, columns=cols)]).rename_axis(\n",
    "                \"#Selection name: \")  # Xenium format\n",
    "# data.to_csv(os.path.join(out_new, \"coordinates\", \"mucosa\",\n",
    "#                          \"50217A_mucosa.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata_crop = self.adata.query.polygon(coords, **kws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import squidpy as sq\n",
    "\n",
    "sq.pl.spatial_scatter(\n",
    "    sdata_crop.table, library_id=\"spatial\", shape=None,\n",
    "    color=None, wspace=0.4, legend_loc=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_x = sdata_crop.table.obs[\"cell_id\"]\n",
    "ann = adata[adata.obs[\"cell_id\"].isin(i_x[\n",
    "                i_x.isin(adata.obs[\"cell_id\"])])]  # coordinate- & pp-filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.pl.spatial_scatter(\n",
    "    ann, library_id=\"spatial\", shape=None,\n",
    "    color=\"bucket_res1pt5_dist0_npc30\", wspace=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.write_h5ad(file_obj_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.obs[\"bucket_res1pt5_dist0_npc30\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        coord_suffix = \"submucosa\"\n",
    "        dir_coord = os.path.join(\n",
    "            out_new, \"coordinates\", coord_suffix)  # coordinates (NFS soon?)\n",
    "        out = os.path.join(out_new, \"objects_cropped\", coord_suffix)  # path\n",
    "        os.makedirs(out, exist_ok=True)  # make sub-directory for new objects?\n",
    "        file_coord = os.path.join(dir_coord, s + f\"_{coord_suffix}.csv\")\n",
    "        file_obj_crop = os.path.join(out, f\"{lib}_{coord_suffix}.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    coords = cr.pp.xenium_explorer_selection(file_coord)\n",
    "                    print(coords.is_valid)\n",
    "                    coords = shapely.validation.make_valid(coords)\n",
    "                    coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatialdata.SpatialData.get_annotated_regions(sdata_crop.table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata_crop.shapes[\"cell_circles\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata_crop.tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata.tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = self.adata.query.polygon(coords, **kws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata.labels[\"cell_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata.shapes[\"cell_circles\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sdata.tables[\"table\"].write_h5ad(file_obj_crop)  # write cropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Setting Regions by Exclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olm = cr.pp.xenium_explorer_selection(os.path.join(\n",
    "    out_new, \"coordinates\", \"smc_longitudinal\",\n",
    "    f\"{s_o}_smc_longitudinal.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_valid = shapely.validation.make_valid(whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leftover = shapely.validation.make_valid(whole_valid.difference(muc))\n",
    "for x in [mye, icm, olm, ser]:\n",
    "    leftover = shapely.validation.make_valid(whole_valid.difference(x))\n",
    "leftover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole = shapely.Polygon(list(self.adata.shapes[\"cell_circles\"].geometry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_o = \"50217A\"\n",
    "out_new = str(\"/mnt/cho_lab/disk2/elizabeth/data/shared-xenium-library/\"\n",
    "              \"outputs/TUQ97N/nebraska\")\n",
    "# mid = pd.read_csv(os.path.join(out_new, f\"coordinates/{s_o}_mid.csv\"),\n",
    "#                   index_col=0).iloc[:, 0]\n",
    "# mid = gpd.GeoDataFrame(mid, geometry=gpd.GeoSeries.from_wkt(\n",
    "#     mid), crs=\"EPSG:4326\")\n",
    "# mid = mid.geometry.apply(lambda geom: shapely.Polygon(geom)).iloc[0]\n",
    "mye, ser, muc, icm = [cr.pp.xenium_explorer_selection(os.path.join(\n",
    "    out_new, \"coordinates\", r, f\"{s_o}_{r}.csv\"))\n",
    "            for r in [\"myenteric_plexus\", \"serosa\", \"mucosa\", \"smc_circular\"]]\n",
    "mye, ser, muc, icm = [x if x.is_valid else shapely.validation.make_valid(\n",
    "    x) for x in [mye, ser, muc, icm]]\n",
    "# muc = cr.pp.xenium_explorer_selection(os.path.join(\n",
    "#     out_new, \"coordinates\", \"mucosa\", f\"{s_o}_mucosa_full.csv\"))\n",
    "# muc = shapely.validation.make_valid(muc)\n",
    "# other = shapely.validation.make_valid(cr.pp.xenium_explorer_selection(\n",
    "#     os.path.join(out_new, \"coordinates/50217A_other.csv\")))\n",
    "# smc = shapely.validation.make_valid(cr.pp.xenium_explorer_selection(\n",
    "#     os.path.join(out_new, \"coordinates/50217A_smc.csv\")))\n",
    "# whole = shapely.validation.make_valid(cr.pp.xenium_explorer_selection(\n",
    "#     os.path.join(out_new, \"coordinates/50217A_all.csv\")))\n",
    "# olm = cr.pp.xenium_explorer_selection(os.path.join(\n",
    "#     out_new, \"coordinates\", \"smc_longitudinal\",\n",
    "#     f\"{s_o}_smc_longitudinal.csv\"))\n",
    "other, olm, smc, whole = None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in zip([\"whole\", \"mye\", \"ser\", \"muc\", \"smc\", \"icm\", \"olm\"], [\n",
    "        whole, mye, ser, muc, smc, icm, olm]):\n",
    "    if r[1] is None:\n",
    "        continue\n",
    "    p_coords = gpd.GeoSeries(r[1]).plot()\n",
    "    p_coords.set_title(r[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olm = smc.difference(mye).difference(icm).difference(ser)\n",
    "olm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = whole.difference(muc).difference(icm).difference(olm).difference(\n",
    "    mye).difference(ser).difference(smc)\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords.boundary.xy[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([[j / 100 for j in i] for i in coords.boundary.xy], index=[\"X\", \"Y\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapely.Polygon(pd.DataFrame([[j / 10 for j in i] for i in coords.boundary.xy], index=[\"X\", \"Y\"]).T.values / 0.2125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.rna.obsm[\"spatial\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kws = {\"target_coordinate_system\": \"global\",\n",
    "        \"filter_table\": True}\n",
    "\n",
    "sdata_crop = self.adata.query.polygon(shapely.Polygon(pd.DataFrame([[j / 100 for j in i] for i in coords.boundary.xy], index=[\"X\", \"Y\"]).T.values), **kws)\n",
    "sdata_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_x = sdata.table.obs[\"cell_id\"].copy()\n",
    "orig = sdata.table.copy()\n",
    "del sdata.table\n",
    "sdata.table = adata[adata.obs[\"cell_id\"].isin(i_x[\n",
    "    i_x.isin(list(adata.obs[\"cell_id\"]))])]  # coordinate- & pp-filtered\n",
    "if plot:\n",
    "    try:\n",
    "        sdata.pl.render_labels(\"cell_labels\").pl.show()  # plot\n",
    "    except Exception:\n",
    "        pass\n",
    "if write_object is True:\n",
    "    sdata.table.write_h5ad(file_obj_crop)  # write cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_size = 0.2125  # pixel size\n",
    "\n",
    "data = {}\n",
    "for i, p in enumerate(olm.geoms):  # Handle each Polygon in MultiPolygon\n",
    "    data[f\"Selection {i + 1}\"] = []\n",
    "    for xi, yi in zip(*p.exterior.xy):\n",
    "        data[f\"Selection {i + 1}\"] += [{\"X\": xi * p_size, \"Y\": yi * p_size}]\n",
    "    data[f\"Selection {i + 1}\"] = pd.DataFrame(data[f\"Selection {i + 1}\"])\n",
    "data = pd.concat(data, names=[\"Selection\"]).reset_index(1, drop=True)\n",
    "cols = [f\"\", \", \".join(data.reset_index().Selection.unique())]\n",
    "data = pd.concat([pd.DataFrame([[\"\", \"\"]], index=[\n",
    "    \"Areas (µm^2): x\"], columns=cols), pd.DataFrame(data.columns, columns=[\n",
    "        \"Selection\"], index=cols).T, pd.DataFrame(np.array(\n",
    "            data), index=data.index, columns=cols)]).rename_axis(\n",
    "                \"#Selection name: \")  # Xenium format\n",
    "# os.system(\"mv \" + os.path.join(\n",
    "#     out_new, \"coordinates\", \"smc_longitudinal\",\n",
    "#     \"50217A_smc_longitudinal.csv\") + \" \" + os.path.join(\n",
    "#         out_new, \"coordinates\", \"smc_longitudinal\",\n",
    "#         \"50217A_smc_longitudinal_old.csv\"))\n",
    "# data.to_csv(os.path.join(out_new, \"coordinates\", \"smc_longitudinal\",\n",
    "#                          \"50217A_smc_longitudinal.csv\"))\n",
    "\n",
    "data = {}\n",
    "for i, p in enumerate(muc.geoms):  # Handle each Polygon in MultiPolygon\n",
    "    data[f\"Selection {i + 1}\"] = []\n",
    "    for xi, yi in zip(*p.exterior.xy):\n",
    "        data[f\"Selection {i + 1}\"] += [{\"X\": xi * p_size, \"Y\": yi * p_size}]\n",
    "    data[f\"Selection {i + 1}\"] = pd.DataFrame(data[f\"Selection {i + 1}\"])\n",
    "data = pd.concat(data, names=[\"Selection\"]).reset_index(1, drop=True)\n",
    "cols = [f\"\", \", \".join(data.reset_index().Selection.unique())]\n",
    "data = pd.concat([pd.DataFrame([[\"\", \"\"]], index=[\n",
    "    \"Areas (µm^2): x\"], columns=cols), pd.DataFrame(data.columns, columns=[\n",
    "        \"Selection\"], index=cols).T, pd.DataFrame(np.array(\n",
    "            data), index=data.index, columns=cols)]).rename_axis(\n",
    "                \"#Selection name: \")  # Xenium format\n",
    "# os.system(\"mv \" + os.path.join(\n",
    "#     out_new, \"coordinates\", \"mucosa\",\n",
    "#     \"50217A_mucosa.csv\") + \" \" + os.path.join(\n",
    "#         out_new, \"coordinates\", \"mucosa\", \"50217A_mucosa_old.csv\"))\n",
    "# data.to_csv(os.path.join(out_new, \"coordinates\", \"mucosa\",\n",
    "#                          \"50217A_mucosa.csv\"))\n",
    "\n",
    "data = {}\n",
    "for i, p in enumerate(icm.geoms):  # Handle each Polygon in MultiPolygon\n",
    "    data[f\"Selection {i + 1}\"] = []\n",
    "    for xi, yi in zip(*p.exterior.xy):\n",
    "        data[f\"Selection {i + 1}\"] += [{\"X\": xi * p_size, \"Y\": yi * p_size}]\n",
    "    data[f\"Selection {i + 1}\"] = pd.DataFrame(data[f\"Selection {i + 1}\"])\n",
    "data = pd.concat(data, names=[\"Selection\"]).reset_index(1, drop=True)\n",
    "cols = [f\"\", \", \".join(data.reset_index().Selection.unique())]\n",
    "data = pd.concat([pd.DataFrame([[\"\", \"\"]], index=[\n",
    "    \"Areas (µm^2): x\"], columns=cols), pd.DataFrame(data.columns, columns=[\n",
    "        \"Selection\"], index=cols).T, pd.DataFrame(np.array(\n",
    "            data), index=data.index, columns=cols)]).rename_axis(\n",
    "                \"#Selection name: \")  # Xenium format\n",
    "# os.system(\"mv \" + os.path.join(\n",
    "#     out_new, \"coordinates\", \"smc_circular\",\n",
    "#     \"50217A_smc_circular.csv\") + \" \" + os.path.join(\n",
    "#         out_new, \"coordinates\", \"smc_circular\",\n",
    "#         \"50217A_smc_circular_old.csv\"))\n",
    "# data.to_csv(os.path.join(out_new, \"coordinates\", \"smc_circular\",\n",
    "#                          \"50217A_smc_circular.csv\"))\n",
    "\n",
    "data = {}\n",
    "for i, p in enumerate(sub.geoms):  # Handle each Polygon in MultiPolygon\n",
    "    data[f\"Selection {i + 1}\"] = []\n",
    "    for xi, yi in zip(*p.exterior.xy):\n",
    "        data[f\"Selection {i + 1}\"] += [{\"X\": xi * p_size, \"Y\": yi * p_size}]\n",
    "    data[f\"Selection {i + 1}\"] = pd.DataFrame(data[f\"Selection {i + 1}\"])\n",
    "data = pd.concat(data, names=[\"Selection\"]).reset_index(1, drop=True)\n",
    "cols = [f\"\", \", \".join(data.reset_index().Selection.unique())]\n",
    "data = pd.concat([pd.DataFrame([[\"\", \"\"]], index=[\n",
    "    \"Areas (µm^2): x\"], columns=cols), pd.DataFrame(data.columns, columns=[\n",
    "        \"Selection\"], index=cols).T, pd.DataFrame(np.array(\n",
    "            data), index=data.index, columns=cols)]).rename_axis(\n",
    "                \"#Selection name: \")  # Xenium format\n",
    "# os.system(\"mv \" + os.path.join(\n",
    "#     out_new, \"coordinates\", \"submucosa\",\n",
    "#     \"50217A_submucosa.csv\") + \" \" + os.path.join(\n",
    "#         out_new, \"coordinates\", \"submucosa\",\n",
    "#         \"50217A_submucosa_old.csv\"))\n",
    "# data.to_csv(os.path.join(out_new, \"coordinates\", \"submucosa\",\n",
    "#                          \"50217A_submucosa.csv\"))\n",
    "\n",
    "\n",
    "# Example if Not MultiPolygon\n",
    "# data = {}\n",
    "# for i, p in enumerate(coords.boundary.geoms)\n",
    "#     data[f\"Selection {i + 1}\"] = []\n",
    "#     for xi, yi in zip(*p.xy):\n",
    "#         data[f\"Selection {i + 1}\"] += [{\"X\": xi * p_size, \"Y\": yi * p_size}]\n",
    "#     data[f\"Selection {i + 1}\"] = pd.DataFrame(data[f\"Selection {i + 1}\"])\n",
    "# data = pd.concat(data, names=[\"Selection\"]).reset_index(1, drop=True)\n",
    "# cols = [f\"\", \", \".join(data.reset_index().Selection.unique())]\n",
    "# data = pd.concat([pd.DataFrame([[\"\", \"\"]], index=[\n",
    "#     \"Areas (µm^2): x\"], columns=cols), pd.DataFrame(data.columns, columns=[\n",
    "#         \"Selection\"], index=cols).T, pd.DataFrame(np.array(\n",
    "#             data), index=data.index, columns=cols)]).rename_axis(\n",
    "#                 \"#Selection name: \")  # Xenium format\n",
    "\n",
    "# Or\n",
    "# data = pd.DataFrame(coords.boundary.xy, index=[\"X\", \"Y\"]).T.assign(\n",
    "#     Selection=\"Selection 1\").set_index(\"Selection\")\n",
    "# cols = [f\"\", \", \".join(data.reset_index().Selection.unique())]\n",
    "# data = pd.concat([pd.DataFrame([[\"\", \"\"]], index=[\n",
    "#     \"Areas (µm^2): x\"], columns=cols), pd.DataFrame(data.columns, columns=[\n",
    "#         \"Selection\"], index=cols).T, pd.DataFrame(np.array(\n",
    "#             data), index=data.index, columns=cols)]).rename_axis(\n",
    "#                 \"#Selection name: \")  # Xenium format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in zip([\"whole\", \"mye\", \"ser\", \"muc\", \"smc\", \"icm\", \"olm\"], [\n",
    "        whole, mye, ser, muc, smc, icm, olm]):\n",
    "    if r[1] is None:\n",
    "        continue\n",
    "    p_coords = gpd.GeoSeries(r[1]).plot()\n",
    "    p_coords.set_title(r[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_suffix=\"submucosa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # s = \"50217A\"\n",
    "\n",
    "        # fff = os.path.join(dir_data, np.array(files)[np.where([\n",
    "        #     s == os.path.basename(x).split(\"__\")[2].split(\"-\")[0]\n",
    "        #     for x in files])[0][0]])  # sample's Xenium data directory path\n",
    "        # lib = metadata.reset_index().set_index(cso).loc[s][col_sample]\n",
    "        # file_obj_proc = os.path.join(obj_dir, f\"{lib}{input_suffix}.h5ad\")\n",
    "        # self = cr.Spatial(fff, library_id=lib,\n",
    "        #                 cells_as_circles=cells_as_circles)  # load original data\n",
    "        # adata = sc.read_h5ad(file_obj_proc)  # processed adata\n",
    "        # print(f\"\\n\\n\\t\\t{'*' * 40}\\n\\t\\t{s}\\n\\t\\t{'*' * 40}\\n\\n\")\n",
    "        dir_coord = os.path.join(\n",
    "            out_new, \"coordinates\", coord_suffix)  # coordinates (NFS soon?)\n",
    "        out = os.path.join(out_new, \"objects_cropped\", coord_suffix)  # path\n",
    "        os.makedirs(out, exist_ok=True)  # make sub-directory for new objects?\n",
    "        file_coord = os.path.join(dir_coord, s + f\"_{coord_suffix}.csv\")\n",
    "        file_obj_crop = os.path.join(out, f\"{lib}_{coord_suffix}.h5ad\")\n",
    "        print(f\"\\n\\nData: {fff}\\nObject: {file_obj_proc}\"\n",
    "              f\"\\nCoordinates: {file_coord}\\nOuput: {file_obj_crop}\")\n",
    "        sdata = self.crop(\n",
    "            file_coord, allow_make_valid=allow_make_valid)  # crop\n",
    "        i_x = sdata.table.obs[\"cell_id\"].copy()\n",
    "        del sdata.table\n",
    "        sdata.table = adata[adata.obs[\"cell_id\"].isin(i_x[\n",
    "            i_x.isin(adata.obs[\"cell_id\"])])]  # coordinate- & pp-filtered\n",
    "        sdata.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_obj_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # s = \"50217A\"\n",
    "\n",
    "        # fff = os.path.join(dir_data, np.array(files)[np.where([\n",
    "        #     s == os.path.basename(x).split(\"__\")[2].split(\"-\")[0]\n",
    "        #     for x in files])[0][0]])  # sample's Xenium data directory path\n",
    "        # lib = metadata.reset_index().set_index(cso).loc[s][col_sample]\n",
    "        # file_obj_proc = os.path.join(obj_dir, f\"{lib}{input_suffix}.h5ad\")\n",
    "        # self = cr.Spatial(fff, library_id=lib,\n",
    "        #                 cells_as_circles=cells_as_circles)  # load original data\n",
    "        # adata = sc.read_h5ad(file_obj_proc)  # processed adata\n",
    "        # print(f\"\\n\\n\\t\\t{'*' * 40}\\n\\t\\t{s}\\n\\t\\t{'*' * 40}\\n\\n\")\n",
    "        dir_coord = os.path.join(\n",
    "            out_new, \"coordinates\", coord_suffix)  # coordinates (NFS soon?)\n",
    "        out = os.path.join(out_new, \"objects_cropped\", coord_suffix)  # path\n",
    "        os.makedirs(out, exist_ok=True)  # make sub-directory for new objects?\n",
    "        file_coord = os.path.join(dir_coord, s + f\"_{coord_suffix}.csv\")\n",
    "        file_obj_crop = os.path.join(out, f\"{lib}_{coord_suffix}.h5ad\")\n",
    "        print(f\"\\n\\nData: {fff}\\nObject: {file_obj_proc}\"\n",
    "              f\"\\nCoordinates: {file_coord}\\nOuput: {file_obj_crop}\")\n",
    "        sdata = self.crop(\n",
    "            file_coord, allow_make_valid=allow_make_valid)  # crop\n",
    "        i_x = sdata.table.obs[\"cell_id\"].copy()\n",
    "        del sdata.table\n",
    "        sdata.table = adata[adata.obs[\"cell_id\"].isin(i_x[\n",
    "            i_x.isin(adata.obs[\"cell_id\"])])]  # coordinate- & pp-filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata.table.write_h5ad(\"/mnt/cho_lab/disk2/elizabeth/data/shared-xenium-library/outputs/TUQ97N/nebraska/objects_cropped/smc_longitudinal/Inflamed-50217A_smc_longitudinal.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata_right = self.adata.query.polygon(poly_right, **kws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kws = {\"target_coordinate_system\": \"global\", \"filter_table\": True}\n",
    "# dff = pd.read_csv(file_coord, skiprows=2)\n",
    "# poly = dff.groupby(\"Selection\").apply(lambda x: shapely.Polygon(\n",
    "#     x.drop(\"Selection\", axis=1).values / 0.2125))\n",
    "# poly_right = poly.iloc[4]\n",
    "# poly_left = shapely.MultiPolygon(list(poly.drop(poly.index.values[4])))\n",
    "sdata_left = self.adata.query.polygon(poly_left, **kws)\n",
    "sdata_right = self.adata.query.polygon(poly_right, **kws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left, right = sdata_left.table.copy(), sdata_right.table.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = spatialdata.concatenate([sdata_left, sdata_right],\n",
    "                                concatenate_tables=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.adata.shapes[\"cell_circles\"][\"radius\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.rna[self.rna.obs[\"cell_id\"].isin(sdata.shapes[\"cell_boundaries\"].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.adata.get_annotated_regions(self.adata.table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spatialdata_io._constants._constants import XeniumKeys\n",
    "\n",
    "transform = Scale([1.0 / 0.2125, 1.0 / 0.2125], axes=(\"x\", \"y\"))\n",
    "radii = np.sqrt(self.rna.obs[XeniumKeys.CELL_NUCLEUS_AREA].to_numpy() / np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.rna.obs[XeniumKeys.CELL_NUCLEUS_AREA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i[1] for i in self.adata._gen_elements()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_regions = set(table.obs[\"cell_id\"].unique().tolist())\n",
    "target_element_set = [\"cell_boundaries\"]\n",
    "symmetric_difference = found_regions.symmetric_difference(target_element_set)\n",
    "len(symmetric_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.adata._change_table_annotation_target(self.adata.table, \"cell_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.uns.get(\"spatialdata_attrs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.adata.set_table_annotates_spatialelement(\"table\", region=\"cell_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# element = self.adata.shapes[\"cell_circles\"]\n",
    "# buffered_df = element.copy()\n",
    "# buffered = to_polygons(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coord_suffix = \"myenteric_plexus\"\n",
    "# coord_suffix = \"smc_circular\"\n",
    "coord_suffix = \"smc_longitudinal\"\n",
    "# s = \"50006B\"\n",
    "# s =  \"50217A\"\n",
    "# s = \"50217B\"\n",
    "\n",
    "# for s in [\"50006A\", \"50217A\", \"50403B\"]:\n",
    "for s in [\"50006A\"]:\n",
    "    fff = os.path.join(dir_data, np.array(files)[np.where([\n",
    "        s == os.path.basename(x).split(\"__\")[2].split(\"-\")[0]\n",
    "        for x in files])[0][0]])  # sample's Xenium data directory path\n",
    "    lib = metadata.reset_index().set_index(cso).loc[s][col_sample]\n",
    "    file_obj_proc = os.path.join(obj_dir, f\"{lib}{input_suffix}.h5ad\")\n",
    "    dir_coord = os.path.join(\n",
    "        out_new, \"coordinates\", coord_suffix)  # coordinates (NFS soon?)\n",
    "    out = os.path.join(out_new, \"objects_cropped\", coord_suffix)  # path\n",
    "    os.makedirs(out, exist_ok=True)  # make sub-directory for new objects?\n",
    "    file_coord = os.path.join(dir_coord, s + f\"_{coord_suffix}.csv\")\n",
    "    file_obj_crop = os.path.join(out, f\"{lib}_{coord_suffix}.h5ad\")\n",
    "    if os.path.exists(file_obj_crop):\n",
    "        continue\n",
    "    self = cr.Spatial(fff, library_id=lib,\n",
    "                      cells_as_circles=cells_as_circles)  # load original data\n",
    "    adata = sc.read_h5ad(file_obj_proc)  # processed adata\n",
    "    # coords = cr.pp.xenium_explorer_selection(file_coord, pixel_size=0.2125)\n",
    "    # if isinstance(coords, list):  # if multiple selections...\n",
    "    #     coords = shapely.MultiPolygon(coords)  # ...union of areas\n",
    "    # kws = {\"target_coordinate_system\": \"global\", \"filter_table\": True}\n",
    "    # try:\n",
    "    #     sdata = self.adata.query.polygon(coords, **kws)  # crop\n",
    "    # except Exception as err:\n",
    "    #     if allow_make_valid:\n",
    "    #         warn(\"\\n\\n*** Invalid geometry! Making geometry valid.\"\n",
    "    #              \"Check new coordinates!\\n\\n\")\n",
    "    #         coords_new = shapely.validation.make_valid(coords)\n",
    "    #         sdata = self.adata.query.polygon(coords_new, **kws)  # crop\n",
    "    #     else:\n",
    "    #         raise err\n",
    "    # i_x = sdata.table.obs[\"cell_id\"].copy()\n",
    "    # del sdata.table\n",
    "    # sdata.table = adata[adata.obs[\"cell_id\"].isin(i_x[\n",
    "    #     i_x.isin(adata.obs[\"cell_id\"])])]\n",
    "    sdata = self.crop(file_coord, allow_make_valid=allow_make_valid)\n",
    "    if not os.path.exists(file_obj_crop):\n",
    "        sdata.tables[\"table\"].write_h5ad(os.path.join(\n",
    "            out, f\"{self._library_id}_{coord_suffix}.h5ad\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import shapely\n",
    "\n",
    "#Create a test dataframe\n",
    "    #The first line is valid, the second is not, it starts and ends at the same point\n",
    "wkts  = [\"LINESTRING (30 10, 10 30, 40 40)\", \"LINESTRING (30 10, 30 10)\"]\n",
    "geometries = [shapely.wkt.loads(x) for x in wkts] #Create shapely geometries\n",
    "df = gpd.GeoDataFrame(geometry=geometries) #And a data frame\n",
    "\n",
    "invalid = df.loc[~df.geometry.is_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.validation import make_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import squidpy as sq\n",
    "\n",
    "sq.pl.spatial_scatter(sdata_crop.table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata.pl.render_labels(\"cell_labels\").pl.show()  # plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = self.gen_spatial_elements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr.pp.xenium_explorer_selection(file_coord)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
