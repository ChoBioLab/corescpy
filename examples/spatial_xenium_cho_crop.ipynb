{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "```\n",
    "pip install git+https://github.com/scverse/spatialdata.git@main\n",
    "pip install git+https://github.com/scverse/spatialdata-io.git@main\n",
    "```\n",
    "\n",
    "This is the stuff you have to edit; the rest of the sections can run as-is after you've set the needed parameters.\n",
    "\n",
    "---\n",
    "\n",
    "`coord_suffix` must align with \n",
    "* the sub-directory (corresponds to region, e.g., \"mucosa\") under the `dir_coord` directory where the Xenium Explorer-exported selection files are stored, and\n",
    "* the suffixes of the coordinate selection files (see file naming conventions below).\n",
    "  \n",
    "The `AnnData` objects created will have this suffix as well (e.g., `Uninflamed-50452A_mucosa.h5ad`).\n",
    "\n",
    "---\n",
    "\n",
    "Selection files should be named by this convention:\n",
    "`<library_id>_<coord_suffix>.csv`.\n",
    "\n",
    "For example, if `dir_coord` is `.../coordinates/mucosa`, the mucosa selection file for sample 50452A should be under `.../coordinates/mucosa/50452A_mucosa.csv`. \n",
    "\n",
    "More specifically, if the coordinates directory is under `/mnt/cho_lab/disk2/elizabeth/data/shared-xenium-library/outputs/TUQ97N/nebraska/coordinates`, and the selection region is \"mucosa,\"`dir_coord` should be `/mnt/cho_lab/disk2/elizabeth/data/shared-xenium-library/outputs/TUQ97N/nebraska/coordinates/mucosa`, and the full file path for this sample would be `/mnt/cho_lab/disk2/elizabeth/data/shared-xenium-library/outputs/TUQ97N/nebraska/coordinates/mucosa/50452A_mucosa.csv`.\n",
    "\n",
    "---\n",
    "\n",
    "**As with any other file naming schema, suffixes/directory names should not any special characters other than underscores (`_`) (no periods, dashes, spaces, etc.).**\n",
    "\n",
    "N.B. In the above explanation, `library_id` refers to library/original sample ID without condition (e.g., \"50452A\", not \"Uninflamed-50452A\" like in other places). Remember that `coord_suffix` should also be the name of the parent directory of the coordinate file. I include this information in both the directory and file name to prevent mix-ups should files be moved or placed in the wrong folder.\n",
    "\n",
    "Loading the metadata allows us to find the object IDs (e.g., for TUQ97N, object IDs are in the format <condition (Inflamed/Uninflamed/Stricture)><block_id>) corresponding to the sample IDs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "    sample_id  block_id  subject_id   run_id panel_id slide_id  grid  project  \\\n",
      "0    49559A5C       NaN       49559  CHO-004   TUQ97N    11167   NaN      NaN   \n",
      "1    49559A5B       NaN       49559  CHO-004   TUQ97N    11167   NaN      NaN   \n",
      "2    49559A5A       NaN       49559  CHO-004   TUQ97N    11167   NaN      NaN   \n",
      "3     49559A5       NaN       49559      NaN      NaN    11167   NaN      NaN   \n",
      "4   49559A5C-       NaN       49559      NaN      NaN    11167   NaN      NaN   \n",
      "5   49559A5B-       NaN       49559      NaN      NaN    11167   NaN      NaN   \n",
      "6     50403A2       NaN       50403  CHO-011   TUQ97N    10589   NaN      NaN   \n",
      "7     50403A1       NaN       50403  CHO-011   TUQ97N    10589   NaN      NaN   \n",
      "8      50336C       NaN       50336  CHO-010   TUQ97N    11047   NaN      NaN   \n",
      "9      50336B       NaN       50336  CHO-010   TUQ97N    11044   NaN      NaN   \n",
      "10     50336A       NaN       50336  CHO-009   TUQ97N    10496   NaN      NaN   \n",
      "11    50403C2       NaN       50403  CHO-012   TUQ97N    21979   NaN      NaN   \n",
      "12    50403C1       NaN       50403  CHO-012   TUQ97N    21978   NaN      NaN   \n",
      "13     50403B       NaN       50403  CHO-011   TUQ97N    10592   NaN      NaN   \n",
      "14     50217C       NaN       50217  CHO-009   TUQ97N    10463   NaN      NaN   \n",
      "15     50217B       NaN       50217  CHO-008   TUQ97N    15522   NaN      NaN   \n",
      "16     50217A       NaN       50217  CHO-008   TUQ97N    15521   NaN      NaN   \n",
      "17     50006C       NaN       50006  CHO-007   TUQ97N    22406   NaN      NaN   \n",
      "18     50006B       NaN       50006  CHO-007   TUQ97N    22407   NaN      NaN   \n",
      "19     50006A       NaN       50006  CHO-007   TUQ97N    22407   NaN      NaN   \n",
      "20    50445A3       NaN       50445  CHO-006   TUQ97N    10923   NaN      NaN   \n",
      "21    50007B2       NaN       50007  CHO-005   TUQ97N    10933   NaN      NaN   \n",
      "22    50115A2       NaN       50115  CHO-005   TUQ97N    10926   NaN      NaN   \n",
      "23    49696A4       NaN       49696  CHO-004   TUQ97N    11170   NaN      NaN   \n",
      "24  49559A5A-       NaN       49559      NaN      NaN    11167   NaN      NaN   \n",
      "25    49464A4       NaN       49464  CHO-003   TUQ97N    10472   NaN      NaN   \n",
      "26    49471A4       NaN       49471  CHO-006   TUQ97N    10490   NaN      NaN   \n",
      "27    49377A2       NaN       49377  CHO-003   TUQ97N    10944   NaN      NaN   \n",
      "28    50618B5       NaN       50618  CHO-002   TUQ97N    22234   NaN      NaN   \n",
      "29    50564A4       NaN       50564  CHO-002   TUQ97N    22235   NaN      NaN   \n",
      "30     50452C       NaN       50452  CHO-001   TUQ97N    10663   NaN      NaN   \n",
      "31     50452B       NaN       50453  CHO-001   TUQ97N    10700   NaN      NaN   \n",
      "32     50452A       NaN       50454  CHO-001   TUQ97N    10700   NaN      NaN   \n",
      "\n",
      "   clinical_block                                        description  ... age  \\\n",
      "0             YES  output-XETG00189__0011167__Region_4__20240229_...  ... NaN   \n",
      "1             YES  output-XETG00189__0011167__Region_2__20240229_...  ... NaN   \n",
      "2             YES  output-XETG00189__0011167__Region_1__20240229_...  ... NaN   \n",
      "3             YES                                                NaN  ... NaN   \n",
      "4             YES  output-XETG00189__0011167__Region_4__20240229_...  ... NaN   \n",
      "5             YES  output-XETG00189__0011167__Region_2__20240229_...  ... NaN   \n",
      "6              NO                                                NaN  ... NaN   \n",
      "7              NO  Tissue adhesion low - two samples on the same ...  ... NaN   \n",
      "8              NO                                                NaN  ... NaN   \n",
      "9              NO                                                NaN  ... NaN   \n",
      "10             NO                                                NaN  ... NaN   \n",
      "11             NO                                                NaN  ... NaN   \n",
      "12             NO                                                NaN  ... NaN   \n",
      "13             NO                                                NaN  ... NaN   \n",
      "14             NO                                                NaN  ... NaN   \n",
      "15             NO                                                NaN  ... NaN   \n",
      "16             NO                                                NaN  ... NaN   \n",
      "17             NO                                                NaN  ... NaN   \n",
      "18             NO                                                NaN  ... NaN   \n",
      "19             NO                                                NaN  ... NaN   \n",
      "20            YES                                                NaN  ... NaN   \n",
      "21            YES                                                NaN  ... NaN   \n",
      "22            YES                                                NaN  ... NaN   \n",
      "23            YES  output-XETG00189__0011170__Region_1__20240229_...  ... NaN   \n",
      "24            YES  output-XETG00189__0011167__Region_1__20240229_...  ... NaN   \n",
      "25            YES           mid-run failure, restarted 21 days later  ... NaN   \n",
      "26            YES                                                NaN  ... NaN   \n",
      "27            YES      Incorrectly run as 49377A4 on Xenium machine.  ... NaN   \n",
      "28            YES                                                NaN  ... NaN   \n",
      "29            YES                                                NaN  ... NaN   \n",
      "30             NO                                                NaN  ... NaN   \n",
      "31             NO                                                NaN  ... NaN   \n",
      "32             NO                                                NaN  ... NaN   \n",
      "\n",
      "   sex  race  hispanic  diagnosis        location  inflammation stricture  \\\n",
      "0  NaN   NaN       NaN        NaN  Terminal Ileum      inflamed       yes   \n",
      "1  NaN   NaN       NaN        NaN  Terminal Ileum      inflamed       yes   \n",
      "2  NaN   NaN       NaN        NaN  Terminal Ileum      inflamed       yes   \n",
      "3  NaN   NaN       NaN        NaN  Terminal Ileum      inflamed       yes   \n",
      "4  NaN   NaN       NaN        NaN  Terminal Ileum      inflamed       yes   \n",
      "5  NaN   NaN       NaN        NaN  Terminal Ileum      inflamed       yes   \n",
      "6  NaN   NaN       NaN        NaN  Terminal Ileum    uninflamed        no   \n",
      "7  NaN   NaN       NaN        NaN  Terminal Ileum    uninflamed        no   \n",
      "8  NaN   NaN       NaN        NaN  Terminal Ileum    uninflamed        no   \n",
      "9  NaN   NaN       NaN        NaN  Terminal Ileum      inflamed        no   \n",
      "10 NaN   NaN       NaN        NaN  Terminal Ileum      inflamed       yes   \n",
      "11 NaN   NaN       NaN        NaN  Terminal Ileum      inflamed       yes   \n",
      "12 NaN   NaN       NaN        NaN  Terminal Ileum      inflamed       yes   \n",
      "13 NaN   NaN       NaN        NaN  Terminal Ileum      inflamed        no   \n",
      "14 NaN   NaN       NaN        NaN  Terminal Ileum      inflamed       yes   \n",
      "15 NaN   NaN       NaN        NaN  Terminal Ileum    uninflamed        no   \n",
      "16 NaN   NaN       NaN        NaN  Terminal Ileum      inflamed        no   \n",
      "17 NaN   NaN       NaN        NaN  Terminal Ileum      inflamed       yes   \n",
      "18 NaN   NaN       NaN        NaN  Terminal Ileum    uninflamed        no   \n",
      "19 NaN   NaN       NaN        NaN  Terminal Ileum      inflamed        no   \n",
      "20 NaN   NaN       NaN        NaN  Terminal Ileum      inflamed       yes   \n",
      "21 NaN   NaN       NaN        NaN  Terminal Ileum      inflamed       yes   \n",
      "22 NaN   NaN       NaN        NaN  Terminal Ileum      inflamed       yes   \n",
      "23 NaN   NaN       NaN        NaN  Terminal Ileum      inflamed       yes   \n",
      "24 NaN   NaN       NaN        NaN  Terminal Ileum      inflamed       yes   \n",
      "25 NaN   NaN       NaN        NaN  Terminal Ileum      inflamed       yes   \n",
      "26 NaN   NaN       NaN        NaN  Terminal Ileum      inflamed       yes   \n",
      "27 NaN   NaN       NaN        NaN  Terminal Ileum      inflamed       yes   \n",
      "28 NaN   NaN       NaN        NaN  Terminal Ileum      inflamed       yes   \n",
      "29 NaN   NaN       NaN        NaN  Terminal Ileum      inflamed       yes   \n",
      "30 NaN   NaN       NaN        NaN  Terminal Ileum      inflamed       yes   \n",
      "31 NaN   NaN       NaN        NaN  Terminal Ileum      inflamed        no   \n",
      "32 NaN   NaN       NaN        NaN  Terminal Ileum    uninflamed        no   \n",
      "\n",
      "     Condition disease_status  \n",
      "0    stricture            NaN  \n",
      "1    stricture            NaN  \n",
      "2    stricture            NaN  \n",
      "3    stricture            NaN  \n",
      "4    stricture            NaN  \n",
      "5    stricture            NaN  \n",
      "6   uninflamed            NaN  \n",
      "7   uninflamed            NaN  \n",
      "8   uninflamed            NaN  \n",
      "9     inflamed            NaN  \n",
      "10   stricture            NaN  \n",
      "11   stricture            NaN  \n",
      "12   stricture            NaN  \n",
      "13    inflamed            NaN  \n",
      "14   stricture            NaN  \n",
      "15  uninflamed            NaN  \n",
      "16    inflamed            NaN  \n",
      "17   stricture            NaN  \n",
      "18  uninflamed            NaN  \n",
      "19    inflamed            NaN  \n",
      "20   stricture            NaN  \n",
      "21   stricture            NaN  \n",
      "22   stricture            NaN  \n",
      "23   stricture            NaN  \n",
      "24   stricture            NaN  \n",
      "25   stricture            NaN  \n",
      "26   stricture            NaN  \n",
      "27   stricture            NaN  \n",
      "28   stricture            NaN  \n",
      "29   stricture            NaN  \n",
      "30   stricture            NaN  \n",
      "31    inflamed            NaN  \n",
      "32  uninflamed            NaN  \n",
      "\n",
      "[33 rows x 22 columns]\n",
      "Sample\n",
      "Uninflamed-50403A2    50403A2\n",
      "Uninflamed-50403A1    50403A1\n",
      "Uninflamed-50336C      50336C\n",
      "Inflamed-50336B        50336B\n",
      "Stricture-50336A       50336A\n",
      "Stricture-50403C2     50403C2\n",
      "Stricture-50403C1     50403C1\n",
      "Inflamed-50403B        50403B\n",
      "Stricture-50217C       50217C\n",
      "Uninflamed-50217B      50217B\n",
      "Inflamed-50217A        50217A\n",
      "Stricture-50006C       50006C\n",
      "Uninflamed-50006B      50006B\n",
      "Inflamed-50006A        50006A\n",
      "Stricture-50445A3     50445A3\n",
      "Stricture-50007B2     50007B2\n",
      "Stricture-50115A2     50115A2\n",
      "Stricture-49471A4     49471A4\n",
      "Stricture-50618B5     50618B5\n",
      "Stricture-50564A4     50564A4\n",
      "Stricture-50452C       50452C\n",
      "Inflamed-50452B        50452B\n",
      "Uninflamed-50452A      50452A\n",
      "Name: sample_id, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sample\n",
       "Inflamed-50006A       50006\n",
       "Uninflamed-50006B     50006\n",
       "Inflamed-50217A       50217\n",
       "Uninflamed-50217B     50217\n",
       "Inflamed-50336B       50336\n",
       "Uninflamed-50336C     50336\n",
       "Inflamed-50403B       50403\n",
       "Uninflamed-50403A2    50403\n",
       "Name: subject_id, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import functools\n",
    "import traceback\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "import spatialdata_plot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import corescpy as cr\n",
    "\n",
    "# Main\n",
    "write_object = True  # change to True when you're ready to save objects\n",
    "overwrite = False  # overwrite if already exists?\n",
    "regions = [\"mucosa\", \"serosa\", \"myenteric_plexus\", \"submucosa\",\n",
    "           \"smc_longitudinal\", \"smc_circular\"]\n",
    "col_leiden = \"leiden_res1pt5_dist0_npc30\"\n",
    "col_ann = \"Bucket\"\n",
    "cells_as_circles = False\n",
    "\n",
    "# Process Options\n",
    "panel = \"TUQ97N\"  # Xenium panel ID\n",
    "constants_dict = cr.get_panel_constants(panel)\n",
    "# libs = [  # sample IDs from patients for whom we have all conditions\n",
    "#     \"50452A\", \"50452B\", \"50452C\",  # old segmentation\n",
    "#     \"50006A\", \"50006B\", \"50006C\",  # rest are new segmentation\n",
    "#     \"50217A\", \"50217B\", \"50217C\",\n",
    "#     \"50336B\", \"50336C\", \"50336A\",\n",
    "#     \"50403A2\", \"50403B\", \"50403C1\"\n",
    "# ]  # excludes low-quality sample/condition replicates 50403A1 & 50403C2\n",
    "libs = [\"50006A\", \"50006B\", \"50217A\", \"50217B\", \"50336B\", \"50336C\",\n",
    "        \"50403B\", \"50403A2\"]  # just inflamed/uninflamed (no strictures)\n",
    "# libs = None  # to run all available samples\n",
    "input_suffix = \"\"  # in case want to crop objects with some suffix\n",
    "# due to creation of a subsidiary object, e.g., for\n",
    "# \"Stricture-50452C_downsampled.h5ad\"\n",
    "# input_suffix would be \"_downsampled\". For \"main\" objects, input_suffix=\"\"\n",
    "plot = True  # could slow process down if large samples/cropped area\n",
    "\n",
    "# Files & Directories\n",
    "direc = \"/mnt/cho_lab/bbdata2/\"  # mounted NFS with data\n",
    "dir_entry = \"/mnt/cho_lab/disk2\"  # Spark writeable data directory\n",
    "mdf = str(\"/mnt/cho_lab/disk2/elizabeth/data/shared-xenium-library/samples_\"\n",
    "          f\"{panel}.csv\")  # metadata file path (for now; will soon be on NFS)\n",
    "dir_writeable = os.path.join(\n",
    "    dir_entry, f\"elizabeth/data/shared-xenium-library\")  # where objects are\n",
    "out_dir = os.path.join(\n",
    "    dir_writeable, f\"outputs/{panel}/nebraska\")  # object output directory\n",
    "\n",
    "#  Your Folders\n",
    "out_new = os.path.join(\n",
    "    dir_entry,\n",
    "    f\"{os.getlogin()}/data/shared-xenium-library/outputs/{panel}/nebraska\")\n",
    "\n",
    "# Constants (Shouldn't Need Edits Unless Extreme Process Changes)\n",
    "cso, col_sample, col_condition, col_inflamed, col_subject = [\n",
    "    constants_dict[x] if x in constants_dict else None for x in [\n",
    "        \"col_sample_id_o\", \"col_sample_id\", \"col_condition\",\n",
    "        \"col_inflamed\", \"col_subject\"]]\n",
    "dir_data = os.path.join(direc, f\"outputs/{panel}\")\n",
    "files = functools.reduce(lambda i, j: i + j, [[os.path.join(\n",
    "    run, i) for i in os.listdir(os.path.join(\n",
    "        dir_data, run))] for run in os.listdir(dir_data)])  # all data paths\n",
    "os.makedirs(out_dir, exist_ok=True)  # make output directory if needed\n",
    "metadata = cr.pp.get_metadata_cho(direc, mdf, panel_id=panel, samples=libs)\n",
    "metadata[col_subject]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset Data by Coordinate Files & Write Cropped Objects\n",
    "\n",
    "Subset the data by coordinates (`corescpy` can use Xenium Explorer-exported manual selection files to get those coordinates) and then write the cropped objects to `out_dir/<coord_suffix>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "================================================================================\n",
      "50006A\n",
      "================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<<< INITIALIZING SPATIAL CLASS OBJECT >>>\n",
      "\n",
      "\u001b[34mINFO    \u001b[0m reading                                                                                                   \n",
      "         \u001b[35m/mnt/cho_lab/bbdata2/outputs/TUQ97N/CHO-007/output-XETG00189__0022407__50006A-TUQ97N-EA__20240411__205514/\u001b[0m\n",
      "         \u001b[95mcell_feature_matrix.h5\u001b[0m                                                                                    \n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for s in libs:  # iterate samples\n",
    "    print(f\"\\n\\n{'=' * 80}\\n{s}\\n{'=' * 80}\\n\\n\")\n",
    "    fff = os.path.join(dir_data, np.array(files)[np.where([\n",
    "        s == os.path.basename(x).split(\"__\")[2].split(\"-\")[0]\n",
    "        for x in files])[0][0]])  # sample's Xenium data directory path\n",
    "    lib = metadata.reset_index().set_index(cso).loc[s][col_sample]\n",
    "    file_obj_proc = os.path.join(out_dir, f\"{lib}{input_suffix}.h5ad\")\n",
    "    self = cr.Spatial(fff, library_id=lib,\n",
    "                      cells_as_circles=cells_as_circles)  # load original data\n",
    "    self.update_from_h5ad(file_obj_proc)  # update with processed object\n",
    "    if \"shapes\" in dir(sdata):\n",
    "        for x in sdata.shapes:\n",
    "            if self.adata.shapes[x].isnull().any().any():\n",
    "                self.adata.shapes[x] = sdata.shapes[x].dropna()\n",
    "    for coord_suffix in regions:\n",
    "        print(f\"\\n\\n\\t\\t{'*' * 40}\\n\\t\\t{s}\\n\\t\\t{'*' * 40}\\n\\n\")\n",
    "        dir_coord = os.path.join(\n",
    "            out_new, \"coordinates\", coord_suffix)  # coordinates (NFS soon?)\n",
    "        out = os.path.join(out_new, \"objects_cropped\", coord_suffix)  # path\n",
    "        os.makedirs(out, exist_ok=True)  # make sub-directory for new objects?\n",
    "        file_coord = os.path.join(dir_coord, s + f\"_{coord_suffix}.csv\")\n",
    "        file_obj_crop = os.path.join(out, f\"{lib}_{coord_suffix}.h5ad\")\n",
    "        if overwrite is False and os.path.exists(file_obj_crop):\n",
    "            print(f\"*** Subset {file_obj_crop} already exists\")\n",
    "            continue\n",
    "        if not os.path.exists(file_coord):\n",
    "            print(f\"*** Coordinate file {file_coord} doesn't exist\")\n",
    "            continue\n",
    "        print(f\"\\n\\nData: {fff}\\nObject: {file_obj_proc}\"\n",
    "              f\"\\nCoordinates: {file_coord}\\nOuput: {file_obj_crop}\")\n",
    "        sdata = self.crop(file_coord)  # crop data to coordinates\n",
    "        try:\n",
    "            # sdata = self.crop(file_coord)  # crop data to coordinates\n",
    "            if plot:\n",
    "                try:\n",
    "                    sdata.pl.render_labels(\"cell_labels\").pl.show()  # plot\n",
    "                except Exception:\n",
    "                    pass\n",
    "            self.adata = sdata\n",
    "            if write_object is True:\n",
    "                self.write(file_obj_crop)  # write cropped\n",
    "        except Exception:\n",
    "            print(traceback.format_exc(), f\"Cropping \\n\\n{s} failed!\")\n",
    "print(\"\\n\\nCompleted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.adata.shapes[\"cell_circles\"][\"radius\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n\\n{'=' * 80}\\n{s}\\n{'=' * 80}\\n\\n\")\n",
    "fff = os.path.join(dir_data, np.array(files)[np.where([\n",
    "    s == os.path.basename(x).split(\"__\")[2].split(\"-\")[0]\n",
    "    for x in files])[0][0]])  # sample's Xenium data directory path\n",
    "lib = metadata.reset_index().set_index(cso).loc[s][col_sample]\n",
    "file_obj_proc = os.path.join(out_dir, f\"{lib}{input_suffix}.h5ad\")\n",
    "self = cr.Spatial(fff, library_id=lib, cells_as_circles=False)  # original\n",
    "self.update_from_h5ad(file_obj_proc)  # update with processed object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.rna[self.rna.obs[\"cell_id\"].isin(sdata.shapes[\"cell_boundaries\"].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.adata.get_annotated_regions(self.adata.table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = self.crop(file_coord)  # crop data to coordinates\n",
    "sdata.pl.render_labels(\"cell_labels\").pl.show()  # plot\n",
    "\n",
    "# self.adata = sdata\n",
    "# self.write(file_obj_crop)  # write cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_obj_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(self.adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.adata.shapes[\"cell_circles\"][self.adata.shapes[\"cell_circles\"].radius.isna()].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_circles = self.adata.shapes[\"cell_circles\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.adata.shapes[\"cell_circles\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spatialdata\n",
    "\n",
    "cell_circles = spatialdata.deepcopy(self.adata.shapes[\"cell_circles\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spatialdata.transformations.transformations import Affine, Identity, Scale\n",
    "from spatialdata_io._constants._constants import XeniumKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        transform = Scale([1.0 / 0.2125, 1.0 / 0.2125], axes=(\"x\", \"y\"))\n",
    "        radii = np.sqrt(self.rna.obs[XeniumKeys.CELL_NUCLEUS_AREA].to_numpy() / np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.rna.obs.iloc[:, 1:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.rna.obs[XeniumKeys.CELL_NUCLEUS_AREA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.adata.shapes[\"cell_circles\"] = self.adata.shapes[\"cell_circles\"].drop(\"radius\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "XeniumKeys.CELL_ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "queried_points = sdata_crop[\"my_points\"].index.compute()\n",
    "sdata_crop[\"my_table\"] = sdata[\"my_table\"][queried_points].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i[1] for i in self.adata._gen_elements()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(table.obs[\"region_key\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    found_regions = set(table.obs[\"cell_id\"].unique().tolist())\n",
    "    target_element_set = [\"cell_boundaries\"]\n",
    "    symmetric_difference = found_regions.symmetric_difference(target_element_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(symmetric_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.adata._change_table_annotation_target(self.adata.table, \"cell_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.uns.get(\"spatialdata_attrs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.adata.set_table_annotates_spatialelement(\"table\", region=\"cell_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = self.crop(file_coord)  # crop data to coordinates\n",
    "sdata.pl.render_labels(\"cell_labels\").pl.show()  # plot\n",
    "\n",
    "self.adata = sdata\n",
    "self.write(file_obj_crop)  # write cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# element = self.adata.shapes[\"cell_circles\"]\n",
    "# buffered_df = element.copy()\n",
    "# buffered = to_polygons(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_cells = {}\n",
    "# for s in libs:  # iterate samples\n",
    "#     print(f\"\\n\\n{'*' * 40}\\n{s}\\n{'*' * 40}\\n\\n\")\n",
    "#     fff = os.path.join(dir_data, np.array(files)[np.where([\n",
    "#         s == os.path.basename(x).split(\"__\")[2].split(\"-\")[0]\n",
    "#         for x in files])[0][0]])  # sample's Xenium data directory path\n",
    "#     lib = metadata.reset_index().set_index(cso).loc[s][col_sample]\n",
    "#     file_obj_proc = os.path.join(out_dir, f\"{lib}{input_suffix}.h5ad\")\n",
    "#     self = cr.Spatial(fff, library_id=lib)  # load original data\n",
    "#     n_obs = self.rna.obs.shape[0]\n",
    "#     self.update_from_h5ad(file_obj_proc)  # update with processed object)\n",
    "#     self.rna.obs.loc[:, \"n_obs_raw\"] = n_obs\n",
    "#     self.write(file_obj_proc)\n",
    "#     n_cells[s] = pd.Series([n_obs, self.rna.obs.shape[0]], index=pd.Index([\n",
    "#         \"Raw\", \"Processed\"], name=\"Source\"))\n",
    "# n_cells = pd.concat(n_cells).unstack(\"Source\")\n",
    "# n_cells.to_excel(\"/home/elizabeth/elizabeth/projects/senescence/meta.xlsx\")\n",
    "# n_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for s in libs:  # iterate samples\n",
    "    print(f\"\\n\\n{'=' * 80}\\n{s}\\n{'=' * 80}\\n\\n\")\n",
    "    fff = os.path.join(dir_data, np.array(files)[np.where([\n",
    "        s == os.path.basename(x).split(\"__\")[2].split(\"-\")[0]\n",
    "        for x in files])[0][0]])  # sample's Xenium data directory path\n",
    "    lib = metadata.reset_index().set_index(cso).loc[s][col_sample]\n",
    "    file_obj_proc = os.path.join(out_dir, f\"{lib}{input_suffix}.h5ad\")\n",
    "    self = cr.Spatial(fff, library_id=lib)  # load original data\n",
    "    self.update_from_h5ad(file_obj_proc)  # update with processed object\n",
    "    if \"shapes\" in dir(sdata):\n",
    "        for x in sdata.shapes:\n",
    "            if self.adata.shapes[x].isnull().any().any():\n",
    "                self.adata.shapes[x] = sdata.shapes[x].dropna()\n",
    "    for coord_suffix in regions:\n",
    "        print(f\"\\n\\n\\t\\t{'*' * 40}\\n\\t\\t{s}\\n\\t\\t{'*' * 40}\\n\\n\")\n",
    "        dir_coord = os.path.join(\n",
    "            out_new, \"coordinates\", coord_suffix)  # coordinates (NFS soon?)\n",
    "        out = os.path.join(out_new, \"objects_cropped\", coord_suffix)  # path\n",
    "        os.makedirs(out, exist_ok=True)  # make sub-directory for new objects?\n",
    "        file_coord = os.path.join(dir_coord, s + f\"_{coord_suffix}.csv\")\n",
    "        file_obj_crop = os.path.join(out, f\"{lib}_{coord_suffix}.h5ad\")\n",
    "        if overwrite is False and os.path.exists(file_obj_crop):\n",
    "            print(f\"*** Subset {file_obj_crop} already exists\")\n",
    "            continue\n",
    "        if not os.path.exists(file_coord):\n",
    "            print(f\"*** Coordinate file {file_coord} doesn't exist\")\n",
    "            continue\n",
    "        print(f\"\\n\\nData: {fff}\\nObject: {file_obj_proc}\"\n",
    "              f\"\\nCoordinates: {file_coord}\\nOuput: {file_obj_crop}\")\n",
    "        sdata = self.crop(file_coord)  # crop data to coordinates\n",
    "        try:\n",
    "            # sdata = self.crop(file_coord)  # crop data to coordinates\n",
    "            if plot:\n",
    "                try:\n",
    "                    sdata.pl.render_labels(\"cell_labels\").pl.show()  # plot\n",
    "                except Exception:\n",
    "                    pass\n",
    "            self.adata = sdata\n",
    "            if write_object is True:\n",
    "                self.write(file_obj_crop)  # write cropped\n",
    "        except Exception:\n",
    "            print(traceback.format_exc(), f\"Cropping \\n\\n{s} failed!\")\n",
    "print(\"\\n\\nCompleted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "file_annotations = os.path.join(\n",
    "    out_dir, \"annotation_dictionaries/annotations_all.xlsx\")\n",
    "fmr = pd.read_excel(file_annotations, index_col=[0, 1])[\n",
    "    col_ann].dropna().astype(str)  # annotation mapping\n",
    "c_ann = col_ann + \"_\" + col_leiden.split(\"leiden_\")[1]\n",
    "\n",
    "for s in libs:  # iterate samples\n",
    "    print(f\"\\n\\n{'=' * 80}\\n{s}\\n{'=' * 80}\\n\\n\")\n",
    "    fff = os.path.join(dir_data, np.array(files)[np.where([\n",
    "        s == os.path.basename(x).split(\"__\")[2].split(\"-\")[0]\n",
    "        for x in files])[0][0]])  # sample's Xenium data directory path\n",
    "    lib = metadata.reset_index().set_index(cso).loc[s][col_sample]\n",
    "    file_obj_proc = os.path.join(out_dir, f\"{lib}{input_suffix}.h5ad\")\n",
    "    for coord_suffix in regions:\n",
    "        print(f\"\\n\\n\\t\\t{'*' * 40}\\n\\t\\t{s}\\n\\t\\t{'*' * 40}\\n\\n\")\n",
    "        self = cr.Spatial(fff, library_id=lib, col_cell_type=c_ann)  # load\n",
    "        self.update_from_h5ad(os.path.join(\n",
    "            out_new, \"objects_cropped\", coord_suffix,\n",
    "            f\"{lib}_{coord_suffix}.h5ad\"))  # update with cropped object\n",
    "        self.annotate_clusters(fmr.loc[i_x], col_cell_type=col_leiden,\n",
    "                               col_annotation=c_ann, copy=False)  # annotate\n",
    "        _ = self.calculate_centrality(n_jobs=sc.settings.n_jobs)\n",
    "        _, fig = self.calculate_neighborhood(figsize=(60, 30))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
