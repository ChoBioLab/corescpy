{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "```\n",
    "pip install git+https://github.com/scverse/spatialdata.git@main\n",
    "pip install git+https://github.com/scverse/spatialdata-io.git@main\n",
    "```\n",
    "\n",
    "This is the stuff you have to edit; the rest of the sections can run as-is after you've set the needed parameters.\n",
    "\n",
    "---\n",
    "\n",
    "`coord_suffix` must align with \n",
    "* the sub-directory (corresponds to region, e.g., \"mucosa\") under the `dir_coord` directory where the Xenium Explorer-exported selection files are stored, and\n",
    "* the suffixes of the coordinate selection files (see file naming conventions below).\n",
    "  \n",
    "The `AnnData` objects created will have this suffix as well (e.g., `Uninflamed-50452A_mucosa.h5ad`).\n",
    "\n",
    "---\n",
    "\n",
    "Selection files should be named by this convention:\n",
    "`<library_id>_<coord_suffix>.csv`.\n",
    "\n",
    "For example, if `dir_coord` is `.../coordinates/mucosa`, the mucosa selection file for sample 50452A should be under `.../coordinates/mucosa/50452A_mucosa.csv`. \n",
    "\n",
    "More specifically, if the coordinates directory is under `/mnt/cho_lab/disk2/elizabeth/data/shared-xenium-library/outputs/TUQ97N/nebraska/coordinates`, and the selection region is \"mucosa,\"`dir_coord` should be `/mnt/cho_lab/disk2/elizabeth/data/shared-xenium-library/outputs/TUQ97N/nebraska/coordinates/mucosa`, and the full file path for this sample would be `/mnt/cho_lab/disk2/elizabeth/data/shared-xenium-library/outputs/TUQ97N/nebraska/coordinates/mucosa/50452A_mucosa.csv`.\n",
    "\n",
    "---\n",
    "\n",
    "**As with any other file naming schema, suffixes/directory names should not any special characters other than underscores (`_`) (no periods, dashes, spaces, etc.).**\n",
    "\n",
    "N.B. In the above explanation, `library_id` refers to library/original sample ID without condition (e.g., \"50452A\", not \"Uninflamed-50452A\" like in other places). Remember that `coord_suffix` should also be the name of the parent directory of the coordinate file. I include this information in both the directory and file name to prevent mix-ups should files be moved or placed in the wrong folder.\n",
    "\n",
    "Loading the metadata allows us to find the object IDs (e.g., for TUQ97N, object IDs are in the format <condition (Inflamed/Uninflamed/Stricture)><block_id>) corresponding to the sample IDs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import functools\n",
    "import traceback\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "import spatialdata_plot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import corescpy as cr\n",
    "\n",
    "# Main\n",
    "write_object = True  # change to True when you're ready to save objects\n",
    "overwrite = False  # overwrite if already exists?\n",
    "regions = [\"mucosa\", \"serosa\", \"myenteric_plexus\", \"submucosa\",\n",
    "           \"smc_longitudinal\", \"smc_circular\"]\n",
    "col_leiden = \"leiden_res1pt5_dist0_npc30\"\n",
    "col_ann = \"Bucket\"\n",
    "cells_as_circles = False\n",
    "\n",
    "# Process Options\n",
    "panel = \"TUQ97N\"  # Xenium panel ID\n",
    "constants_dict = cr.get_panel_constants(panel)\n",
    "# libs = [  # sample IDs from patients for whom we have all conditions\n",
    "#     \"50452A\", \"50452B\", \"50452C\",  # old segmentation\n",
    "#     \"50006A\", \"50006B\", \"50006C\",  # rest are new segmentation\n",
    "#     \"50217A\", \"50217B\", \"50217C\",\n",
    "#     \"50336B\", \"50336C\", \"50336A\",\n",
    "#     \"50403A2\", \"50403B\", \"50403C1\"\n",
    "# ]  # excludes low-quality sample/condition replicates 50403A1 & 50403C2\n",
    "libs = [\"50006A\", \"50006B\", \"50217A\", \"50217B\", \"50336B\", \"50336C\",\n",
    "        \"50403B\", \"50403A2\"]  # just inflamed/uninflamed (no strictures)\n",
    "# libs = None  # to run all available samples\n",
    "input_suffix = \"\"  # in case want to crop objects with some suffix\n",
    "# due to creation of a subsidiary object, e.g., for\n",
    "# \"Stricture-50452C_downsampled.h5ad\"\n",
    "# input_suffix would be \"_downsampled\". For \"main\" objects, input_suffix=\"\"\n",
    "plot = True  # could slow process down if large samples/cropped area\n",
    "\n",
    "# Files & Directories\n",
    "direc = \"/mnt/cho_lab/bbdata2/\"  # mounted NFS with data\n",
    "dir_entry = \"/mnt/cho_lab/disk2\"  # Spark writeable data directory\n",
    "mdf = str(\"/mnt/cho_lab/disk2/elizabeth/data/shared-xenium-library/samples_\"\n",
    "          f\"{panel}.csv\")  # metadata file path (for now; will soon be on NFS)\n",
    "dir_writeable = os.path.join(\n",
    "    dir_entry, f\"elizabeth/data/shared-xenium-library\")  # where objects are\n",
    "out_dir = os.path.join(\n",
    "    dir_writeable, f\"outputs/{panel}/nebraska\")  # object output directory\n",
    "\n",
    "#  Your Folders\n",
    "out_new = os.path.join(\n",
    "    dir_entry,\n",
    "    f\"{os.getlogin()}/data/shared-xenium-library/outputs/{panel}/nebraska\")\n",
    "\n",
    "# Constants (Shouldn't Need Edits Unless Extreme Process Changes)\n",
    "cso, col_sample, col_condition, col_inflamed, col_subject = [\n",
    "    constants_dict[x] if x in constants_dict else None for x in [\n",
    "        \"col_sample_id_o\", \"col_sample_id\", \"col_condition\",\n",
    "        \"col_inflamed\", \"col_subject\"]]\n",
    "dir_data = os.path.join(direc, f\"outputs/{panel}\")\n",
    "files = functools.reduce(lambda i, j: i + j, [[os.path.join(\n",
    "    run, i) for i in os.listdir(os.path.join(\n",
    "        dir_data, run))] for run in os.listdir(dir_data)])  # all data paths\n",
    "os.makedirs(out_dir, exist_ok=True)  # make output directory if needed\n",
    "metadata = cr.pp.get_metadata_cho(direc, mdf, panel_id=panel, samples=libs)\n",
    "metadata[col_subject]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset Data by Coordinate Files & Write Cropped Objects\n",
    "\n",
    "Subset the data by coordinates (`corescpy` can use Xenium Explorer-exported manual selection files to get those coordinates) and then write the cropped objects to `out_dir/<coord_suffix>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for s in libs:  # iterate samples\n",
    "    print(f\"\\n\\n{'=' * 80}\\n{s}\\n{'=' * 80}\\n\\n\")\n",
    "    fff = os.path.join(dir_data, np.array(files)[np.where([\n",
    "        s == os.path.basename(x).split(\"__\")[2].split(\"-\")[0]\n",
    "        for x in files])[0][0]])  # sample's Xenium data directory path\n",
    "    lib = metadata.reset_index().set_index(cso).loc[s][col_sample]\n",
    "    file_obj_proc = os.path.join(out_dir, f\"{lib}{input_suffix}.h5ad\")\n",
    "    self = cr.Spatial(fff, library_id=lib,\n",
    "                      cells_as_circles=cells_as_circles)  # load original data\n",
    "    self.update_from_h5ad(file_obj_proc)  # update with processed object\n",
    "    if \"shapes\" in dir(sdata):\n",
    "        for x in sdata.shapes:\n",
    "            if self.adata.shapes[x].isnull().any().any():\n",
    "                self.adata.shapes[x] = sdata.shapes[x].dropna()\n",
    "    for coord_suffix in regions:\n",
    "        print(f\"\\n\\n\\t\\t{'*' * 40}\\n\\t\\t{s}\\n\\t\\t{'*' * 40}\\n\\n\")\n",
    "        dir_coord = os.path.join(\n",
    "            out_new, \"coordinates\", coord_suffix)  # coordinates (NFS soon?)\n",
    "        out = os.path.join(out_new, \"objects_cropped\", coord_suffix)  # path\n",
    "        os.makedirs(out, exist_ok=True)  # make sub-directory for new objects?\n",
    "        file_coord = os.path.join(dir_coord, s + f\"_{coord_suffix}.csv\")\n",
    "        file_obj_crop = os.path.join(out, f\"{lib}_{coord_suffix}.h5ad\")\n",
    "        if overwrite is False and os.path.exists(file_obj_crop):\n",
    "            print(f\"*** Subset {file_obj_crop} already exists\")\n",
    "            continue\n",
    "        if not os.path.exists(file_coord):\n",
    "            print(f\"*** Coordinate file {file_coord} doesn't exist\")\n",
    "            continue\n",
    "        print(f\"\\n\\nData: {fff}\\nObject: {file_obj_proc}\"\n",
    "              f\"\\nCoordinates: {file_coord}\\nOuput: {file_obj_crop}\")\n",
    "        sdata = self.crop(file_coord)  # crop data to coordinates\n",
    "        try:\n",
    "            # sdata = self.crop(file_coord)  # crop data to coordinates\n",
    "            if plot:\n",
    "                try:\n",
    "                    sdata.pl.render_labels(\"cell_labels\").pl.show()  # plot\n",
    "                except Exception:\n",
    "                    pass\n",
    "            self.adata = sdata\n",
    "            if write_object is True:\n",
    "                self.write(file_obj_crop)  # write cropped\n",
    "        except Exception:\n",
    "            print(traceback.format_exc(), f\"Cropping \\n\\n{s} failed!\")\n",
    "print(\"\\n\\nCompleted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.adata.shapes[\"cell_circles\"][\"radius\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n\\n{'=' * 80}\\n{s}\\n{'=' * 80}\\n\\n\")\n",
    "fff = os.path.join(dir_data, np.array(files)[np.where([\n",
    "    s == os.path.basename(x).split(\"__\")[2].split(\"-\")[0]\n",
    "    for x in files])[0][0]])  # sample's Xenium data directory path\n",
    "lib = metadata.reset_index().set_index(cso).loc[s][col_sample]\n",
    "file_obj_proc = os.path.join(out_dir, f\"{lib}{input_suffix}.h5ad\")\n",
    "self = cr.Spatial(fff, library_id=lib, cells_as_circles=False)  # original\n",
    "self.update_from_h5ad(file_obj_proc)  # update with processed object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.rna[self.rna.obs[\"cell_id\"].isin(sdata.shapes[\"cell_boundaries\"].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.adata.get_annotated_regions(self.adata.table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = self.crop(file_coord)  # crop data to coordinates\n",
    "sdata.pl.render_labels(\"cell_labels\").pl.show()  # plot\n",
    "\n",
    "# self.adata = sdata\n",
    "# self.write(file_obj_crop)  # write cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_obj_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(self.adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.adata.shapes[\"cell_circles\"][self.adata.shapes[\"cell_circles\"].radius.isna()].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_circles = self.adata.shapes[\"cell_circles\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.adata.shapes[\"cell_circles\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spatialdata\n",
    "\n",
    "cell_circles = spatialdata.deepcopy(self.adata.shapes[\"cell_circles\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spatialdata.transformations.transformations import Affine, Identity, Scale\n",
    "from spatialdata_io._constants._constants import XeniumKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        transform = Scale([1.0 / 0.2125, 1.0 / 0.2125], axes=(\"x\", \"y\"))\n",
    "        radii = np.sqrt(self.rna.obs[XeniumKeys.CELL_NUCLEUS_AREA].to_numpy() / np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.rna.obs.iloc[:, 1:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.rna.obs[XeniumKeys.CELL_NUCLEUS_AREA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.adata.shapes[\"cell_circles\"] = self.adata.shapes[\"cell_circles\"].drop(\"radius\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "XeniumKeys.CELL_ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "queried_points = sdata_crop[\"my_points\"].index.compute()\n",
    "sdata_crop[\"my_table\"] = sdata[\"my_table\"][queried_points].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i[1] for i in self.adata._gen_elements()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(table.obs[\"region_key\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    found_regions = set(table.obs[\"cell_id\"].unique().tolist())\n",
    "    target_element_set = [\"cell_boundaries\"]\n",
    "    symmetric_difference = found_regions.symmetric_difference(target_element_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(symmetric_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.adata._change_table_annotation_target(self.adata.table, \"cell_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.uns.get(\"spatialdata_attrs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.adata.set_table_annotates_spatialelement(\"table\", region=\"cell_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = self.crop(file_coord)  # crop data to coordinates\n",
    "sdata.pl.render_labels(\"cell_labels\").pl.show()  # plot\n",
    "\n",
    "self.adata = sdata\n",
    "self.write(file_obj_crop)  # write cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# element = self.adata.shapes[\"cell_circles\"]\n",
    "# buffered_df = element.copy()\n",
    "# buffered = to_polygons(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_cells = {}\n",
    "# for s in libs:  # iterate samples\n",
    "#     print(f\"\\n\\n{'*' * 40}\\n{s}\\n{'*' * 40}\\n\\n\")\n",
    "#     fff = os.path.join(dir_data, np.array(files)[np.where([\n",
    "#         s == os.path.basename(x).split(\"__\")[2].split(\"-\")[0]\n",
    "#         for x in files])[0][0]])  # sample's Xenium data directory path\n",
    "#     lib = metadata.reset_index().set_index(cso).loc[s][col_sample]\n",
    "#     file_obj_proc = os.path.join(out_dir, f\"{lib}{input_suffix}.h5ad\")\n",
    "#     self = cr.Spatial(fff, library_id=lib)  # load original data\n",
    "#     n_obs = self.rna.obs.shape[0]\n",
    "#     self.update_from_h5ad(file_obj_proc)  # update with processed object)\n",
    "#     self.rna.obs.loc[:, \"n_obs_raw\"] = n_obs\n",
    "#     self.write(file_obj_proc)\n",
    "#     n_cells[s] = pd.Series([n_obs, self.rna.obs.shape[0]], index=pd.Index([\n",
    "#         \"Raw\", \"Processed\"], name=\"Source\"))\n",
    "# n_cells = pd.concat(n_cells).unstack(\"Source\")\n",
    "# n_cells.to_excel(\"/home/elizabeth/elizabeth/projects/senescence/meta.xlsx\")\n",
    "# n_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for s in libs:  # iterate samples\n",
    "    print(f\"\\n\\n{'=' * 80}\\n{s}\\n{'=' * 80}\\n\\n\")\n",
    "    fff = os.path.join(dir_data, np.array(files)[np.where([\n",
    "        s == os.path.basename(x).split(\"__\")[2].split(\"-\")[0]\n",
    "        for x in files])[0][0]])  # sample's Xenium data directory path\n",
    "    lib = metadata.reset_index().set_index(cso).loc[s][col_sample]\n",
    "    file_obj_proc = os.path.join(out_dir, f\"{lib}{input_suffix}.h5ad\")\n",
    "    self = cr.Spatial(fff, library_id=lib)  # load original data\n",
    "    self.update_from_h5ad(file_obj_proc)  # update with processed object\n",
    "    if \"shapes\" in dir(sdata):\n",
    "        for x in sdata.shapes:\n",
    "            if self.adata.shapes[x].isnull().any().any():\n",
    "                self.adata.shapes[x] = sdata.shapes[x].dropna()\n",
    "    for coord_suffix in regions:\n",
    "        print(f\"\\n\\n\\t\\t{'*' * 40}\\n\\t\\t{s}\\n\\t\\t{'*' * 40}\\n\\n\")\n",
    "        dir_coord = os.path.join(\n",
    "            out_new, \"coordinates\", coord_suffix)  # coordinates (NFS soon?)\n",
    "        out = os.path.join(out_new, \"objects_cropped\", coord_suffix)  # path\n",
    "        os.makedirs(out, exist_ok=True)  # make sub-directory for new objects?\n",
    "        file_coord = os.path.join(dir_coord, s + f\"_{coord_suffix}.csv\")\n",
    "        file_obj_crop = os.path.join(out, f\"{lib}_{coord_suffix}.h5ad\")\n",
    "        if overwrite is False and os.path.exists(file_obj_crop):\n",
    "            print(f\"*** Subset {file_obj_crop} already exists\")\n",
    "            continue\n",
    "        if not os.path.exists(file_coord):\n",
    "            print(f\"*** Coordinate file {file_coord} doesn't exist\")\n",
    "            continue\n",
    "        print(f\"\\n\\nData: {fff}\\nObject: {file_obj_proc}\"\n",
    "              f\"\\nCoordinates: {file_coord}\\nOuput: {file_obj_crop}\")\n",
    "        sdata = self.crop(file_coord)  # crop data to coordinates\n",
    "        try:\n",
    "            # sdata = self.crop(file_coord)  # crop data to coordinates\n",
    "            if plot:\n",
    "                try:\n",
    "                    sdata.pl.render_labels(\"cell_labels\").pl.show()  # plot\n",
    "                except Exception:\n",
    "                    pass\n",
    "            self.adata = sdata\n",
    "            if write_object is True:\n",
    "                self.write(file_obj_crop)  # write cropped\n",
    "        except Exception:\n",
    "            print(traceback.format_exc(), f\"Cropping \\n\\n{s} failed!\")\n",
    "print(\"\\n\\nCompleted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "file_annotations = os.path.join(\n",
    "    out_dir, \"annotation_dictionaries/annotations_all.xlsx\")\n",
    "fmr = pd.read_excel(file_annotations, index_col=[0, 1])[\n",
    "    col_ann].dropna().astype(str)  # annotation mapping\n",
    "c_ann = col_ann + \"_\" + col_leiden.split(\"leiden_\")[1]\n",
    "\n",
    "for s in libs:  # iterate samples\n",
    "    print(f\"\\n\\n{'=' * 80}\\n{s}\\n{'=' * 80}\\n\\n\")\n",
    "    fff = os.path.join(dir_data, np.array(files)[np.where([\n",
    "        s == os.path.basename(x).split(\"__\")[2].split(\"-\")[0]\n",
    "        for x in files])[0][0]])  # sample's Xenium data directory path\n",
    "    lib = metadata.reset_index().set_index(cso).loc[s][col_sample]\n",
    "    file_obj_proc = os.path.join(out_dir, f\"{lib}{input_suffix}.h5ad\")\n",
    "    for coord_suffix in regions:\n",
    "        print(f\"\\n\\n\\t\\t{'*' * 40}\\n\\t\\t{s}\\n\\t\\t{'*' * 40}\\n\\n\")\n",
    "        self = cr.Spatial(fff, library_id=lib, col_cell_type=c_ann)  # load\n",
    "        self.update_from_h5ad(os.path.join(\n",
    "            out_new, \"objects_cropped\", coord_suffix,\n",
    "            f\"{lib}_{coord_suffix}.h5ad\"))  # update with cropped object\n",
    "        self.annotate_clusters(fmr.loc[i_x], col_cell_type=col_leiden,\n",
    "                               col_annotation=c_ann, copy=False)  # annotate\n",
    "        _ = self.calculate_centrality(n_jobs=sc.settings.n_jobs)\n",
    "        _, fig = self.calculate_neighborhood(figsize=(60, 30))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
