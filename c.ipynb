{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ryp2 is not installed. Install with </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">pip install rpy2 </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">to run tools with R support.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33mryp2 is not installed. Install with \u001b[0m\u001b[1;32mpip install rpy2 \u001b[0m\u001b[1;33mto run tools with R support.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data from `https://omnipathdb.org/queries/enzsub?format=json`\n",
      "Downloading data from `https://omnipathdb.org/queries/interactions?format=json`\n",
      "Downloading data from `https://omnipathdb.org/queries/complexes?format=json`\n",
      "Downloading data from `https://omnipathdb.org/queries/annotations?format=json`\n",
      "Downloading data from `https://omnipathdb.org/queries/intercell?format=json`\n",
      "Downloading data from `https://omnipathdb.org/about?format=text`\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import re\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import corescpy as cr\n",
    "\n",
    "# Computing Resources\n",
    "gpu = False\n",
    "sc.settings.n_jobs = 4\n",
    "sc.settings.max_memory = 200\n",
    "\n",
    "# Display\n",
    "pd.options.display.max_colwidth = 1000\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 500\n",
    "sc.settings.set_figure_params(dpi=100, frameon=False, figsize=(30, 30))\n",
    "plt.rcParams[\"figure.figsize\"] = [15, 15]\n",
    "\n",
    "# Panel Information\n",
    "old_seg = [\"50452A\", \"50452B\", \"50452C\",  # CHO-001\n",
    "           \"50618B5\", \"50564A4\",  # CHO-002\n",
    "           \"49377A2\",  # CHO-003\n",
    "           \"49464A4\",  # ?\n",
    "           \"49696A4\", \"49559A5\",  # CHO-004\n",
    "           \"50115A2\", \"50007B2\",  # CHO-005\n",
    "           \"49471A4\", \"50445A3\",  # CHO-006\n",
    "           ]  # old segmentation = old processing arguments\n",
    "\n",
    "# Panel & Column Names (from Metadata & To Be Created)\n",
    "panel = \"TUQ97N\"\n",
    "col_sample_id_o, col_sample_id = \"Sample ID\", \"Sample\"  # in metadata, new\n",
    "col_subject = \"Patient\"  # in metadata file\n",
    "col_inflamed, col_stricture = \"Inflamed\", \"Stricture\"  # in metadata file\n",
    "col_condition = \"Condition\"  # constructed from col_inflamed & col_stricture\n",
    "col_fff = \"file_path\"  # column in metadata in which to store data file path\n",
    "col_tangram = \"tangram_prediction\"  # for future Tangram imputation annotation\n",
    "col_segment = \"segmentation\"\n",
    "key_uninfl, key_infl, key_stric = \"Uninflamed\", \"Inflamed\", \"Stricture\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddm = \"/mnt/cho_lab\" if os.path.exists(\"/mnt/cho_lab\") else \"/mnt\"  # Spark?\n",
    "ddl = f\"{ddm}/disk2/{os.getlogin()}/data/shared-xenium-library\" if (\n",
    "    \"cho\" in ddm) else os.path.join(ddu, \"shared-xenium-library\")\n",
    "file_mdf = os.path.join(ddl, \"samples.csv\")  # metadata\n",
    "m_d = (pd.read_excel if file_mdf[-4:] == \"xlsx\" else pd.read_csv)(\n",
    "    file_mdf, dtype={\"Slide ID\": str}).rename({\n",
    "        \"Name\": col_subject, \"Inflammation\": col_inflamed}, axis=1)\n",
    "m_d.loc[:, col_segment] = \"new\"\n",
    "m_d.loc[m_d[col_sample_id_o].isin(old_seg), col_segment] = \"old\"\n",
    "m_d.loc[:, col_condition] = m_d.apply(lambda x: \"Stricture\" if x[\n",
    "    col_stricture].lower() in [\"stricture\", \"yes\"] else x[\n",
    "        col_inflamed].capitalize(), axis=1)  # inflamation/stricture condition\n",
    "m_d.loc[:, col_sample_id] = m_d[[col_condition, col_sample_id_o]].apply(\n",
    "    \"-\".join, axis=1)\n",
    "m_d = m_d.set_index(col_sample_id)\n",
    "print(m_d[[col_subject, col_condition]].reset_index(0)[\n",
    "    col_condition].value_counts())\n",
    "samps_paired = m_d.groupby(\"Patient\").apply(\n",
    "    lambda x: list(x.reset_index()[col_sample_id].sort_values()) if all((\n",
    "        i in list(x.reset_index()[col_condition]) for i in [\n",
    "            key_uninfl, key_infl, key_stric])) else np.nan).dropna(\n",
    "                ).explode()\n",
    "# print(list(samps_paired.sort_index()))\n",
    "# m_d.reset_index().set_index(col_sample_id).loc[samps_paired.to_list()]\n",
    "m_d.reset_index().set_index([col_subject, col_condition]).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories & Metadata\n",
    "load, reannotate = True, True\n",
    "# run = \"CHO-011\"\n",
    "# samples = \"all\"\n",
    "run = None  # just look for samples in all runs\n",
    "samples = [\"50452A\", \"50452B\", \"50006A\", \"50006B\",\n",
    "           \"50217A\", \"50217B\", \"50336B\", \"50336C\"]  # paired (un)inflamed\n",
    "# samples = [\"50006B\", \"50006A\",  \"50006C\",\n",
    "#            \"50217B\", \"50217A\", \"50217C\",\n",
    "#            \"50564A4\",\n",
    "#            \"50452A\", \"50452B\", \"50452C\",\n",
    "#            \"50336C\", \"50336B\",  \"50336A\"]  # all\n",
    "# samples = [\"50006C\", \"50217C\", \"50452C\", \"50336A\"]  # paired strictures\n",
    "dir_ax = \"/home/elizabeth/elizabeth/projects/senescence/analysis\"\n",
    "\n",
    "\n",
    "# Optionally, Define Manual Annotation Versions\n",
    "# should be stored in (\"<out_dir>/annotations_dictionaries\")\n",
    "# in format <selves[i]._library_id>___leiden_<man_anns[i]>_dictionary.xlsx\n",
    "# with first column = leiden cluster and second column = annotation\n",
    "man_anns = True  # load manual annotations according to clustering kws\n",
    "# man_anns = [\"res0pt5_dist0pt5_npc30\", \"res0pt75_dist0pt3_npc30\",\n",
    "#             \"res1pt5_dist0_npc30\"]  # choose manual annotations to load\n",
    "# man_anns = None  # do not load manual annotations\n",
    "\n",
    "# Main Directories\n",
    "# Replace manually or mirror my file/directory tree in your home (`ddu`)\n",
    "ddu = os.path.expanduser(\"~\")\n",
    "ddm = \"/mnt/cho_lab\" if os.path.exists(\"/mnt/cho_lab\") else \"/mnt\"  # Spark?\n",
    "ddl = f\"{ddm}/disk2/{os.getlogin()}/data/shared-xenium-library\" if (\n",
    "    \"cho\" in ddm) else os.path.join(ddu, \"shared-xenium-library\")\n",
    "ddx = f\"{ddm}/bbdata2\"  # mounted drive Xenium folder\n",
    "out_dir = os.path.join(ddl, \"outputs\", \"TUQ97N\", \"nebraska\")  # None = no save\n",
    "d_path = os.path.join(ddm, \"disk2\" if \"cho\" in ddm else \"\",\n",
    "                      os.getlogin(), \"data\")  # other, e.g., Tangram data\n",
    "anf = pd.read_csv(os.path.join(ddu, \"corescpy/examples/markers_lineages.csv\"))\n",
    "file_mdf = os.path.join(ddl, \"samples.csv\")  # metadata\n",
    "\n",
    "# Annotation & Tangram Imputation\n",
    "col_assignment = \"Bin\"  # which column from annotation file to use\n",
    "# col_cell_type_sc, file_sc = \"ClusterAnnotation\", str(\n",
    "#     f\"{d_path}/2023-05-12_CombinedCD-v2_ileal_new.h5ad\")\n",
    "col_cell_type_sc, file_sc = \"cell_type\", f\"{d_path}/elmentaite_ileal.h5ad\"\n",
    "# file_sc = None  # to skip Tangram imputation/label transfer\n",
    "\n",
    "# Processing & Clustering Options\n",
    "kws_cluster = dict(kws_umap=dict(method=\"rapids\" if gpu else \"umap\"),\n",
    "                   genes_subset=list(anf.iloc[:, 0]),  # use only markers\n",
    "                   use_gpu=gpu, use_highly_variable=False)\n",
    "kws_clustering, col_assignment = {}, []\n",
    "for i in zip([0.5, 0.75, 1.5], [0.5, 0.3, 0], [30, 30, 30]):\n",
    "    kws = {**kws_cluster, \"resolution\": i[0], \"kws_umap\": {\n",
    "        **kws_cluster[\"kws_umap\"], \"min_dist\": i[1]}, \"n_comps\": i[2]}\n",
    "    suff = str(f\"res{re.sub('[.]', 'pt', str(kws['resolution']))}_dist\"\n",
    "               f\"{re.sub('[.]', 'pt', str(kws['kws_umap']['min_dist']))}\"\n",
    "               f\"_npc{kws['n_comps']}\")  # file path suffix\n",
    "    kws_clustering.update({suff: kws})\n",
    "    col_assignment += [\"group\" if kws[\"resolution\"] >= 0.7 else \"Bucket\"]\n",
    "if man_anns is True:\n",
    "    man_anns = list(kws_clustering.keys())\n",
    "col_cell_type = list(kws_clustering.keys())[-1] if (\n",
    "    man_anns is None) else f\"manual_{man_anns[-1]}\"  # default cell labels\n",
    "\n",
    "# After this point, no more options to specify\n",
    "# Just code to infer the data file path from your specifications\n",
    "# and construct argument dictionaries and manipulate metadata and such.\n",
    "\n",
    "# Read Metadata & Other Information\n",
    "metadata = (pd.read_excel if file_mdf[-4:] == \"xlsx\" else pd.read_csv)(\n",
    "    file_mdf, dtype={\"Slide ID\": str}).rename({\n",
    "        \"Name\": col_subject, \"Inflammation\": col_inflamed}, axis=1)\n",
    "metadata.loc[:, col_segment] = \"new\"\n",
    "metadata.loc[metadata[col_sample_id_o].isin(old_seg), col_segment] = \"old\"\n",
    "\n",
    "# Revise Metadata & Construct Variables from Options\n",
    "metadata.loc[:, col_condition] = metadata.apply(lambda x: key_stric if x[\n",
    "    col_stricture].lower() in [\"stricture\", \"yes\"] else x[\n",
    "        col_inflamed].capitalize(), axis=1)  # inflamation/stricture condition\n",
    "metadata.loc[:, col_sample_id] = metadata[[col_condition, col_sample_id_o]\n",
    "                                          ].apply(\"-\".join, axis=1)\n",
    "metadata_o = metadata.copy()\n",
    "if samples not in [\"all\", None]:  # subset by sample ID?\n",
    "    metadata = metadata.set_index(col_sample_id_o).loc[samples].reset_index()\n",
    "metadata = metadata.set_index(col_sample_id)\n",
    "fff = np.array(cr.pp.construct_file(run=run, directory=ddx, panel_id=panel))\n",
    "bff = np.array([os.path.basename(i) for i in fff])  # base path names\n",
    "samps = np.array([i.split(\"__\")[2].split(\"-\")[0] for i in fff])\n",
    "for x in metadata[col_sample_id_o]:\n",
    "    m_f = metadata[metadata[col_sample_id_o] == x][\n",
    "        \"out_file\"].iloc[0]  # ...use to find unconventionally-named files\n",
    "    locx = np.where(samps == x)[0] if pd.isnull(\n",
    "        m_f) else np.where(bff == m_f)[0]\n",
    "    metadata.loc[metadata[col_sample_id_o] == x, col_fff] = fff[locx[0]] if (\n",
    "        len(locx) > 0) else np.nan  # assign output file to metadata row\n",
    "metadata = metadata.dropna(subset=[col_fff]).drop_duplicates()\n",
    "\n",
    "# Annotation File\n",
    "assign = anf.dropna(subset=col_assignment).set_index(\n",
    "    \"gene\").rename_axis(\"Gene\")  # markers\n",
    "# assign = assign[~assign.Quality.isin([-1])]  # drop low-quality markers\n",
    "\n",
    "# Print Metadata & Make Output Directory (If Not Present)\n",
    "print(metadata)\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "# Load Data\n",
    "kws_init = dict(col_sample_id=col_sample_id, col_subject=col_subject,\n",
    "                col_cell_type=col_cell_type)  # object creation arguments\n",
    "selves = [None] * metadata.shape[0]  # to hold different samples\n",
    "for i, x in enumerate(metadata.index.values):\n",
    "    selves[i] = cr.Spatial(metadata.loc[x][col_fff], library_id=x, **kws_init)\n",
    "    for j in metadata:  # iterate metadata columns\n",
    "        selves[i].rna.obs.loc[:, j] = str(metadata.loc[x][j])  # add to object\n",
    "    selves[i].rna.obs.loc[:, \"out_file\"] = os.path.join(\n",
    "        out_dir, selves[i]._library_id)  # output path (to save object)\n",
    "    if load is True:\n",
    "        if os.path.exists(str(selves[i].rna.obs.out_file.iloc[0]) + \".h5ad\"):\n",
    "            selves[i].update_from_h5ad(selves[i].rna.obs.out_file.iloc[0])\n",
    "        print(selves[i].rna)\n",
    "\n",
    "# Marker Gene Dictionary (for Scanpy Plotting)\n",
    "marker_genes_dict = dict(assign[\"Bucket\"].reset_index().groupby(\n",
    "    \"Bucket\").apply(lambda x: list(pd.unique(list(set(\n",
    "        x.Gene).intersection(selves[0].rna.var_names))))))  # to dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann = {}\n",
    "# for x in [f for f in os.listdir(dir_ann) if os.path.isdir(\n",
    "#         os.path.join(dir_ann, f)) is False]:\n",
    "#     ann[x] = pd.read_excel(os.path.join(\n",
    "#         out_dir, \"annotation_dictionaries\", x), index_col=0)\n",
    "#     # ann[x] = ann[x].assign(Sample=x.split(\"___\")[0])\n",
    "# ann = pd.concat(ann, names=[\"File\"])\n",
    "# ann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Manual Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if man_anns is not None and man_anns is not False:\n",
    "    for i, s in enumerate(selves):\n",
    "        for r in man_anns:  # iterate Leiden clusterings\n",
    "            fmr = os.path.join(out_dir, \"annotation_dictionaries\", str(\n",
    "                f\"{s._library_id}___leiden_{r}_dictionary.xlsx\"))  # file\n",
    "            if os.path.exists(fmr) is False:\n",
    "                print(f\"{fmr} file NOT found.\")\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"{fmr} file found.\")\n",
    "            if f\"leiden_{r}\" not in s.rna.obs:\n",
    "                print(f\"leiden_{r} not found in adata for {s._library_id}\")\n",
    "                continue\n",
    "            fmr = pd.read_excel(fmr).astype(str)\n",
    "            for x in [\"annotation\", \"bin\", \"bucket\"]:\n",
    "                s.rna.obs.loc[:, f\"{x}_{r}\"] = s.rna.obs[\n",
    "                    f\"leiden_{r}\"].astype(int).astype(str).replace(\n",
    "                        fmr.set_index(fmr.columns[0])[x])  # Leiden -> label\n",
    "                s.rna.obs.loc[s.rna.obs[f\"{x}_{r}\"].isnull(\n",
    "                    ), f\"{x}_{r}\"] = s.rna.obs.loc[s.rna.obs[\n",
    "                        f\"{x}_{r}\"].isnull(), f\"leiden_{r}\"].astype(\n",
    "                            str)  # missing annotations replaced with Leiden\n",
    "                s.rna.obs.loc[:, f\"{x}_{r}\"] = s.rna.obs[\n",
    "                    f\"{x}_{r}\"].astype(\"category\")  # as categorical\n",
    "                # s.plot_spatial(f\"{x}_{r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Cell Counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_m = f\"bin_{man_anns[-1]}\"\n",
    "p_clusts = pd.concat([100 * s.rna.obs[c_m].value_counts() / s.rna.n_obs\n",
    "                      for s in selves], keys=[s._library_id for s in selves],\n",
    "                     names=[\"Sample\"])\n",
    "p_clusts = p_clusts.unstack(1).replace(np.nan, 0).stack().to_frame(\"Percent\")\n",
    "all_samps = p_clusts.Percent.unstack().T.apply(\n",
    "    lambda x: x if all(x > 0) else np.nan, axis=1).dropna().index\n",
    "for x in [col_subject, col_condition]:\n",
    "    p_clusts = p_clusts.join(pd.Series([\n",
    "        s.rna.obs[x].iloc[0] for s in selves], index=pd.Index([\n",
    "            s._library_id for s in selves], name=p_clusts.index.names[\n",
    "                0])).to_frame(x))\n",
    "print(f\"Clusters Present in All Samples: {', '.join(list(all_samps))}\")\n",
    "fig = sb.catplot(p_clusts, x=c_m, y=\"Percent\", sharex=False,\n",
    "                 kind=\"bar\", margin_titles=True,\n",
    "                 col=col_subject, hue=col_condition,\n",
    "                 hue_order=[key_uninfl, key_infl, key_stric],\n",
    "                 palette=[\"blue\", \"red\", \"yellow\"])\n",
    "fig.set_xticklabels(rotation=90)\n",
    "fig.set_yticklabels(rotation=30)\n",
    "fig.fig.tight_layout()\n",
    "fig.fig.suptitle(x)\n",
    "fig.fig.set_size_inches(30, 30)\n",
    "fig.fig.show()\n",
    "n_clusts.unstack().astype(int).T.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Cluster Ns to Annotation Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if out_dir is not None:\n",
    "    for i, s in enumerate(selves):\n",
    "        for r in man_anns:  # iterate Leiden clusterings\n",
    "            fff = os.path.join(out_dir, \"annotation_dictionaries\", str(\n",
    "                f\"{s._library_id}___leiden_{r}_dictionary.xlsx\"))  # file\n",
    "            if os.path.exists(fff) is False:\n",
    "                print(f\"{fff} file NOT found.\")\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"{fff} file found.\")\n",
    "            fmr = pd.read_excel(fff).astype(str)\n",
    "            if \"n_cells\" in fmr:\n",
    "                fmr = fmr.drop(\"n_cells\", axis=1)\n",
    "            i_x = fmr.columns[0]\n",
    "            fmr = fmr.set_index(i_x).join(s.rna.obs[f\"leiden_{r}\"].astype(\n",
    "                str).value_counts().to_frame(\"n_cells\").rename_axis(i_x))\n",
    "            fmr.to_excel(fff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Manual Annotations (Xenium Explorer Files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if man_anns not in [None, False] and out_dir is not None and load is True:\n",
    "    for i, s in enumerate(selves):\n",
    "        for r in man_anns:\n",
    "            for x in [\"annotation\", \"bin\", \"bucket\"]:\n",
    "                if f\"{x}_{r}\" in s.rna.obs:\n",
    "                    s.write_clusters(out_dir, col_cell_type=f\"{x}_{r}\",\n",
    "                                     overwrite=True,\n",
    "                                     file_prefix=f\"{s._library_id}__\")\n",
    "        s.write(s.rna.obs.out_file.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tangram Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if file_sc is not None:\n",
    "    adata_sc = sc.read(file_sc)  # read whole tx'ome data for imputation\n",
    "    if load is False:\n",
    "        for i, s in enumerate(selves):\n",
    "            out = s.impute(\n",
    "                adata_sc.copy(), col_cell_type=col_cell_type_sc,\n",
    "                mode=\"clusters\", markers=None, plot=False, plot_density=False,\n",
    "                plot_genes=None, col_annotation=col_tangram, out_file=None)\n",
    "            out[0].write_h5ad(os.path.splitext(selves[\n",
    "                0].rna.obs.out_file.iloc[0])[0] + \"___tangram.h5ad\")  # write\n",
    "            s.write(s.rna.obs.out_file.iloc[0])\n",
    "            s.write_clusters(out_dir, file_prefix=f\"{s._library_id}___\",\n",
    "                             col_cell_type=col_tangram,\n",
    "                             overwrite=True, n_top=True)\n",
    "    s.plot_spatial(color=col_tangram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in selves:\n",
    "    s.plot_spatial(color=col_tangram)\n",
    "    for j, x in enumerate(kws_clustering):\n",
    "        _ = s.plot_spatial(color=[f\"leiden_{x}\",, f\"label_{x}\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centrality Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for s in selves:\n",
    "    _, fig = s.calculate_centrality(n_jobs=sc.settings.n_jobs)\n",
    "    fig.savefig(os.path.join(dir_ax, f\"{s._library_id}_centrality.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighborhood Enrichment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for s in selves:\n",
    "    _, fig = s.calculate_neighborhood(figsize=(60, 30))\n",
    "    fig.savefig(os.path.join(dir_ax, f\"{s.library_id}_neighborhood.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell Type Co-Occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for s in selves:\n",
    "    _ = s.find_cooccurrence(figsize=(60, 20), kws_plot=dict(wspace=3))\n",
    "    fig.savefig(os.path.join(dir_ax, f\"{s.library_id}_cooccurrence.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatially-Variable Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "kws = dict(kws_plot=dict(legend_fontsize=\"large\"), figsize=(15, 15))\n",
    "for s in selves:\n",
    "    _ = s.find_svgs(genes=15, method=\"moran\", n_perms=10, **kws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receptor-Ligand Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for s in selves:\n",
    "    kss, ktt = None, None\n",
    "    _ = s.calculate_receptor_ligand(\n",
    "        col_condition=False, p_threshold=0.01, remove_ns=True,\n",
    "        figsize=(30, 20), top_n=25, key_sources=kss, key_targets=ktt)\n",
    "    # s.calculate_receptor_ligand_spatial()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in selves:\n",
    "    s.plot_spatial(color=[\"CSF1\", \"CSF2\", \"CSF3\", col_cell_type])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in selves:\n",
    "    cct = f\"leiden_spatial_{list(kws_clustering.keys())[-1]}\"\n",
    "    _ = s.cluster_spatial(key_added=cct,\n",
    "                          **kws_clustering[list(kws_clustering.keys())[-1]])\n",
    "    _ = s.find_markers(col_cell_type=cct, kws_plot=False)\n",
    "    _ = s.annotate_clusters(assign[[col_assignment[-1]]], col_cell_type=cct,\n",
    "                            col_annotation=f\"annotation_{cct}\")\n",
    "    for c in [cct, f\"annotation_{cct}\"]:\n",
    "        s.plot_spatial(c)\n",
    "        if out_dir is not None:\n",
    "            s.write_clusters(out_dir, col_cell_type=c, overwrite=True,\n",
    "                             n_top=True, file_prefix=f\"{s._library_id}___\")\n",
    "    if out_dir is not None:\n",
    "        s.write(str(s.rna.obs.out_file.iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Results Files? Read & Join Prior Results if Present?\n",
    "write = True\n",
    "join_old = True\n",
    "\n",
    "# Cell Type Columns\n",
    "c_l = \"leiden_res1pt5_dist0_npc30\"\n",
    "c_ann = [\"bucket\", \"bin\", \"annotation\"]\n",
    "c_m = \"bucket\"  # focus for certain plots\n",
    "\n",
    "# For Plots\n",
    "hue_order = [\"Uninflamed\", \"Inflamed\", \"Stricture\"]\n",
    "palette = [\"blue\", \"red\", \"yellow\"]\n",
    "hue = dict(hue=col_condition, hue_order=hue_order, palette=palette)\n",
    "\n",
    "# For Markers\n",
    "p_threshold = 1e-15\n",
    "lfc_threshold = 1.5\n",
    "n_top = 10\n",
    "\n",
    "# Senescence\n",
    "# label = \"snc\"\n",
    "# c_t = \"Senescence_Proxy\"\n",
    "# g_t = [\"CDKN1A\", \"TP53\", \"PLAUR\"]\n",
    "# g_c = [\"CDKN1A\", \"TP53\", \"PLAUR\"]\n",
    "# directory = \"/home/elizabeth/elizabeth/projects/senescence/analysis\"\n",
    "\n",
    "# CSF2RB\n",
    "label = \"csf\"\n",
    "c_t = \"ILC_Proxy\"\n",
    "g_t = [\"CSF1\", \"CSF2\", \"CSF3\"]\n",
    "g_c = [\"IL7R\", \"KLRB1\", \"RORC\"]\n",
    "c_l = \"leiden_res1pt5_dist0_npc30\"\n",
    "directory = \"/home/elizabeth/elizabeth/projects/csf2rb/analysis\"\n",
    "\n",
    "fmrs = {}\n",
    "for x in metadata_o[col_sample_id].unique():\n",
    "    fann = os.path.join(out_dir, \"annotation_dictionaries\", str(\n",
    "        f\"{x}___{c_l}_dictionary.xlsx\"))\n",
    "    if os.path.exists(fann):\n",
    "        fmr = pd.read_excel(fann).astype(str).replace(\"nan\", np.nan)\n",
    "        fmrs[x] = fmr.set_index(fmr.columns[0]).rename_axis(c_l)\n",
    "fmrs = pd.concat(fmrs, names=[\"Sample\", c_l])\n",
    "\n",
    "# Markers\n",
    "mks = pd.concat([cr.ax.make_marker_genes_df(\n",
    "    s.rna, c_l, key_added=f\"rank_genes_groups_{c_l}\", p_threshold=p_threshold,\n",
    "    lfc_threshold=lfc_threshold) for s in selves], keys=[\n",
    "        s._library_id for s in selves], names=[\"Sample\"])\n",
    "mks_strings = mks.groupby(mks.index.names[:-1]).apply(lambda x: \", \".join([\n",
    "    str(f\"{i} (lfc={round(x.loc[x.name].loc[i]['logfoldchanges'], 2)}; \"\n",
    "        f\"p_adj={x.loc[x.name].loc[i]['pvals_adj']})\")\n",
    "    for i in x.reset_index().sort_values(\"pvals_adj\").iloc[\n",
    "        :min(n_top, x.shape[0])].names.unique()])).to_frame(\"Markers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_cts, tx_cts_cl = {}, {}\n",
    "for s in selves:\n",
    "    tx_cts[s._library_id], tx_cts_cl[s._library_id] = s.quantify_transcripts(\n",
    "        g_t, col_cell_type=c_l if c_l in s.rna.obs else None, layer=\"counts\")\n",
    "tx_cts = pd.concat(tx_cts, keys=tx_cts, names=[\"Sample\", \"Gene\"])\n",
    "tx_cts_cl = pd.concat(tx_cts_cl, names=[\"Sample\", c_l])\n",
    "fff = os.path.join(directory, f\"quantification_{label}_tx_cts\")\n",
    "if join_old is True and os.path.exists(fff + \".xlsx\"):\n",
    "    tx_os = pd.read_excel(fff + \".xlsx\", index_col=np.arange(\n",
    "        len(tx_cts.index.names)))\n",
    "    tx_cts = pd.concat([tx_cts, tx_os.loc[\n",
    "        tx_os.index.difference(tx_cts.index)]])\n",
    "if join_old is True and os.path.exists(fff + \"_by_cluster.xlsx\"):\n",
    "    tx_os_cl = pd.read_excel(fff + \"_by_cluster.xlsx\", index_col=np.arange(\n",
    "        len(tx_cts.index.names))).reset_index().astype(\n",
    "            {c_l: str}).set_index(tx_cts_cl.index.names)\n",
    "    tx_cts_cl = pd.concat([tx_cts_cl, tx_os_cl.loc[\n",
    "        tx_os_cl.index.difference(tx_cts_cl.index)]])\n",
    "tx_cts_cl = tx_cts_cl.reset_index().astype({c_l: str}).set_index(\n",
    "    tx_cts_cl.index.names).drop(set(c_ann).intersection(\n",
    "        tx_cts_cl.columns), axis=1).join(\n",
    "            fmrs[c_ann], on=[\"Sample\", c_l])\n",
    "tx_cts_cl = tx_cts_cl.reset_index().drop_duplicates().astype(\n",
    "    {c_l: int}).set_index(tx_cts_cl.index.names).sort_index().reset_index(\n",
    "        ).astype({c_l: \"string\"}).set_index(tx_cts_cl.index.names)\n",
    "tx_cts = tx_cts.reset_index().drop_duplicates().set_index(tx_cts.index.names)\n",
    "if write is True:\n",
    "    tx_cts.to_excel(fff + \".xlsx\")\n",
    "    tx_cts_cl.join(mks_strings).to_excel(fff + \"_by_cluster.xlsx\")\n",
    "tx_cts_cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in selves:\n",
    "    val = tx_cts.loc[s._library_id].stack().to_frame(\"Mine\").join(\n",
    "        s.rna.var.loc[g_t].rename_axis(\"Gene\")[\"n_counts\"].to_frame(\n",
    "            \"n_transcripts\").assign(total_counts=s.rna.obs[\n",
    "                \"n_counts\"].sum()).stack().to_frame(\"Scanpy\"))\n",
    "    print(\"Comparison\\n\\n\", val[\"Mine\"].compare(val[\"Scanpy\"]))\n",
    "val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall (Multi-Gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = tx_cts_cl.join(\n",
    "    metadata_o[[col_sample_id, col_subject, col_condition]].set_index(\n",
    "        col_sample_id), how=\"left\").set_index([\n",
    "            col_subject, col_condition] + c_ann, append=True).rename_axis(\n",
    "                \"Gene\", axis=1).stack()\n",
    "dff = [dff.groupby(dff.index.names.difference(set(c_ann).difference(\n",
    "    [y]))).sum() for y in c_ann]\n",
    "dff = pd.concat([x.to_frame(\"n_transcripts\").reset_index().rename({\n",
    "    c_ann[i]: \"Cluster\"}, axis=1).set_index(x.index.names.difference([c_ann[\n",
    "        i]])).set_index(\"Cluster\", append=True) for i, x in enumerate(dff)],\n",
    "                keys=c_ann, names=[\"Annotation\"])\n",
    "for x in dff.reset_index()[col_subject].unique():\n",
    "    fig = sb.catplot(dff.reset_index()[dff.reset_index()[col_subject] == x],\n",
    "                     x=\"Cluster\", y=\"n_transcripts\", kind=\"bar\", sharex=False,\n",
    "                     sharey=False, row=\"Annotation\",\n",
    "                     margin_titles=True, **hue)\n",
    "    fig.set_xticklabels(rotation=90)\n",
    "    fig.set_titles(col_template=\"{col_name}\", row_template=\"{row_name}\")\n",
    "    fig.fig.set_size_inches(25, 25)\n",
    "    plt.subplots_adjust(hspace=0.8)\n",
    "    fig.fig.suptitle(x)\n",
    "    plt.show()\n",
    "# fig.fig.tight_layout()\n",
    "fig = sb.catplot(dff.reset_index()[dff.reset_index()[\n",
    "    \"Annotation\"] == c_ann[0]], x=\"Cluster\", y=\"n_transcripts\", **hue,\n",
    "                 kind=\"box\", sharex=False, sharey=False)\n",
    "fig.set_xticklabels(rotation=90)\n",
    "fig.set_titles(col_template=\"{col_name}\", row_template=\"{row_name}\")\n",
    "fig.fig.set_size_inches(25, 25)\n",
    "plt.subplots_adjust(hspace=0.8)\n",
    "fig.fig.suptitle(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label = \"Gene Transcript Counts: Percent of Total Counts\"\n",
    "dff = tx_cts_cl.set_index(c_ann, append=True).apply(lambda x: tx_cts_cl[\n",
    "    x.name] / tx_cts_cl[\"total_counts\"]).drop(\n",
    "        \"total_counts\", axis=1).rename_axis(\"Gene\", axis=1).stack()\n",
    "dff = dff * 100\n",
    "dff = dff.to_frame(y_label).join(\n",
    "    metadata_o[[col_sample_id, col_subject, col_condition]].set_index(\n",
    "        col_sample_id), how=\"left\").join(fmrs[c_ann]).reset_index(\n",
    "            ).drop_duplicates()\n",
    "if dff[y_label].max() > 1:\n",
    "    raise ValueError(f\"Percentages > 1: {dff[dff[y_label] > 1]}\")\n",
    "fig = sb.catplot(dff, x=c_m, y=y_label, kind=\"bar\",\n",
    "                 sharex=False, sharey=False, col=\"Gene\", hue=c_m)\n",
    "fig.set_xticklabels(rotation=90)\n",
    "fig.fig.set_size_inches(60, 25)\n",
    "fig.fig.set_dpi(200)\n",
    "plt.subplots_adjust(hspace=0.8)\n",
    "fig.fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By Gene & Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label = \"Gene Transcript Counts: Percent of Total Counts\"\n",
    "dff = tx_cts_cl.set_index(c_ann, append=True).apply(lambda x: tx_cts_cl[\n",
    "    x.name] / tx_cts_cl[\"total_counts\"]).drop(\n",
    "        \"total_counts\", axis=1).rename_axis(\"Gene\", axis=1).stack()\n",
    "dff = dff * 100\n",
    "dff = dff.to_frame(y_label).join(\n",
    "    metadata_o[[col_sample_id, col_subject, col_condition]].set_index(\n",
    "        col_sample_id), how=\"left\").join(fmrs[c_ann]).reset_index(\n",
    "            ).drop_duplicates()\n",
    "if dff[y_label].max() > 1:\n",
    "    raise ValueError(f\"Percentages > 1: {dff[dff[y_label] > 1]}\")\n",
    "for x in [None, col_subject]:  # aggregate across subjects, or facet\n",
    "    fig = sb.catplot(dff.dropna(subset=[c_m]), x=c_m, y=y_label,\n",
    "                     kind=\"box\" if x is None else \"bar\",\n",
    "                     sharex=False, sharey=False, row=x, col=\"Gene\",\n",
    "                     margin_titles=True, **hue)\n",
    "    fig.set_xticklabels(rotation=90)\n",
    "    fig.set_titles(col_template=\"{col_name}\", row_template=\"{row_name}\")\n",
    "    fig.fig.set_size_inches(60, 25)\n",
    "    plt.subplots_adjust(hspace=0.8)\n",
    "    fig.fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = [1, 2, 3]\n",
    "lfc_threshold, p_threshold = 1.5, 1e-15\n",
    "\n",
    "cts, cts_cl = {}, {}\n",
    "for s in selves:\n",
    "    if label = \"csf\":\n",
    "        _, cts_cl[s._library_id], _ = s.quantify_cells(\n",
    "            g_c, threshold=threshold, n_combos=\"all\", col_cell_type=c_l,\n",
    "            layer=\"counts\", inplace=True)\n",
    "        cts[s._library_id], _, _ = s.quantify_cells(\n",
    "            g_t, threshold=threshold, n_combos=\"all\", col_cell_type=None,\n",
    "            layer=\"counts\", inplace=True)\n",
    "    else:\n",
    "        cts[s._library_id], cts_cl[s._library_id], _ = s.quantify_cells(\n",
    "            g_c, threshold=threshold, n_combos=\"all\", col_cell_type=c_l,\n",
    "            layer=\"counts\", inplace=True)\n",
    "cts, cts_cl = [pd.concat(x, names=[\"Sample\"]) for x in [cts, cts_cl]]\n",
    "fff = os.path.join(directory, f\"quantification_ncells_{label}\")\n",
    "# for s in selves:\n",
    "#     if c_l in s.rna.obs and f\"rank_genes_groups_{c_l}\" in s.rna.uns:\n",
    "#         mks =\n",
    "#         cts_cl.loc[s._library_id] = cts_cl.loc[s._library_id].join(\n",
    "#             mks.groupby(c_l).apply(lambda x: \", \".join(mks.loc[x.name].head(\n",
    "#                 10).index) if (x.name in mks.index) else \"\").to_frame(\n",
    "#                     \"Meta\").rename_axis(\"Metric\", axis=1).stack().to_frame(\n",
    "#                         \"Markers\").unstack())\n",
    "if join_old is True and os.path.exists(fff + \".xlsx\"):\n",
    "    cts_o = pd.read_excel(fff + \".xlsx\").set_index(list(cts.index.names))\n",
    "    for x in cts_o:\n",
    "        if x in cts_o:\n",
    "            cts_o = cts_o.drop(x, axis=1)\n",
    "    cts = pd.concat([cts, cts_o.loc[cts_o.index.difference(cts.index)]])\n",
    "if join_old is True and os.path.exists(fff + \"_by_cluster.xlsx\"):\n",
    "    cts_cl_o = pd.read_excel(fff + \"_by_cluster.xlsx\", header=[0, 1],\n",
    "                             index_col=[0, 1, 2])\n",
    "    for x in c_ann:\n",
    "        if x in cts_cl_o:\n",
    "            cts_cl_o = cts_cl_o.drop(x, axis=1)\n",
    "    cts_cl = pd.concat([cts_cl, cts_cl_o.loc[\n",
    "        cts_cl_o.index.difference(cts_cl.index)]]).dropna(how=\"all\")\n",
    "cts_cl_s = pd.concat([fmrs[c_ann].reset_index().astype(\"string\").set_index(\n",
    "    fmrs.index.names)], axis=1, keys=[\"Annotation\"])\n",
    "cts_cl_s = cts_cl_s.reset_index().drop_duplicates().astype(str).set_index(\n",
    "    cts_cl_s.index.names)\n",
    "cts_cl = cts_cl[cts_cl.columns.difference(cts_cl_s.columns)].reset_index(\n",
    "    ).drop_duplicates().astype(str).set_index(\n",
    "        cts_cl.index.names).join(cts_cl_s)\n",
    "if any(cts_cl[\"Percent\"].astype(float).stack() > 100):\n",
    "    raise ValueError(\"Percentages > 1:\\n\")\n",
    "    print(cts_cl[\"Percent\"].astype(float).stack()[cts_cl[\n",
    "        \"Percent\"].astype(float).stack() > 100])\n",
    "if write is True:\n",
    "    cts.to_excel(fff + \".xlsx\")\n",
    "    cts_cl.join(pd.concat([mks_strings], keys=[\"Markers\"], axis=1)).to_excel(\n",
    "        fff + \"_by_cluster.xlsx\")\n",
    "cts_cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in selves:\n",
    "    val = cts.loc[s._library_id].loc[1].stack().to_frame(\"Mine\").join(\n",
    "        s.rna.var.loc[g_c].rename_axis(\"Gene\")[\"n_cells\"].to_frame(\n",
    "            \"Count\").assign(Total=s.rna.n_obs).stack(\n",
    "                ).to_frame(\"Scanpy\"))\n",
    "    print(\"Comparison\\n\\n\", val[\"Mine\"].compare(val[\"Scanpy\"]))\n",
    "val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vvr = cts_cl.copy()[\"Percent\"].rename_axis(\"Label\", axis=1).dropna(\n",
    "    how=\"all\").stack().to_frame(\"Percent\").astype(float).join(fmrs[[c_m]])\n",
    "vvr = vvr.join(vvr.groupby(\"Sample\").apply(lambda x: x.name.split(\"-\")[\n",
    "    0]).to_frame(col_condition)).reset_index().drop_duplicates()\n",
    "vvr = vvr[vvr.apply(lambda x: \"|\" not in x[c_m], axis=1)]  # no mixes\n",
    "for x in vvr.Threshold.unique():\n",
    "    fig = sb.catplot(vvr[vvr.Threshold == x], x=c_m, y=\"Percent\",\n",
    "                     sharey=False, kind=\"box\", margin_titles=True,\n",
    "                     row=\"Label\", sharex=False, **hue)\n",
    "    fig.set_titles(col_template=\"{col_name}\", row_template=\"{row_name}\")\n",
    "    fig.set_xticklabels(rotation=90)\n",
    "    fig.fig.set_size_inches(35, 25)\n",
    "    fig.fig.suptitle(f\"Threshold = {x}\")\n",
    "    fig.fig.set_dpi(100)\n",
    "    fig.fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = s.calculate_spatial_distance(f\"{'/'.join(g_c)}+\", col_cell_type=c_t,\n",
    "                                 genes=\"CSF2RB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.adata.labels[\"cell_labels\"][\"scale0\"]\n",
    "# selves[1].adata.shapes[\"cell_boundaries\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in selves:\n",
    "    m_d = metadata.loc[s._library_id]\n",
    "    fig = s.plot_spatial(color=\"bucket_res1pt5_dist0_npc30\")\n",
    "    fig.set_title(f\"{s._library_id} (Age {m_d['Age']})\")\n",
    "    fig.fig.set_dpi(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEX Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [\"heat\", \"matrix\", \"dot\"]:\n",
    "    for s in selves:\n",
    "        s.plot(g_c, kind=k, col_cell_type=c_m, title=s._library_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=selves[0]\n",
    "\n",
    "coex = [[\"CSF2RA\", \"CSF2RB\"], [\"IL3RA\", \"CSF2RB\"], [\"IL5RA\", \"CSF2RB\"]]\n",
    "col_cell_type = \"leiden_res1pt5_dist0_npc30\"\n",
    "threshold = 1\n",
    "layer = \"counts\"\n",
    "\n",
    "percs = {}\n",
    "for s in selves:\n",
    "    for i in coex:\n",
    "        s.get_layer(layer, inplace=True)\n",
    "        for g in i:\n",
    "            s.rna.obs.loc[:, g] = s.rna[:, g].X.toarray()\n",
    "        s.rna.obs.loc[:, \"-\".join(i)] = s.rna.obs.apply(\n",
    "            lambda x: all((x[g] >= threshold for g in i)), axis=1)\n",
    "    coex_names = [\"-\".join(i) for i in coex]\n",
    "    percs[s._library_id] = pd.concat([s.rna.obs.groupby(col_cell_type).apply(\n",
    "        lambda x: 100 * x.loc[:, c].mean()) for c in coex_names],\n",
    "                                     keys=coex_names, names=[\"Coexpression\"])\n",
    "percs = pd.concat(percs, names=[\"Sample\"]).to_frame(\"Percent of Cells\")\n",
    "percs = percs.groupby([\"Sample\", \"Coexpression\"]).apply(\n",
    "    lambda x: x.iloc[:, 0].sort_values(ascending=False)).reset_index([\n",
    "        2, 3], drop=True).to_frame(percs.columns[0]).join(fmrs[[\n",
    "            c_ann[-1]]]).join(mks_strings).join(metadata[[\n",
    "                col_subject, col_condition]]).reset_index().set_index([\n",
    "                    col_condition, \"Coexpression\",\n",
    "                    col_subject, col_cell_type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percs.to_excel(str(\"/home/elizabeth/elizabeth/projects\"\n",
    "                   \"/csf2rb/analysis/percs_coex.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percs.groupby([\"Condition\", \"Coexpression\", \"Patient\"]).apply(\n",
    "    lambda x: x[x[\"Percent of Cells\"] >= 3]).reset_index([\n",
    "        -2, -3, -4], drop=True).groupby([\n",
    "            col_condition, \"Coexpression\"]).apply(\n",
    "                lambda x: x.annotation.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_ce = 3\n",
    "cct = \"bin\"\n",
    "percs_p = percs.join(fmrs[[cct]], lsuffix=\"_original\")\n",
    "in_all_cond = [i for i in percs_p[cct].unique() if all(\n",
    "    (any(percs_p[percs_p[cct] == i].reset_index(col_condition)[\n",
    "        col_condition] == x) for x in percs_p.reset_index(col_condition)[\n",
    "            col_condition].unique()))]  # cell types present in all conditions\n",
    "percs_p = percs_p[percs_p[cct].isin(in_all_cond)]  # only if cell type in all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_ce = 3\n",
    "cct = \"bin\"\n",
    "\n",
    "percs_p = percs.join(fmrs[[cct]], lsuffix=\"_original\")\n",
    "in_all_cond = [i for i in percs_p[cct].unique() if all(\n",
    "    (any(percs_p[percs_p[cct] == i].reset_index(col_condition)[\n",
    "        col_condition] == x) for x in percs_p.reset_index(col_condition)[\n",
    "            col_condition].unique()))]  # cell types present in all conditions\n",
    "percs_p = percs_p[percs_p[cct].isin(in_all_cond)]  # only if cell type in all\n",
    "\n",
    "percs_p = percs_p[percs_p[cct].isin(percs_p[percs_p[\n",
    "    \"Percent of Cells\"] >= thresh_ce][cct].unique())]\n",
    "percs_p = percs_p[percs_p.annotation.apply(\n",
    "    lambda x: \"B Cell\" in x or \"T Cell\" in x or \"Endothelial\" in x or (\n",
    "        \"Glia\" in x) or \"Mono\" in x or \"DC\" in x or \"Myeloid\" in x or (\n",
    "            \"Macrophage\" in x) or \"Mast\" in x or \"Plasma\" in x)]\n",
    "fig = sb.catplot(percs_p, y=\"Percent of Cells\", row=\"Coexpression\", x=cct,\n",
    "                 hue=col_condition, kind=\"box\", sharex=False)\n",
    "fig.set_titles(col_template=\"{col_name}\", row_template=\"{row_name}\")\n",
    "fig.set_xticklabels(rotation=90)\n",
    "fig.fig.set_size_inches(25, 20)\n",
    "fig.fig.suptitle(f\"Coexpression Levels\" + str(\n",
    "    f\" (Cell Types with Any >= {thresh_ce}%)\" if thresh_ce > 0 else \"\"))\n",
    "fig.fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbt = percs[percs.annotation.apply(lambda x: \"B Cell\" in x or \"T Cell\" in x)]\n",
    "# pbt.loc[\"Uninflamed\"]\n",
    "pbt[pbt[\"Percent of Cells\"] >= 3].sort_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-bio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
